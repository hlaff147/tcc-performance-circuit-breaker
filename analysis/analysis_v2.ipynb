{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0631f5fa",
   "metadata": {},
   "source": [
    "### Seção 6: Análise Estatística\n",
    "Aplique testes estatísticos (como ANOVA ou teste t) para determinar se as diferenças de desempenho observadas entre as versões são estatisticamente significativas. Formule as hipóteses nula ($H_0$) e alternativa ($H_1$) e interprete os resultados do p-valor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b31c78d9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BASE_DIR' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Diretório para salvar os resultados finais\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m OUTPUT_DIR = \u001b[43mBASE_DIR\u001b[49m / \u001b[33m'\u001b[39m\u001b[33mresults_archive\u001b[39m\u001b[33m'\u001b[39m / \u001b[33m'\u001b[39m\u001b[33mv2.0.0-SNAPSHOT\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      3\u001b[39m PLOTS_DIR = OUTPUT_DIR / \u001b[33m'\u001b[39m\u001b[33mplots\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      4\u001b[39m LATEX_DIR = OUTPUT_DIR / \u001b[33m'\u001b[39m\u001b[33mlatex\u001b[39m\u001b[33m'\u001b[39m\n",
      "\u001b[31mNameError\u001b[39m: name 'BASE_DIR' is not defined"
     ]
    }
   ],
   "source": [
    "# Diretório para salvar os resultados finais\n",
    "OUTPUT_DIR = BASE_DIR / 'results_archive' / 'v2.0.0-SNAPSHOT'\n",
    "PLOTS_DIR = OUTPUT_DIR / 'plots'\n",
    "LATEX_DIR = OUTPUT_DIR / 'latex'\n",
    "\n",
    "# Cria os diretórios se não existirem\n",
    "PLOTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "LATEX_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# --- Exemplo 1: Salvar um gráfico de boxplot em alta qualidade ---\n",
    "scenario_to_save = 'indisponibilidade-extrema'\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "sns.boxplot(\n",
    "    ax=ax,\n",
    "    data=results_df[results_df['scenario'] == scenario_to_save],\n",
    "    x='treatment',\n",
    "    y='p95_duration_ms',\n",
    "    order=[f'v{i}' for i in range(1, 5)]\n",
    ")\n",
    "\n",
    "ax.set_title(f'Distribuição do Tempo de Resposta (p95) - {scenario_to_save.replace(\"-\", \" \").title()}', fontsize=16)\n",
    "ax.set_ylabel('Tempo de Resposta p95 (ms)', fontsize=12)\n",
    "ax.set_xlabel('Versão do Serviço', fontsize=12)\n",
    "ax.set_yscale('log')\n",
    "\n",
    "# Salva em diferentes formatos\n",
    "plot_filename_base = f'boxplot_p95_{scenario_to_save}'\n",
    "fig.savefig(PLOTS_DIR / f'{plot_filename_base}.pdf', bbox_inches='tight') # Vetorial, ideal para LaTeX\n",
    "fig.savefig(PLOTS_DIR / f'{plot_filename_base}.png', dpi=300, bbox_inches='tight') # Alta resolução\n",
    "\n",
    "print(f\"Gráfico salvo em: {PLOTS_DIR / f'{plot_filename_base}.pdf'}\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# --- Exemplo 2: Exportar um DataFrame para uma tabela LaTeX ---\n",
    "# Vamos exportar a tabela de análise agrupada\n",
    "latex_table = grouped_analysis.to_latex(\n",
    "    index=False,\n",
    "    float_format=\"%.2f\", # Formata floats com 2 casas decimais\n",
    "    caption='Análise Agrupada das Métricas de Performance por Cenário e Versão.',\n",
    "    label='tab:grouped_analysis',\n",
    "    column_format='llrrrrrr' # Define o alinhamento das colunas\n",
    ")\n",
    "\n",
    "latex_filename = LATEX_DIR / 'tabela_resumo_agrupado.tex'\n",
    "with open(latex_filename, 'w') as f:\n",
    "    f.write(latex_table)\n",
    "\n",
    "print(f\"\\nTabela LaTeX salva em: {latex_filename}\")\n",
    "# Exibe o código LaTeX gerado\n",
    "# print(\"\\nCódigo LaTeX gerado:\")\n",
    "# print(latex_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f858a2",
   "metadata": {},
   "source": [
    "### Seção 8: Geração de Gráficos para Publicação (LaTeX)\n",
    "Produza gráficos de alta qualidade com `matplotlib` e `seaborn`, com rótulos claros, títulos e legendas. Demonstre como salvar esses gráficos em formatos vetoriais (como PDF ou SVG) ou de alta resolução (PNG) para inclusão em documentos LaTeX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7474ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_full_run_data(experiment_dir: Path, scenario: str, treatment: str, run: int) -> pd.DataFrame:\n",
    "    \"\"\"Carrega os dados de série temporal de um arquivo de execução completo.\"\"\"\n",
    "    filepath = experiment_dir / f\"{scenario}_{treatment}_run{run}.json\"\n",
    "    \n",
    "    if not filepath.exists():\n",
    "        print(f\"Arquivo não encontrado: {filepath}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    points = []\n",
    "    with open(filepath, 'r') as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                record = json.loads(line)\n",
    "                # Filtra apenas os pontos de dados de métricas de série temporal\n",
    "                if record['type'] == 'Point' and 'data' in record:\n",
    "                    # Converte o timestamp para datetime\n",
    "                    timestamp = pd.to_datetime(record['data']['time'])\n",
    "                    metric_name = record['metric']\n",
    "                    value = record['data']['value']\n",
    "                    points.append([timestamp, metric_name, value])\n",
    "            except (json.JSONDecodeError, KeyError):\n",
    "                continue # Ignora linhas que não são JSON ou não têm a estrutura esperada\n",
    "    \n",
    "    if not points:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    df = pd.DataFrame(points, columns=['time', 'metric', 'value'])\n",
    "    df = df.set_index('time')\n",
    "    return df\n",
    "\n",
    "# Exemplo: Analisar a série temporal da duração das requisições para uma execução\n",
    "# Vamos escolher um cenário e uma execução para demonstrar\n",
    "scenario_to_plot = 'falha-catastrofica'\n",
    "treatment_to_plot = 'v4' # Ex: A versão com Circuit Breaker\n",
    "run_to_plot = 1\n",
    "\n",
    "print(f\"Carregando dados detalhados para: {scenario_to_plot}, {treatment_to_plot}, run {run_to_plot}\")\n",
    "full_run_df = load_full_run_data(EXPERIMENT_DIR, scenario_to_plot, treatment_to_plot, run_to_plot)\n",
    "\n",
    "if not full_run_df.empty:\n",
    "    # Filtra a métrica de duração da requisição\n",
    "    duration_ts = full_run_df[full_run_df['metric'] == 'http_req_duration']\n",
    "\n",
    "    plt.figure(figsize=(15, 7))\n",
    "    duration_ts['value'].plot(style='.', alpha=0.5)\n",
    "    \n",
    "    # Adiciona uma média móvel para visualizar a tendência\n",
    "    duration_ts['value'].rolling('10s').mean().plot(color='red', linewidth=2)\n",
    "\n",
    "    plt.title(f'Duração das Requisições ao Longo do Tempo\\n({scenario_to_plot} - {treatment_to_plot} - Run {run_to_plot})')\n",
    "    plt.ylabel('Duração (ms)')\n",
    "    plt.xlabel('Tempo de Execução do Teste')\n",
    "    plt.legend(['Duração da Requisição', 'Média Móvel (10s)'])\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Não foi possível gerar o gráfico de série temporal.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f19d55",
   "metadata": {},
   "source": [
    "### Seção 7: Análise de Séries Temporais das Métricas\n",
    "Carregue os dados detalhados (arquivos `.json` sem `_summary`) para uma execução específica. Plote métricas como requisições por segundo (`http_reqs`) e latência (`http_req_duration`) ao longo do tempo para analisar o comportamento do sistema durante o teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c04b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usaremos o teste de Mann-Whitney U, que não assume uma distribuição normal dos dados,\n",
    "# o que é uma escolha segura para métricas de performance.\n",
    "\n",
    "# Hipóteses:\n",
    "# H0 (Hipótese Nula): As distribuições das métricas de duas versões são iguais.\n",
    "# H1 (Hipótese Alternativa): As distribuições são diferentes.\n",
    "# Se p-valor < 0.05, rejeitamos H0 e concluímos que há uma diferença estatisticamente significativa.\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "statistical_results = []\n",
    "\n",
    "# Métricas para testar\n",
    "metrics_to_test = ['success_rate', 'p95_duration_ms']\n",
    "\n",
    "for scenario in results_df['scenario'].unique():\n",
    "    for metric in metrics_to_test:\n",
    "        # Gera todas as combinações de pares de tratamentos (v1 vs v2, v1 vs v3, etc.)\n",
    "        treatment_pairs = list(combinations(results_df['treatment'].unique(), 2))\n",
    "        \n",
    "        for v_a, v_b in treatment_pairs:\n",
    "            # Seleciona os dados para cada versão no cenário atual\n",
    "            data_a = results_df[(results_df['scenario'] == scenario) & (results_df['treatment'] == v_a)][metric]\n",
    "            data_b = results_df[(results_df['scenario'] == scenario) & (results_df['treatment'] == v_b)][metric]\n",
    "            \n",
    "            # Realiza o teste\n",
    "            if len(data_a) > 1 and len(data_b) > 1:\n",
    "                stat, p_value = stats.mannwhitneyu(data_a, data_b, alternative='two-sided')\n",
    "                \n",
    "                statistical_results.append({\n",
    "                    'scenario': scenario,\n",
    "                    'metric': metric,\n",
    "                    'comparison': f'{v_a} vs {v_b}',\n",
    "                    'statistic': stat,\n",
    "                    'p_value': p_value,\n",
    "                    'significant_at_5%': 'Sim' if p_value < 0.05 else 'Não'\n",
    "                })\n",
    "\n",
    "# Cria um DataFrame com os resultados estatísticos\n",
    "stats_df = pd.DataFrame(statistical_results)\n",
    "\n",
    "print(\"Resultados da Análise Estatística (Mann-Whitney U):\")\n",
    "with pd.option_context('display.max_rows', None): # Mostra todas as linhas\n",
    "    display(stats_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3259a7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico de Barras: Taxa de Sucesso Média por Cenário\n",
    "for scenario in results_df['scenario'].unique():\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    \n",
    "    sns.barplot(\n",
    "        data=grouped_analysis[grouped_analysis['scenario'] == scenario],\n",
    "        x='treatment',\n",
    "        y='avg_success_rate',\n",
    "        order=[f'v{i}' for i in range(1, 5)] # Garante a ordem v1, v2, v3, v4\n",
    "    )\n",
    "    \n",
    "    plt.title(f'Taxa de Sucesso Média - Cenário: {scenario.replace(\"-\", \" \").title()}')\n",
    "    plt.ylabel('Taxa de Sucesso Média')\n",
    "    plt.xlabel('Versão do Serviço')\n",
    "    plt.ylim(0, 1.05) # Limite do eixo y para taxa (0 a 1)\n",
    "    \n",
    "    # Salvar o gráfico\n",
    "    plot_filename = PLOTS_DIR / f'bar_avg_success_rate_{scenario}.png'\n",
    "    plt.savefig(plot_filename, dpi=300, bbox_inches='tight')\n",
    "    print(f\"Gráfico salvo em: {plot_filename}\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Box Plot: Distribuição do Tempo de Resposta (p95) por Cenário\n",
    "for scenario in results_df['scenario'].unique():\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    \n",
    "    sns.boxplot(\n",
    "        data=results_df[results_df['scenario'] == scenario],\n",
    "        x='treatment',\n",
    "        y='p95_duration_ms',\n",
    "        order=[f'v{i}' for i in range(1, 5)]\n",
    "    )\n",
    "    \n",
    "    plt.title(f'Distribuição do Tempo de Resposta (p95) - Cenário: {scenario.replace(\"-\", \" \").title()}')\n",
    "    plt.ylabel('Tempo de Resposta p95 (ms)')\n",
    "    plt.xlabel('Versão do Serviço')\n",
    "    plt.yscale('log') # Usar escala logarítmica pode ajudar a visualizar melhor grandes variações\n",
    "    \n",
    "    # Salvar o gráfico\n",
    "    plot_filename = PLOTS_DIR / f'boxplot_p95_duration_{scenario}.png'\n",
    "    plt.savefig(plot_filename, dpi=300, bbox_inches='tight')\n",
    "    print(f\"Gráfico salvo em: {plot_filename}\")\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cbd8f9",
   "metadata": {},
   "source": [
    "### Seção 5: Visualização de Métricas de Desempenho\n",
    "Crie visualizações para comparar o desempenho entre as diferentes versões em cada cenário. Use gráficos de barras para comparar médias e box plots para visualizar a distribuição dos tempos de resposta (ex: `http_req_duration`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66996c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupa por cenário e tratamento para análise\n",
    "grouped_analysis = results_df.groupby(['scenario', 'treatment']).agg(\n",
    "    avg_success_rate=('success_rate', 'mean'),\n",
    "    std_success_rate=('success_rate', 'std'),\n",
    "    avg_p95_duration=('p95_duration_ms', 'mean'),\n",
    "    std_p95_duration=('p95_duration_ms', 'std'),\n",
    "    avg_duration=('avg_duration_ms', 'mean'),\n",
    "    std_duration=('avg_duration_ms', 'std'),\n",
    "    run_count=('run', 'count')\n",
    ").reset_index()\n",
    "\n",
    "print(\"Análise Agrupada por Cenário e Versão:\")\n",
    "display(grouped_analysis)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5582ca55",
   "metadata": {},
   "source": [
    "### Seção 4: Análise Comparativa por Cenário e Versão\n",
    "Agrupe os dados por cenário e versão. Calcule a média, desvio padrão e outras estatísticas agregadas para as principais métricas de desempenho, como tempo de resposta (média, p(95)) e taxa de falha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a074daac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibe as primeiras linhas para verificação\n",
    "print(\"Dados carregados:\")\n",
    "display(results_df.head())\n",
    "\n",
    "# Informações gerais sobre o DataFrame\n",
    "print(\"\\nInformações do DataFrame:\")\n",
    "results_df.info()\n",
    "\n",
    "# Estatísticas descritivas\n",
    "print(\"\\nEstatísticas Descritivas:\")\n",
    "display(results_df.describe().T)\n",
    "\n",
    "# Verifica dados ausentes\n",
    "print(\"\\nVerificação de Dados Ausentes:\")\n",
    "print(results_df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67418d05",
   "metadata": {},
   "source": [
    "### Seção 3: Análise Exploratória dos Dados (EDA)\n",
    "Exiba as primeiras linhas do DataFrame para verificar o carregamento. Use `.describe()` para obter estatísticas descritivas das métricas numéricas. Verifique se há dados ausentes e realize a limpeza de dados, se necessário."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d261c03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ATENÇÃO: Ajuste o caminho base se o seu notebook não estiver na raiz do projeto.\n",
    "# Como estamos em analysis/analysis_v2.ipynb, subimos um nível para a raiz do projeto.\n",
    "# O WSL usa caminhos no estilo Linux, então o Path funciona bem.\n",
    "BASE_DIR = Path(os.getcwd()).parent\n",
    "EXPERIMENT_DIR = BASE_DIR / 'k6' / 'results' / 'comparative' / 'experiment_20251216_101442'\n",
    "\n",
    "def load_summary_files(experiment_dir: Path) -> pd.DataFrame:\n",
    "    \"\"\"Carrega todos os arquivos *_summary.json do diretório.\"\"\"\n",
    "    records = []\n",
    "    \n",
    "    for f in experiment_dir.glob(\"*_summary.json\"):\n",
    "        filename = f.stem.replace(\"_summary\", \"\")\n",
    "        # Formato: cenario_treatment_runN (cenario pode conter hífens)\n",
    "        match = re.match(r\"^(.+)_(v\\d+)_(run\\d+)$\", filename)\n",
    "        \n",
    "        if match:\n",
    "            scenario = match.group(1)\n",
    "            treatment = match.group(2)\n",
    "            run = int(match.group(3).replace(\"run\", \"\"))\n",
    "            \n",
    "            with open(f) as fp:\n",
    "                data = json.load(fp)\n",
    "            \n",
    "            metrics = data.get(\"metrics\", {})\n",
    "            \n",
    "            # Extrai as métricas de interesse\n",
    "            reqs_metric = metrics.get(\"http_reqs\", {})\n",
    "            failed_metric = metrics.get(\"http_req_failed\", {})\n",
    "            duration_metric = metrics.get(\"http_req_duration\", {})\n",
    "            iterations_metric = metrics.get(\"iterations\", {})\n",
    "\n",
    "            record = {\n",
    "                \"scenario\": scenario,\n",
    "                \"treatment\": treatment,\n",
    "                \"run\": run,\n",
    "                \"total_requests\": reqs_metric.get(\"count\", 0),\n",
    "                \"fail_rate\": failed_metric.get(\"rate\", 0),\n",
    "                \"avg_duration_ms\": duration_metric.get(\"avg\", 0),\n",
    "                \"p95_duration_ms\": duration_metric.get(\"p(95)\", 0),\n",
    "                \"p99_duration_ms\": duration_metric.get(\"p(99)\", 0),\n",
    "                \"iterations\": iterations_metric.get(\"count\", 0),\n",
    "            }\n",
    "            records.append(record)\n",
    "    \n",
    "    df = pd.DataFrame(records)\n",
    "    # Adiciona a taxa de sucesso para facilitar a análise\n",
    "    if not df.empty:\n",
    "        df['success_rate'] = 1 - df['fail_rate']\n",
    "        \n",
    "    return df\n",
    "\n",
    "# Carrega os dados\n",
    "results_df = load_summary_files(EXPERIMENT_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d49db2",
   "metadata": {},
   "source": [
    "### Seção 2: Carregamento e Pré-processamento dos Dados\n",
    "Defina o caminho para a pasta de resultados, considerando o ambiente WSL. Crie uma função para percorrer os diretórios, ler os arquivos JSON de sumário (`_summary.json`), extrair métricas chave (como `http_req_duration`, `http_req_failed`, `iterations`) e informações dos nomes dos arquivos (cenário, versão, execução). Consolide tudo em um único DataFrame do Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e507ed25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import plotly.express as px\n",
    "\n",
    "# Configurações de visualização\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5e4492",
   "metadata": {},
   "source": [
    "### Seção 1: Configuração do Ambiente e Importação de Bibliotecas\n",
    "Importe as bibliotecas necessárias para a análise, como pandas, os, json, matplotlib e seaborn. Defina as configurações iniciais para os gráficos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466882a0",
   "metadata": {},
   "source": [
    "# Análise Comparativa de Performance - Versão 2.0.0\n",
    "\n",
    "Este notebook realiza a análise dos dados de performance coletados via k6. O processo inclui carregamento de dados, análise estatística, visualização e exportação de resultados.\n",
    "\n",
    "**Diretório de dados**: `k6/results/comparative/experiment_20251216_101442`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c95c49",
   "metadata": {},
   "source": [
    "### Seção 9: Conclusão\n",
    "\n",
    "Resuma os principais achados da análise.\n",
    "Destaque quais versões tiveram melhor desempenho em quais cenários, com base nas evidências estatísticas e visuais.\n",
    "Aponte observações importantes (ex: onde o Circuit Breaker foi mais eficaz)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
