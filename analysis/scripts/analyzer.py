import os
import json
import time
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from jinja2 import Template
from scipy import stats
from datetime import datetime
import warnings

warnings.filterwarnings('ignore')

# Import do loader otimizado
try:
    from fast_loader import FastK6Loader, fast_bootstrap_ci, fast_cliffs_delta
    USE_FAST_LOADER = True
except ImportError:
    USE_FAST_LOADER = False
    print("‚ö†Ô∏è  fast_loader n√£o encontrado. Usando carregamento padr√£o.")

# --- Configura√ß√µes ---
RESULTS_DIR = "k6/results"
OUTPUT_DIR = "analysis_results"
PLOTS_DIR = os.path.join(OUTPUT_DIR, "plots")
CSV_DIR = os.path.join(OUTPUT_DIR, "csv")
LATEX_DIR = os.path.join(OUTPUT_DIR, "latex")
MARKDOWN_DIR = os.path.join(OUTPUT_DIR, "markdown")

# --- Cores e Estilos para Gr√°ficos ---
PALETTE = {"V1": "#d62728", "V2": "#2ca02c", "V3": "#1f77b4", "V4": "#ff7f0e"}
sns.set_style("whitegrid")

class K6Analyzer:
    """
    Analisa os resultados de testes de carga do k6, gera gr√°ficos e um relat√≥rio HTML.
    """
    def __init__(self, results_dir, output_dir):
        self.results_dir = results_dir
        self.output_dir = output_dir
        self.plots_dir = os.path.join(output_dir, "plots")
        self.csv_dir = os.path.join(output_dir, "csv")
        self.latex_dir = os.path.join(output_dir, "latex")
        self.markdown_dir = os.path.join(output_dir, "markdown")
        self.data = {}
        self.response_times = {}  # Para an√°lise estat√≠stica

        # Cria diret√≥rios de sa√≠da se n√£o existirem
        os.makedirs(self.plots_dir, exist_ok=True)
        os.makedirs(self.csv_dir, exist_ok=True)
        os.makedirs(self.latex_dir, exist_ok=True)
        os.makedirs(self.markdown_dir, exist_ok=True)

    def load_data(self, max_sample_size=500000, versions=None):
        """
        Carrega os dados dos arquivos de resultado do k6 (JSON) de forma eficiente.
        
        Args:
            max_sample_size: N√∫mero m√°ximo de pontos a carregar por vers√£o (default: 500k)
            versions: Lista de vers√µes a carregar (default: V1, V2, V3, V4)
        """
        versions = versions or ["V1", "V2", "V3", "V4"]
        import gc
        
        start_time = time.time()
        print("\n" + "="*60)
        print("  CARREGAMENTO DE DADOS")
        print("="*60)
        
        if USE_FAST_LOADER:
            print("üöÄ Usando FastK6Loader (otimizado)")
            loader = FastK6Loader(
                results_dir=self.results_dir,
                use_cache=True
            )
            self.data = loader.load_all_versions(
                max_sample_size=max_sample_size,
                versions=versions
            )
        else:
            print("‚ö†Ô∏è  Usando carregamento padr√£o (mais lento)")
            self._load_data_legacy(max_sample_size, versions)
        
        elapsed = time.time() - start_time
        print(f"\n‚è±Ô∏è  Tempo de carregamento: {elapsed:.2f}s")
        print("="*60 + "\n")
        
        gc.collect()
    
    def _load_data_legacy(self, max_sample_size=500000, versions=None):
        """
        Carregamento legado para fallback quando FastK6Loader n√£o est√° dispon√≠vel.
        """
        versions = versions or ["V1", "V2", "V3", "V4"]
        import random
        
        print("Carregando dados dos resultados do k6 (modo legado)...")
        for version in versions:
            file_path = os.path.join(self.results_dir, f"{version}_Completo.json")
            if os.path.exists(file_path):
                file_size_mb = os.path.getsize(file_path) / (1024 * 1024)
                print(f"  {version}: arquivo tem {file_size_mb:.1f} MB")
                
                use_sampling = file_size_mb > 100
                
                if use_sampling:
                    print(f"  {version}: usando amostragem (m√°x. {max_sample_size:,} pontos)...")
                    all_points = []
                    line_count = 0
                    
                    with open(file_path, 'r') as f:
                        for line in f:
                            if '"type":"Point"' in line:
                                line_count += 1
                                try:
                                    m = json.loads(line)
                                    point_data = m['data']
                                    point_data['metric'] = m['metric']
                                    
                                    if len(all_points) < max_sample_size:
                                        all_points.append(point_data)
                                    else:
                                        j = random.randint(0, line_count - 1)
                                        if j < max_sample_size:
                                            all_points[j] = point_data
                                except json.JSONDecodeError:
                                    continue
                    
                    print(f"  {version}: processadas {line_count:,} linhas, amostradas {len(all_points):,}")
                else:
                    all_points = []
                    with open(file_path, 'r') as f:
                        for line in f:
                            if '"type":"Point"' in line:
                                try:
                                    m = json.loads(line)
                                    point_data = m['data']
                                    point_data['metric'] = m['metric']
                                    all_points.append(point_data)
                                except json.JSONDecodeError:
                                    continue
                
                if all_points:
                    self.data[version] = pd.DataFrame(all_points)
                    print(f"Dados de {version} carregados com sucesso ({len(all_points):,} pontos).")
                else:
                    print(f"Aviso: Nenhum ponto de m√©trica encontrado para {version}")
            else:
                print(f"Aviso: Arquivo de resultado para {version} n√£o encontrado")

    def process_data(self):
        """
        Processa os dados brutos para extrair e calcular m√©tricas chave,
        diferenciando sucesso, fallback e falha.
        
        V1: N√£o tem Circuit Breaker
            - 200: Sucesso
            - 5xx: Falhas diretas da API
        
        V2: Com Circuit Breaker
            - 200: Sucesso
            - 500: Falha da API (aciona fallback, conta para abrir CB)
            - 503: Circuit Breaker aberto
            - 202: Conting√™ncia (n√£o usado neste cen√°rio)
        """
        print("Processando e agregando dados...")
        processed_data = []
        for version, df in self.data.items():
            if 'tags' not in df.columns:
                print(f"Aviso: Coluna 'tags' n√£o encontrada para a vers√£o {version}. Pulando.")
                continue

            # Normaliza o status para string para evitar compara√ß√µes problem√°ticas
            df['status'] = df['tags'].apply(lambda x: str(x.get('status')) if isinstance(x, dict) and x.get('status') is not None else None)

            req_duration_df = df[df['metric'] == 'http_req_duration']
            http_reqs_df = df[df['metric'] == 'http_reqs']
            
            # Contagem por c√≥digo de status
            success_count = http_reqs_df[http_reqs_df['status'] == '200']['value'].sum()
            fallback_count = http_reqs_df[http_reqs_df['status'] == '202']['value'].sum()
            cb_open_count = http_reqs_df[http_reqs_df['status'] == '503']['value'].sum()
            
            # Falhas da API (status 500)
            # V1: Todas as falhas 5xx s√£o falhas diretas (n√£o tem CB)
            # V2: Status 500 = falha que aciona fallback e conta para abrir CB
            #     Status 503 = CB j√° est√° aberto (contabilizado separadamente)
            failure_count = http_reqs_df[http_reqs_df['status'] == '500']['value'].sum()

            # Total real de requisi√ß√µes registrado pelo http_reqs (evita omitir c√≥digos inesperados)
            total_requests = http_reqs_df['value'].sum()
            
            # Debug: mostrar contagens brutas
            print(f"\n{version} - Contagens brutas:")
            print(f"  Status 200 (Sucesso): {success_count}")
            print(f"  Status 500 (Falha API): {failure_count}")
            print(f"  Status 503 (CB Aberto): {cb_open_count}")
            print(f"  Status 202 (Conting√™ncia): {fallback_count}")
            print(f"  Total: {total_requests}")

            summary = {
                "Version": version,
                "Total Requests": total_requests,
                "Avg Response Time (ms)": req_duration_df['value'].mean(),
                "P95 Response Time (ms)": req_duration_df['value'].quantile(0.95),
                "Success Rate (%)": (success_count / total_requests) * 100 if total_requests > 0 else 0,
                "Fallback Rate (%)": (fallback_count / total_requests) * 100 if total_requests > 0 else 0,
                "Circuit Breaker Open Rate (%)": (cb_open_count / total_requests) * 100 if total_requests > 0 else 0,
                "API Failure Rate (%)": (failure_count / total_requests) * 100 if total_requests > 0 else 0,
            }
            processed_data.append(summary)
            
        self.summary_df = pd.DataFrame(processed_data)
        self.summary_df.to_csv(os.path.join(self.csv_dir, "summary_analysis.csv"), index=False)
        print("Dados processados e salvos em CSV.")
        print(f"\nResumo das contagens:")
        for idx, row in self.summary_df.iterrows():
            print(f"\n{row['Version']}:")
            print(f"  - Total: {row['Total Requests']:.0f}")
            print(f"  - Sucesso (200): {row['Success Rate (%)']:.2f}%")
            print(f"  - Falhas API (500): {row['API Failure Rate (%)']:.2f}%")
            print(f"  - CB Aberto (503): {row['Circuit Breaker Open Rate (%)']:.2f}%")
            print(f"  - Conting√™ncia (202): {row['Fallback Rate (%)']:.2f}%")

    def generate_plots(self):
        """
        Gera gr√°ficos comparativos a partir dos dados processados.
        """
        print("Gerando gr√°ficos comparativos...")

        # Gr√°fico 1: Tempo de Resposta (M√©dio e P95)
        plt.figure(figsize=(12, 7))
        colors = [PALETTE.get(v, '#333333') for v in self.summary_df['Version'].tolist()]
        self.summary_df.plot(
            kind='bar',
            x='Version',
            y=['Avg Response Time (ms)', 'P95 Response Time (ms)'],
            color=colors,
            title="Tempo de Resposta: Comparacao de Versoes"
        )
        plt.ylabel("Tempo (ms)")
        plt.xticks(rotation=0)
        plt.tight_layout()
        plt.savefig(os.path.join(self.plots_dir, "response_times.png"))
        plt.close()

        # Gr√°fico 2: Taxa de Sucesso vs Falha vs Fallback
        plt.figure(figsize=(12, 7))
        plot_df = self.summary_df.set_index('Version')[['Success Rate (%)', 'Fallback Rate (%)', 'Circuit Breaker Open Rate (%)', 'API Failure Rate (%)']]
        plot_df.plot(
            kind='bar', 
            stacked=True, 
            color={
                "Success Rate (%)": "#2ca02c", 
                "Fallback Rate (%)": "#ff7f0e", 
                "Circuit Breaker Open Rate (%)": "#f0f000", # Amarelo para CB Aberto
                "API Failure Rate (%)": "#d62728"
            },
            title="Composi√ß√£o das Respostas: Sucesso, Fallback e Falha"
        )
        plt.ylabel("Percentual (%)")
        plt.xticks(rotation=0)
        plt.tight_layout()
        plt.savefig(os.path.join(self.plots_dir, "success_failure_rate.png"))
        plt.close()
        
        print("Gr√°ficos gerados com sucesso.")

    def generate_html_report(self):
        """
        Gera um relat√≥rio HTML consolidado com os resultados e gr√°ficos.
        """
        print("Gerando relat√≥rio HTML...")
        template_str = """
        <!DOCTYPE html>
        <html lang="pt-BR">
        <head>
            <meta charset="UTF-8">
            <title>Relat√≥rio de An√°lise de Performance</title>
            <style>
                body { font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; margin: 40px; background-color: #f9f9f9; color: #333; }
                .container { max-width: 1200px; margin: 0 auto; background-color: #fff; padding: 30px; box-shadow: 0 0 15px rgba(0,0,0,0.1); }
                h1, h2 { color: #0056b3; border-bottom: 2px solid #0056b3; padding-bottom: 10px; }
                table { border-collapse: collapse; width: 100%; margin: 25px 0; }
                th, td { border: 1px solid #ddd; padding: 12px; text-align: left; }
                th { background-color: #007bff; color: white; }
                tr:nth-child(even) { background-color: #f2f2f2; }
                .section { margin: 40px 0; }
                img { max-width: 100%; height: auto; margin: 20px 0; border: 1px solid #ddd; border-radius: 5px; }
            </style>
        </head>
        <body>
            <div class="container">
                <h1>Relat√≥rio de An√°lise de Performance: V1, V2, V3 e V4</h1>
                
                <div class="section">
                    <h2>Resumo das M√©tricas</h2>
                    <p>Esta tabela resume as principais m√©tricas de performance para cada vers√£o do servi√ßo.</p>
                    {{ summary_table }}
                </div>
                
                <div class="section">
                    <h2>Gr√°ficos Comparativos</h2>
                    <h3>Tempo de Resposta (M√©dio e P95)</h3>
                    <img src="plots/response_times.png" alt="Gr√°fico de Tempo de Resposta">
                    
                    <h3>Composi√ß√£o das Respostas: Sucesso, Fallback e Falha</h3>
                    <img src="plots/success_failure_rate.png" alt="Gr√°fico de Composi√ß√£o das Respostas">
                </div>
            </div>
        </body>
        </html>
        """
        
        template = Template(template_str)
        html_content = template.render(
            summary_table=self.summary_df.to_html(index=False, classes='table table-striped')
        )
        
        report_path = os.path.join(self.output_dir, "analysis_report.html")
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(html_content)
        print(f"Relat√≥rio HTML gerado em: {report_path}")

    def plot_timeline(self, window_size='5s'):
        """
        Gera gr√°ficos de s√©rie temporal para an√°lise do comportamento ao longo do teste.
        Permite identificar padr√µes de degrada√ß√£o, recupera√ß√£o e transi√ß√µes do CB.
        
        Args:
            window_size: Janela de agrega√ß√£o para suaviza√ß√£o (ex: '5s', '10s', '30s')
        """
        print(f"Gerando an√°lise de s√©ries temporais (janela: {window_size})...")
        
        for version, df in self.data.items():
            if 'time' not in df.columns:
                print(f"Aviso: Coluna 'time' n√£o encontrada para {version}. Pulando s√©rie temporal.")
                continue
            
            # Converte timestamp para datetime
            df_timeline = df.copy()
            df_timeline['timestamp'] = pd.to_datetime(df_timeline['time'])
            df_timeline = df_timeline.set_index('timestamp')
            
            # Filtra apenas m√©tricas de dura√ß√£o de requisi√ß√£o
            req_duration = df_timeline[df_timeline['metric'] == 'http_req_duration']
            
            if req_duration.empty:
                print(f"Aviso: Nenhuma m√©trica de dura√ß√£o encontrada para {version}.")
                continue
            
            # Armazena para an√°lise estat√≠stica
            self.response_times[version] = req_duration['value'].values
            
            # Agrega por janela de tempo
            resampled = req_duration['value'].resample(window_size).agg(['mean', 'median', 'std', 'count'])
            resampled.columns = ['M√©dia', 'Mediana', 'Desvio Padr√£o', 'Contagem']
            
            # Calcula percentis m√≥veis
            resampled['P95'] = req_duration['value'].resample(window_size).quantile(0.95)
            resampled['P99'] = req_duration['value'].resample(window_size).quantile(0.99)
            
            # Plot 1: Tempo de resposta ao longo do tempo
            fig, axes = plt.subplots(3, 1, figsize=(14, 12), sharex=True)
            
            # Subplot 1: M√©dia e Percentis
            ax1 = axes[0]
            ax1.plot(resampled.index, resampled['M√©dia'], label='M√©dia', color=PALETTE[version], linewidth=2)
            ax1.fill_between(resampled.index, 
                            resampled['M√©dia'] - resampled['Desvio Padr√£o'],
                            resampled['M√©dia'] + resampled['Desvio Padr√£o'],
                            alpha=0.3, color=PALETTE[version], label='¬±1 Desvio Padr√£o')
            ax1.plot(resampled.index, resampled['P95'], '--', label='P95', color='orange', linewidth=1.5)
            ax1.plot(resampled.index, resampled['P99'], ':', label='P99', color='red', linewidth=1.5)
            ax1.set_ylabel('Tempo de Resposta (ms)')
            ax1.set_title(f'{version} - Tempo de Resposta ao Longo do Teste')
            ax1.legend(loc='upper right')
            ax1.grid(True, alpha=0.3)
            
            # Subplot 2: Throughput (requisi√ß√µes por janela)
            ax2 = axes[1]
            ax2.bar(resampled.index, resampled['Contagem'], width=pd.Timedelta(window_size)*0.8,
                   color=PALETTE[version], alpha=0.7, label='Requisi√ß√µes')
            ax2.set_ylabel('Requisi√ß√µes por Janela')
            ax2.set_title(f'{version} - Throughput')
            ax2.grid(True, alpha=0.3)
            
            # Subplot 3: Taxa de Sucesso por janela (se dispon√≠vel)
            ax3 = axes[2]
            http_reqs = df_timeline[df_timeline['metric'] == 'http_reqs'].copy()
            if not http_reqs.empty and 'tags' in http_reqs.columns:
                http_reqs['status'] = http_reqs['tags'].apply(
                    lambda x: str(x.get('status')) if isinstance(x, dict) and x.get('status') else None
                )
                success_rate = http_reqs.groupby([pd.Grouper(freq=window_size), 'status'])['value'].sum().unstack(fill_value=0)
                
                if '200' in success_rate.columns:
                    total_per_window = success_rate.sum(axis=1)
                    success_pct = (success_rate.get('200', 0) / total_per_window * 100).fillna(0)
                    ax3.plot(success_pct.index, success_pct.values, color=PALETTE[version], linewidth=2)
                    ax3.axhline(y=95, color='green', linestyle='--', alpha=0.5, label='SLA 95%')
                    ax3.axhline(y=99, color='blue', linestyle=':', alpha=0.5, label='SLA 99%')
                    ax3.fill_between(success_pct.index, success_pct.values, alpha=0.3, color=PALETTE[version])
            
            ax3.set_ylabel('Taxa de Sucesso (%)')
            ax3.set_xlabel('Tempo')
            ax3.set_title(f'{version} - Taxa de Sucesso')
            ax3.set_ylim(0, 105)
            ax3.legend(loc='lower right')
            ax3.grid(True, alpha=0.3)
            
            plt.tight_layout()
            plt.savefig(os.path.join(self.plots_dir, f"timeline_{version}.png"), dpi=150)
            plt.close()
            
            # Salva dados da s√©rie temporal
            resampled.to_csv(os.path.join(self.csv_dir, f"timeline_{version}.csv"))
        
        # Gera plot comparativo V1 vs V2
        self._plot_comparative_timeline(window_size)
        
        print("An√°lise de s√©ries temporais conclu√≠da.")

    def _plot_comparative_timeline(self, window_size='5s'):
        """
        Gera gr√°fico comparativo de V1 vs V2 ao longo do tempo.
        """
        fig, axes = plt.subplots(2, 1, figsize=(14, 10), sharex=True)
        
        for version, df in self.data.items():
            if 'time' not in df.columns:
                continue
            
            df_timeline = df.copy()
            df_timeline['timestamp'] = pd.to_datetime(df_timeline['time'])
            df_timeline = df_timeline.set_index('timestamp')
            
            req_duration = df_timeline[df_timeline['metric'] == 'http_req_duration']
            if req_duration.empty:
                continue
            
            resampled = req_duration['value'].resample(window_size).agg(['mean', 'median'])
            
            # Plot m√©dia
            axes[0].plot(resampled.index, resampled['mean'], label=f'{version} - M√©dia', 
                        color=PALETTE[version], linewidth=2)
            axes[1].plot(resampled.index, resampled['median'], label=f'{version} - Mediana', 
                        color=PALETTE[version], linewidth=2)
        
        axes[0].set_ylabel('Tempo M√©dio (ms)')
        axes[0].set_title('Compara√ß√£o V1 vs V2 - Tempo de Resposta M√©dio')
        axes[0].legend()
        axes[0].grid(True, alpha=0.3)
        
        axes[1].set_ylabel('Tempo Mediano (ms)')
        axes[1].set_xlabel('Tempo')
        axes[1].set_title('Compara√ß√£o V1 vs V2 - Tempo de Resposta Mediano')
        axes[1].legend()
        axes[1].grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(os.path.join(self.plots_dir, "timeline_comparison.png"), dpi=150)
        plt.close()

    def statistical_analysis(self):
        """
        Realiza an√°lise estat√≠stica robusta incluindo:
        - Teste de Mann-Whitney U (diferen√ßa significativa entre V1 e V2)
        - Teste de Kolmogorov-Smirnov (diferen√ßa nas distribui√ß√µes)
        - Effect Size (Cliff's Delta)
        - Intervalos de confian√ßa bootstrap
        """
        print("Realizando an√°lise estat√≠stica robusta...")
        
        # Garante que temos os dados de tempo de resposta
        if not self.response_times:
            for version, df in self.data.items():
                if 'time' in df.columns:
                    req_duration = df[df['metric'] == 'http_req_duration']
                    self.response_times[version] = req_duration['value'].values
        
        if 'V1' not in self.response_times or 'V2' not in self.response_times:
            print("Aviso: Dados insuficientes para an√°lise estat√≠stica comparativa.")
            return
        
        v1_times = self.response_times['V1']
        v2_times = self.response_times['V2']
        
        # Teste de Mann-Whitney U (n√£o param√©trico)
        statistic_mw, p_value_mw = stats.mannwhitneyu(v1_times, v2_times, alternative='two-sided')
        
        # Teste de Kolmogorov-Smirnov
        statistic_ks, p_value_ks = stats.ks_2samp(v1_times, v2_times)
        
        # Effect Size: Cliff's Delta
        cliffs_delta = self._cliffs_delta(v1_times, v2_times)
        
        # Bootstrap para intervalo de confian√ßa da diferen√ßa de m√©dias
        ci_low, ci_high = self._bootstrap_ci(v1_times, v2_times, n_bootstrap=10000)
        
        # Estat√≠sticas descritivas
        stats_results = {
            'M√©trica': [
                'N (V1)', 'N (V2)',
                'M√©dia (V1)', 'M√©dia (V2)',
                'Mediana (V1)', 'Mediana (V2)',
                'Desvio Padr√£o (V1)', 'Desvio Padr√£o (V2)',
                'P95 (V1)', 'P95 (V2)',
                'P99 (V1)', 'P99 (V2)',
                'Mann-Whitney U', 'p-valor (MW)',
                'Kolmogorov-Smirnov', 'p-valor (KS)',
                "Cliff's Delta", 'Interpreta√ß√£o Effect Size',
                'IC 95% Diferen√ßa (baixo)', 'IC 95% Diferen√ßa (alto)',
                'Diferen√ßa Significativa (Œ±=0.05)'
            ],
            'Valor': [
                len(v1_times), len(v2_times),
                f'{np.mean(v1_times):.2f} ms', f'{np.mean(v2_times):.2f} ms',
                f'{np.median(v1_times):.2f} ms', f'{np.median(v2_times):.2f} ms',
                f'{np.std(v1_times):.2f} ms', f'{np.std(v2_times):.2f} ms',
                f'{np.percentile(v1_times, 95):.2f} ms', f'{np.percentile(v2_times, 95):.2f} ms',
                f'{np.percentile(v1_times, 99):.2f} ms', f'{np.percentile(v2_times, 99):.2f} ms',
                f'{statistic_mw:.2f}', f'{p_value_mw:.2e}',
                f'{statistic_ks:.4f}', f'{p_value_ks:.2e}',
                f'{cliffs_delta:.4f}', self._interpret_cliffs_delta(cliffs_delta),
                f'{ci_low:.2f} ms', f'{ci_high:.2f} ms',
                'Sim' if p_value_mw < 0.05 else 'N√£o'
            ]
        }
        
        self.stats_df = pd.DataFrame(stats_results)
        self.stats_df.to_csv(os.path.join(self.csv_dir, "statistical_analysis.csv"), index=False)
        
        # Gera visualiza√ß√£o das distribui√ß√µes
        self._plot_distributions(self.response_times)
        
        print(f"\n=== Resultados da An√°lise Estat√≠stica ===")
        print(f"Mann-Whitney U (V1 vs V2): {statistic_mw:.2f}, p-valor: {p_value_mw:.2e}")
        print(f"Cliff's Delta (V1 vs V2): {cliffs_delta:.4f} ({self._interpret_cliffs_delta(cliffs_delta)})")
        print(f"IC 95% da diferen√ßa de m√©dias (V1 vs V2): [{ci_low:.2f}, {ci_high:.2f}] ms")
        print(f"Diferen√ßa estatisticamente significativa (V1 vs V2): {'Sim' if p_value_mw < 0.05 else 'N√£o'}")
        
        return self.stats_df

    def _cliffs_delta(self, x, y):
        """
        Calcula Cliff's Delta - medida de effect size n√£o param√©trica.
        Usa vers√£o vetorizada quando FastK6Loader est√° dispon√≠vel.
        
        Valores: [-1, 1], onde:
        - |d| < 0.147: neglig√≠vel
        - |d| < 0.33: pequeno
        - |d| < 0.474: m√©dio
        - |d| >= 0.474: grande
        """
        if USE_FAST_LOADER:
            return fast_cliffs_delta(x, y)
        
        # Fallback para implementa√ß√£o legada
        n_x, n_y = len(x), len(y)
        more = np.sum([np.sum(xi > y) for xi in x])
        less = np.sum([np.sum(xi < y) for xi in x])
        return (more - less) / (n_x * n_y)

    def _interpret_cliffs_delta(self, d):
        """Interpreta o valor de Cliff's Delta."""
        abs_d = abs(d)
        if abs_d < 0.147:
            return "Neglig√≠vel"
        elif abs_d < 0.33:
            return "Pequeno"
        elif abs_d < 0.474:
            return "M√©dio"
        else:
            return "Grande"

    def _bootstrap_ci(self, x, y, n_bootstrap=10000, ci=0.95):
        """
        Calcula intervalo de confian√ßa bootstrap para a diferen√ßa de m√©dias.
        Usa vers√£o vetorizada quando FastK6Loader est√° dispon√≠vel (~10x mais r√°pido).
        """
        if USE_FAST_LOADER:
            return fast_bootstrap_ci(x, y, n_bootstrap=n_bootstrap, ci=ci)
        
        # Fallback para implementa√ß√£o legada
        np.random.seed(42)
        diff_means = []
        for _ in range(n_bootstrap):
            x_sample = np.random.choice(x, size=len(x), replace=True)
            y_sample = np.random.choice(y, size=len(y), replace=True)
            diff_means.append(np.mean(x_sample) - np.mean(y_sample))
        
        alpha = 1 - ci
        lower = np.percentile(diff_means, alpha / 2 * 100)
        upper = np.percentile(diff_means, (1 - alpha / 2) * 100)
        return lower, upper

    def _plot_distributions(self, times_dict):
        """
        Gera visualiza√ß√µes das distribui√ß√µes de tempo de resposta para todas as vers√µes.
        """
        fig, axes = plt.subplots(2, 2, figsize=(14, 10))
        versions = sorted(times_dict.keys())
        
        # Histograma comparativo
        ax1 = axes[0, 0]
        for version in versions:
            ax1.hist(times_dict[version], bins=50, alpha=0.5, label=version, 
                    color=PALETTE.get(version, '#333'), density=True)
        ax1.set_xlabel('Tempo de Resposta (ms)')
        ax1.set_ylabel('Densidade')
        ax1.set_title('Distribui√ß√£o de Tempos de Resposta')
        ax1.legend()
        
        # Box plot
        ax2 = axes[0, 1]
        data_bp = [times_dict[v] for v in versions]
        bp = ax2.boxplot(data_bp, labels=versions, patch_artist=True)
        for i, version in enumerate(versions):
            bp['boxes'][i].set_facecolor(PALETTE.get(version, '#333'))
            bp['boxes'][i].set_alpha(0.7)
        ax2.set_ylabel('Tempo de Resposta (ms)')
        ax2.set_title('Box Plot Comparativo')
        
        # Violin plot
        ax3 = axes[1, 0]
        positions = np.arange(1, len(versions) + 1)
        parts = ax3.violinplot(data_bp, positions=positions, showmeans=True, showmedians=True)
        for i, (version, pc) in enumerate(zip(versions, parts['bodies'])):
            pc.set_facecolor(PALETTE.get(version, '#333'))
            pc.set_alpha(0.7)
        ax3.set_xticks(positions)
        ax3.set_xticklabels(versions)
        ax3.set_ylabel('Tempo de Resposta (ms)')
        ax3.set_title('Violin Plot - Distribui√ß√£o Completa')
        
        # ECDF
        ax4 = axes[1, 1]
        for version in versions:
            sorted_times = np.sort(times_dict[version])
            ax4.plot(sorted_times, np.arange(1, len(sorted_times)+1) / len(sorted_times), 
                    label=version, color=PALETTE.get(version, '#333'), linewidth=2)
        ax4.set_xlabel('Tempo de Resposta (ms)')
        ax4.set_ylabel('Propor√ß√£o Cumulativa')
        ax4.set_title('ECDF - Distribui√ß√£o Cumulativa Emp√≠rica')
        ax4.legend()
        ax4.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(os.path.join(self.plots_dir, "distributions.png"), dpi=150)
        plt.close()

    def export_latex(self):
        """
        Exporta tabelas e resultados para formato LaTeX para inclus√£o direta no TCC.
        """
        print("Exportando resultados para LaTeX...")
        
        # Tabela de resumo principal
        if hasattr(self, 'summary_df'):
            latex_summary = self.summary_df.to_latex(
                index=False,
                caption="Resumo das M√©tricas de Performance: V1 vs V2",
                label="tab:metricas-performance",
                column_format='l' + 'r' * (len(self.summary_df.columns) - 1),
                float_format="%.2f",
                escape=True
            )
            
            with open(os.path.join(self.latex_dir, "tabela_resumo.tex"), 'w') as f:
                f.write(latex_summary)
        
        # Tabela de an√°lise estat√≠stica
        if hasattr(self, 'stats_df'):
            latex_stats = self.stats_df.to_latex(
                index=False,
                caption="An√°lise Estat√≠stica Comparativa entre V1 e V2",
                label="tab:analise-estatistica",
                column_format='lr',
                escape=True
            )
            
            with open(os.path.join(self.latex_dir, "tabela_estatistica.tex"), 'w') as f:
                f.write(latex_stats)
        
        # Gera arquivo .tex com figuras
        figures_tex = r"""
% Figuras geradas automaticamente pelo analyzer.py
% Inclua este arquivo no seu documento LaTeX com \input{figuras_analise.tex}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=\textwidth]{analysis_results/plots/response_times.png}
    \caption{Compara√ß√£o de Tempo de Resposta entre V1 (sem Circuit Breaker) e V2 (com Circuit Breaker).}
    \label{fig:response-times}
\end{figure}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=\textwidth]{analysis_results/plots/success_failure_rate.png}
    \caption{Composi√ß√£o das Respostas: Taxa de Sucesso, Fallback e Falha para cada vers√£o.}
    \label{fig:success-failure-rate}
\end{figure}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=\textwidth]{analysis_results/plots/timeline_comparison.png}
    \caption{Evolu√ß√£o temporal do tempo de resposta durante o teste de carga.}
    \label{fig:timeline-comparison}
\end{figure}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=\textwidth]{analysis_results/plots/distributions.png}
    \caption{Distribui√ß√µes estat√≠sticas dos tempos de resposta: (a) Histograma, (b) Box Plot, (c) Violin Plot, (d) ECDF.}
    \label{fig:distributions}
\end{figure}
"""
        with open(os.path.join(self.latex_dir, "figuras_analise.tex"), 'w') as f:
            f.write(figures_tex)
        
        # Gera resumo em Markdown tamb√©m
        self._export_markdown()
        
        print(f"Arquivos LaTeX exportados para: {self.latex_dir}")

    def _export_markdown(self):
        """
        Exporta resultados para Markdown para documenta√ß√£o.
        """
        md_content = f"""# An√°lise de Performance: V1 vs V2

Gerado em: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## Resumo das M√©tricas

"""
        if hasattr(self, 'summary_df'):
            md_content += self.summary_df.to_markdown(index=False)
            md_content += "\n\n"
        
        md_content += "## An√°lise Estat√≠stica\n\n"
        
        if hasattr(self, 'stats_df'):
            md_content += self.stats_df.to_markdown(index=False)
            md_content += "\n\n"
        
        md_content += """## Gr√°ficos Gerados

- `plots/response_times.png`: Tempo de resposta m√©dio e P95
- `plots/success_failure_rate.png`: Composi√ß√£o das respostas
- `plots/timeline_V1.png` / `timeline_V2.png`: S√©ries temporais por vers√£o
- `plots/timeline_comparison.png`: Compara√ß√£o temporal V1 vs V2
- `plots/distributions.png`: An√°lise de distribui√ß√µes

## Interpreta√ß√£o

### Signific√¢ncia Estat√≠stica
- **Mann-Whitney U Test**: Teste n√£o param√©trico para comparar as distribui√ß√µes
- **Cliff's Delta**: Medida de effect size (magnitude da diferen√ßa)
- **Bootstrap CI**: Intervalo de confian√ßa para a diferen√ßa de m√©dias

### Thresholds de Cliff's Delta
| Valor |d| | Interpreta√ß√£o |
|---------|---------------|
| < 0.147 | Neglig√≠vel    |
| < 0.33  | Pequeno       |
| < 0.474 | M√©dio         |
| ‚â• 0.474 | Grande        |
"""
        
        with open(os.path.join(self.markdown_dir, "analise_resultados.md"), 'w') as f:
            f.write(md_content)

    def run_analysis(self, include_timeline=True, include_stats=True, export_latex=True):
        """
        Executa o pipeline completo de an√°lise.
        
        Args:
            include_timeline: Se True, gera an√°lise de s√©ries temporais
            include_stats: Se True, realiza an√°lise estat√≠stica robusta
            export_latex: Se True, exporta resultados para LaTeX
        """
        self.load_data()
        if not self.data:
            print("Nenhum dado foi carregado. Abortando a an√°lise.")
            return
        self.process_data()
        self.generate_plots()
        
        if include_timeline:
            self.plot_timeline(window_size='5s')
        
        if include_stats:
            self.statistical_analysis()
        
        self.generate_html_report()
        
        if export_latex:
            self.export_latex()
        
        print("\nAn√°lise conclu√≠da com sucesso!")

if __name__ == "__main__":
    analyzer = K6Analyzer(results_dir=RESULTS_DIR, output_dir=OUTPUT_DIR)
    analyzer.run_analysis()
