\documentclass{svproc}
\usepackage{url}
\usepackage{graphicx}
\usepackage{listings}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{float}
\usepackage{booktabs}

\def\UrlFont{\rmfamily}

% Definição do ambiente Resumo (português) - para documentos acadêmicos brasileiros
\newenvironment{resumo}{%
\small
\begin{center}%
{\bfseries Resumo\vspace{-.5em}\vspace{\z}}%
\end{center}%
\quotation}%
{\endquotation}

% Definição do comando palavraschave
\providecommand{\palavraschave}[1]{\par\addvspace\baselineskip
\noindent\textbf{Palavras-chave:} #1}

\begin{document}
\mainmatter
\title{Análise de Desempenho e Resiliência em Microsserviços Síncronos: Um Estudo Experimental do Padrão Circuit Breaker}
\titlerunning{Análise de Desempenho e Resiliência em Microsserviços}

\author{Humberto L. A. Fonseca Filho}
\authorrunning{H. L. A. Fonseca Filho}
\tocauthor{Fonseca Filho, H. L. A.}

\institute{Centro de Informática, Universidade Federal de Pernambuco (UFPE) \\
\email{hlaff@cin.ufpe.br}}

\maketitle

\begin{resumo}
Arquiteturas de microsserviços tornaram-se o padrão para construção de sistemas distribuídos escaláveis, porém a comunicação síncrona entre serviços introduz vulnerabilidades críticas: quando uma dependência downstream degrada ou falha, falhas em cascata podem se propagar por todo o sistema, levando à exaustão do pool de threads e indisponibilidade total do serviço. Embora o padrão Circuit Breaker seja amplamente recomendado como estratégia de mitigação, evidências empíricas quantificando sua eficácia em cenários realistas de falha permanecem escassas na literatura. Este trabalho preenche essa lacuna através de um estudo experimental controlado comparando uma arquitetura baseline contra uma protegida por Circuit Breaker (implementado com Resilience4j) em quatro cenários de estresse: falha catastrófica, degradação gradual, rajadas intermitentes e indisponibilidade extrema. Utilizando microsserviços orquestrados via Docker e testes de carga com k6 totalizando mais de 769.000 requisições, foram medidos vazão, latência (p95/p99) e taxas de sucesso. Os resultados demonstram que o Circuit Breaker proporciona ganhos substanciais de resiliência: no cenário de indisponibilidade extrema (75\% de downtime), as taxas de sucesso melhoraram de 10,14\% para 97,08\% (+86,94 pontos percentuais), representando uma redução de 96,77\% nas falhas. Adicionalmente, o tempo médio de resposta reduziu de 735,05ms para 477,60ms (melhoria de 35\%), e a mediana caiu de 160,56ms para 35,69ms (melhoria de 78\%). A análise estatística (teste de Mann-Whitney U, p $<$ 0,001; Cliff's Delta = 0,38 --- efeito médio) confirma diferença significativa entre as versões. Este estudo fornece evidência empírica reprodutível e um framework experimental reutilizável para avaliação de padrões de tolerância a falhas em arquiteturas de microsserviços síncronos.
\palavraschave{Microsserviços, Circuit Breaker, Resiliência, Tolerância a Falhas, Sistemas Distribuídos, Engenharia de Desempenho, Resilience4j}
\end{resumo}

\begin{abstract}
Microservices architectures have become the standard for building scalable distributed systems, yet synchronous inter-service communication introduces critical vulnerabilities: when a downstream dependency degrades or fails, cascading failures can propagate throughout the entire system, leading to thread pool exhaustion and complete service unavailability. While the Circuit Breaker pattern is widely recommended as a mitigation strategy, empirical evidence quantifying its effectiveness under realistic failure scenarios remains scarce in the literature. This work addresses this gap by conducting a controlled experimental study comparing a baseline architecture against one protected by Circuit Breaker (implemented with Resilience4j) across four stress scenarios: catastrophic failure, gradual degradation, intermittent bursts, and extreme unavailability. Using Docker-orchestrated microservices and k6 load testing with over 769,000 total requests, we measured throughput, latency (p95/p99), and success rates. Results demonstrate that the Circuit Breaker delivers substantial resilience gains: in the extreme unavailability scenario (75\% downtime), success rates improved from 10.14\% to 97.08\% (+86.94 percentage points), representing a 96.77\% reduction in failures. Additionally, average response time decreased from 735.05ms to 477.60ms (35\% improvement), and median response time dropped from 160.56ms to 35.69ms (78\% improvement). Statistical analysis (Mann-Whitney U test, p $<$ 0.001; Cliff's Delta = 0.38 --- medium effect size) confirms significant difference between versions. This study provides reproducible empirical evidence and a reusable experimental framework for evaluating fault tolerance patterns in synchronous microservices architectures.
\keywords{Microservices, Circuit Breaker, Resilience, Fault Tolerance, Distributed Systems, Performance Engineering, Resilience4j}
\end{abstract}

\section{Contextualização}
A era dos microsserviços consolidou-se no cenário corporativo. A adoção de arquiteturas de microsserviços tornou-se onipresente em organizações que precisam construir plataformas digitais de grande escala, disponibilidade contínua e ciclos de evolução acelerados. Ecossistemas de comércio eletrônico e, em especial, sistemas de processamento de pagamentos, são exemplos emblemáticos desse movimento, pois demandam flexibilidade para incorporar novos meios de pagamento, tolerância a falhas e capacidade de adaptação rápida a volumes variáveis de transações. O particionamento de funcionalidades em serviços independentes facilita o desenvolvimento paralelo, a escalabilidade seletiva e a implantação contínua. Contudo, essa independência lógica é sustentada por interações em tempo real entre serviços, frequentemente estabelecidas por APIs REST e clientes declarativos como o Spring Cloud OpenFeign. A comunicação síncrona simplifica a implementação e a observabilidade, mas introduz um forte acoplamento temporal: o serviço consumidor permanece bloqueado até que a resposta do serviço dependente seja recebida ou um timeout seja atingido. Esse padrão, quando aplicado a cadeias críticas como autorizações financeiras, amplifica a fragilidade do sistema diante de latências elevadas ou indisponibilidade intermitente na infraestrutura externa.

\section{Definição do Problema}

O risco inerente à comunicação síncrona constitui o cerne desta investigação. O problema investigado neste trabalho — \textbf{falhas em cascata causadas por comunicação síncrona entre microsserviços} — é transversal a diversos domínios da engenharia de software: e-commerce, logística, saúde, fintechs, streaming, IoT, entre outros. Qualquer sistema distribuído que dependa de chamadas HTTP síncronas está sujeito aos riscos aqui analisados.

Este trabalho adota o \textbf{domínio de pagamentos on-line} como contexto experimental. A escolha foi motivada pela relevância do domínio na área de sistemas financeiros, onde a resiliência é requisito crítico e falhas têm impacto direto na receita e experiência do usuário. Contudo, os resultados e conclusões deste estudo são \textbf{generalizáveis} para qualquer arquitetura de microsserviços com dependências síncronas.

\textbf{Cenário Hipotético Modelado:} Um \texttt{servico-pagamento} orquestra a jornada de checkout e depende, de forma síncrona, de um \texttt{servico-adquirente} responsável por encaminhar transações a gateways externos (Cielo, Rede, etc.). O risco emerge quando essa dependência apresenta degradação: se o \texttt{servico-adquirente} experimenta alta latência, o \texttt{servico-pagamento} aguarda até o timeout, mantendo threads bloqueadas. Com volume crescente de requisições, o pool de threads se esgota (\textbf{thread pool starvation}), provocando \textbf{falha em cascata} que interrompe todo o checkout.

\section{Solução Proposta}
Os padrões de resiliência e o Circuit Breaker emergem como resposta aos desafios descritos. Padrões de resiliência, tradicionalmente agrupados sob o guarda-chuva de \textit{fault tolerance}, surgem como contramedidas a essa fragilidade. Entre eles, o padrão Circuit Breaker (CB) destaca-se como um mecanismo sofisticado para conter falhas em cascata. O CB monitora as chamadas ao serviço dependente e opera segundo uma máquina de estados composta por três modos: \textbf{Fechado}, \textbf{Aberto} e \textbf{Semiaberto}. No estado Fechado, o serviço consumidor executa chamadas normalmente e o CB coleta métricas de sucesso e falha. Ao detectar uma taxa de falhas ou tempo de resposta acima de limites configurados, o circuito é \textbf{Aberto}, interrompendo novas tentativas de chamadas e falhando rapidamente (\textit{fail-fast}). Esse comportamento protege o serviço consumidor da exaustão de recursos e evita contribuir para a sobrecarga do serviço dependente. Após um período de resfriamento, o CB entra no estado \textbf{Semiaberto}, permitindo um número controlado de chamadas de teste. Se elas forem bem-sucedidas, o circuito retorna ao estado Fechado; caso contrário, reabre. Além disso, é comum empregar mecanismos de \textit{fallback} para entregar respostas degradadas, mas ainda úteis, enquanto o serviço dependente se recupera. Dessa forma, o Circuit Breaker harmoniza a necessidade de disponibilidade do consumidor com a estabilidade do ecossistema.

\section{Fundamentação Teórica}

\subsection{Arquitetura de Microsserviços}
A arquitetura de microsserviços representa uma abordagem de desenvolvimento de software que estrutura uma aplicação como um conjunto de serviços pequenos, autônomos e fracamente acoplados \cite{newman2021}. Cada serviço é responsável por uma capacidade de negócio específica, pode ser desenvolvido, implantado e escalado de forma independente, e se comunica com outros serviços através de interfaces bem definidas, geralmente APIs REST ou mensageria assíncrona \cite{fowler2014}.

Os principais benefícios desta arquitetura incluem: (i) \textbf{escalabilidade seletiva}, permitindo escalar apenas os serviços sob maior demanda; (ii) \textbf{autonomia de equipes}, possibilitando que times diferentes desenvolvam e implantem serviços independentemente; (iii) \textbf{resiliência a falhas}, onde a falha de um serviço não necessariamente compromete todo o sistema; e (iv) \textbf{flexibilidade tecnológica}, permitindo que cada serviço utilize a tecnologia mais adequada ao seu propósito \cite{richardson2018}.

Contudo, essa arquitetura introduz desafios significativos de natureza distribuída. A comunicação entre serviços através da rede é inerentemente não confiável, sujeita a latências variáveis, timeouts e falhas parciais. Em sistemas monolíticos, chamadas de função são executadas em memória com latência desprezível; em microsserviços, cada chamada atravessa a rede e pode falhar de múltiplas formas \cite{nygard2018}.

\subsection{Comunicação Síncrona e seus Riscos}
A comunicação síncrona, tipicamente implementada via HTTP/REST, é caracterizada pelo bloqueio do serviço consumidor enquanto aguarda a resposta do serviço provedor. Embora seja simples de implementar e depurar, este modelo introduz um \textbf{acoplamento temporal} entre os serviços: se o provedor estiver lento ou indisponível, o consumidor também será afetado \cite{burns2018}.

Os principais riscos associados à comunicação síncrona incluem:

\begin{itemize}
    \item \textbf{Thread Pool Starvation:} Quando múltiplas requisições aguardam respostas lentas, as threads do servidor ficam bloqueadas, esgotando o pool disponível e impedindo o processamento de novas requisições.
    \item \textbf{Falhas em Cascata:} Uma dependência lenta ou indisponível pode propagar sua condição para todos os serviços que dela dependem, amplificando o impacto de uma falha localizada para todo o ecossistema.
    \item \textbf{Efeito Dominó:} Em cadeias de dependências (A → B → C), a falha de C pode derrubar B e, consequentemente, A, mesmo que estes estejam funcionando corretamente.
\end{itemize}

\subsection{Padrões de Tolerância a Falhas}
Para mitigar os riscos da comunicação distribuída, diversos padrões de tolerância a falhas foram propostos pela comunidade de engenharia de software \cite{nygard2018, richardson2018}:

\textbf{Timeout:} Define um limite máximo de espera por uma resposta. Embora essencial, não é suficiente isoladamente, pois o serviço ainda consome recursos durante a espera.

\textbf{Retry:} Reenvia automaticamente requisições que falharam, útil para falhas transitórias. Deve ser implementado com backoff exponencial para evitar sobrecarga do serviço dependente.

\textbf{Bulkhead:} Isola recursos (threads, conexões) por dependência, impedindo que a falha de uma dependência consuma todos os recursos do serviço.

\textbf{Rate Limiter:} Controla a taxa de requisições enviadas ou recebidas, protegendo serviços de sobrecarga.

\textbf{Circuit Breaker:} Interrompe temporariamente chamadas a uma dependência que apresenta falhas recorrentes, permitindo recuperação e evitando desperdício de recursos.

\subsection{O Padrão Circuit Breaker em Detalhe}
O padrão Circuit Breaker, popularizado por Michael Nygard em seu livro ``Release It!'' \cite{nygard2018} e documentado por Martin Fowler \cite{fowler2014cb}, opera como um disjuntor elétrico: quando detecta condições anormais, ``abre'' para interromper o fluxo e proteger o sistema.

A implementação típica do Circuit Breaker utiliza uma máquina de estados com três estados:

\begin{enumerate}
    \item \textbf{Fechado (Closed):} Estado normal de operação. Todas as requisições são encaminhadas à dependência. O CB monitora continuamente métricas como taxa de falha e tempo de resposta.
    \item \textbf{Aberto (Open):} Ativado quando métricas excedem limiares configurados (ex: >50\% de falhas). Requisições são imediatamente rejeitadas ou redirecionadas a um fallback, sem tentar contactar a dependência. Após um período de espera (\textit{wait duration}), transiciona para Semiaberto.
    \item \textbf{Semiaberto (Half-Open):} Estado de teste. Um número limitado de requisições é permitido para verificar se a dependência se recuperou. Se bem-sucedidas, retorna ao estado Fechado; caso contrário, volta ao estado Aberto.
\end{enumerate}

\subsection{Implementações de Circuit Breaker: Hystrix vs Resilience4j}
O Netflix Hystrix foi pioneiro na implementação do padrão Circuit Breaker para a JVM, sendo amplamente adotado na indústria \cite{hystrix, netflix2016}. Contudo, em 2018, o projeto entrou em modo de manutenção, e o Resilience4j emergiu como seu sucessor recomendado \cite{resilience4j}.

O Resilience4j apresenta vantagens significativas sobre o Hystrix:

\begin{itemize}
    \item \textbf{Design modular:} Cada padrão (Circuit Breaker, Retry, Bulkhead, Rate Limiter, Time Limiter) é um módulo independente que pode ser composto conforme necessário.
    \item \textbf{Menor footprint:} Não requer thread pools separados como o Hystrix, reduzindo consumo de recursos.
    \item \textbf{Suporte a programação funcional:} Integração nativa com lambdas Java 8+, CompletableFuture e frameworks reativos.
    \item \textbf{Métricas nativas:} Exportação de métricas para Prometheus/Micrometer sem configuração adicional.
    \item \textbf{Janela deslizante configurável:} Suporta janelas baseadas em contagem ou tempo para cálculo de métricas.
\end{itemize}

\subsection{Trabalhos Relacionados}
A literatura recente apresenta diversos estudos sobre resiliência em microsserviços. Montesi e Weber \cite{montesi2016} analisam a interação entre Circuit Breakers e API Gateways, propondo padrões de composição. Burns \cite{burns2018} contextualiza padrões de resiliência no design de sistemas distribuídos modernos.

De particular relevância para este trabalho é o estudo de Pinheiro, Dantas et al. \cite{pinheiro2024}, que propõe uma modelagem analítica do comportamento de Circuit Breakers utilizando Redes de Petri Estocásticas (SPNs). Esta abordagem permite prever o impacto de diferentes parametrizações do CB em métricas de SLA antes da implantação em produção. O presente TCC complementa essa contribuição teórica ao fornecer \textbf{validação empírica} dos benefícios do Circuit Breaker através de experimentos controlados em um ambiente realista.

A documentação oficial da Microsoft Azure \cite{microsoftpatterns} apresenta o Circuit Breaker como um dos padrões essenciais para aplicações cloud-native, reforçando sua relevância em arquiteturas modernas de larga escala.

\section{A Lacuna e a Justificativa}
Apesar da vasta literatura sobre arquiteturas de microsserviços e padrões de resiliência, observa-se uma lacuna significativa no que diz respeito a \textbf{estudos experimentais quantitativos} que demonstrem, com dados empíricos, o impacto real do padrão Circuit Breaker. Grande parte da documentação disponível limita-se a descrições conceituais ou exemplos triviais que não capturam a complexidade de cenários reais de falha.

Este TCC preenche essa lacuna ao \textbf{implementar} uma POC (Prova de Conceito) que simula um ecossistema de microsserviços com dependência síncrona, instrumentado com Resilience4j, e \textbf{executar} campanhas de benchmark com Docker e k6 para \textbf{medir} empiricamente vazão, latência (p95) e taxa de erro sob cenários controlados. Embora o contexto escolhido seja pagamentos — por familiaridade do autor com o domínio — os padrões de falha simulados (indisponibilidade, degradação, rajadas) são \textbf{universais} em sistemas distribuídos, tornando os resultados aplicáveis a e-commerce, logística, saúde, IoT e qualquer domínio que utilize comunicação síncrona entre serviços.

\section{Objetivos}
\textbf{Objetivo Geral.} Avaliar quantitativamente o impacto do padrão Circuit Breaker no desempenho e na resiliência de microsserviços com comunicação síncrona, utilizando uma POC no domínio de pagamentos como estudo de caso.

\textbf{Objetivos Específicos.}
\begin{enumerate}
    \item Implementar uma POC simplificada composta por \texttt{servico-pagamento} e \texttt{servico-adquirente}, utilizando Spring Boot, Spring Cloud OpenFeign e orquestração via Docker.
    \item Desenvolver duas versões do \texttt{servico-pagamento}: (V1) Baseline com timeouts básicos e (V2) com Resilience4j, Circuit Breaker e fallback.
    \item Construir e executar benchmarks automatizados com k6 para simular cenários de falha universais: indisponibilidade total, degradação gradual, rajadas intermitentes e indisponibilidade prolongada.
    \item Analisar comparativamente as métricas de vazão, latência e taxa de erro, destacando os benefícios e custos da adoção do Circuit Breaker.
\end{enumerate}

\section{Metodologia e Design do Experimento}

\subsection{Visão Geral da Metodologia}
Este Trabalho de Conclusão de Curso adota uma abordagem de \textbf{pesquisa experimental quantitativa}. O método consiste em construir uma \textbf{POC (Prova de Conceito) simplificada} que simula um ecossistema de microsserviços com dependência síncrona. A POC é intencionalmente minimalista — sem banco de dados, cache ou autenticação — para isolar o efeito do Circuit Breaker como única variável de interesse.

A investigação compara duas variações arquiteturais do \texttt{servico-pagamento}: (i) uma versão Baseline, sem mecanismos avançados de resiliência, e (ii) uma versão com Circuit Breaker implementado via Resilience4j. Ambas são orquestradas com \texttt{Docker Compose} e submetidas a campanhas de testes de carga com \texttt{k6}, permitindo coletar métricas objetivas de desempenho (vazão e latência) e resiliência (taxa de erro).

\subsection{Ambiente Experimental}
Os experimentos foram executados em um ambiente controlado com as seguintes especificações:

\textbf{Hardware:}
\begin{itemize}
    \item \textbf{Processador:} Apple M1 Pro (8 núcleos de desempenho + 2 de eficiência)
    \item \textbf{Memória RAM:} 16 GB LPDDR5
    \item \textbf{Armazenamento:} SSD NVMe 512 GB
    \item \textbf{Sistema Operacional:} macOS Sonoma 14.x
\end{itemize}

\textbf{Versões de Software:}
\begin{itemize}
    \item \textbf{Docker Desktop:} 4.25+ com Docker Engine 24.0+
    \item \textbf{Docker Compose:} v2.20+
    \item \textbf{Java:} OpenJDK 17.0.8 (Eclipse Temurin)
    \item \textbf{Spring Boot:} 3.1.5
    \item \textbf{Resilience4j:} 2.1.0
    \item \textbf{Grafana k6:} v0.46.0
\end{itemize}

\textbf{Configuração dos Contêineres Docker:}
\begin{itemize}
    \item \textbf{servico-pagamento:} 1 GB de memória, 1 CPU
    \item \textbf{servico-adquirente:} 512 MB de memória, 0.5 CPU
    \item \textbf{Rede:} Bridge network dedicada para isolamento
\end{itemize}

\textbf{Configuração do Circuit Breaker (V2):}
\begin{itemize}
    \item \texttt{failureRateThreshold}: 50\%
    \item \texttt{slowCallRateThreshold}: 70\%
    \item \texttt{slowCallDurationThreshold}: 3000ms
    \item \texttt{slidingWindowType}: COUNT\_BASED
    \item \texttt{slidingWindowSize}: 10 requisições
    \item \texttt{minimumNumberOfCalls}: 5
    \item \texttt{waitDurationInOpenState}: 10s
    \item \texttt{permittedNumberOfCallsInHalfOpenState}: 3
\end{itemize}

\textbf{Repetições:} Cada cenário foi executado uma única vez por versão (V1 e V2), totalizando 8 execuções. A duração dos testes (9 a 13 minutos por cenário) e o volume de requisições (60.000 a 83.000 por teste) fornecem amostras estatisticamente significativas para análise.

\subsection{Ferramentas e Tecnologias (O Stack)}
O experimento será conduzido com um conjunto integrado de ferramentas que sustentam tanto o desenvolvimento quanto a execução controlada dos cenários de teste:

\begin{figure}[htbp]
\centering
\includegraphics[width=0.8\textwidth]{images/arquitetura_simplificada.png}
\caption{Stack de Monitoramento e Testes}
\label{fig:stack}
\end{figure}

\begin{itemize}
    \item \textbf{Java 17+ e Spring Boot 3:} fundamentos para a implementação dos microsserviços do ecossistema de pagamentos, oferecendo um ambiente moderno, performático e amplamente suportado pela comunidade.
    \item \textbf{Spring Cloud OpenFeign:} cliente declarativo utilizado para a comunicação síncrona entre \texttt{servico-pagamento} e \texttt{servico-adquirente}, simplificando a integração entre serviços através de interfaces anotadas.
    \item \textbf{Spring Cloud Resilience4j:} biblioteca responsável por fornecer o mecanismo de Circuit Breaker e demais padrões de tolerância a falhas, incluindo suporte nativo para métricas, fallbacks e configurações flexíveis.
    \item \textbf{Docker e Docker Compose:} garantem que o ambiente experimental seja isolado, reproduzível e facilmente provisionado, permitindo a execução consistente dos testes em qualquer máquina.
    \item \textbf{Grafana k6:} ferramenta de testes de carga de código aberto escrita em JavaScript/Go, que permite descrever cenários complexos com usuários virtuais (VUs), estágios de carga progressivos e \texttt{thresholds} para validação automática de SLAs. O k6 exporta métricas detalhadas em formato JSON para análise posterior.
\end{itemize}

\subsection{Arquitetura do Sistema Experimental}
O ambiente experimental consiste em uma \textbf{Prova de Conceito (POC) simplificada}, propositalmente rudimentar, desenvolvida para isolar e evidenciar o comportamento do Circuit Breaker sem a complexidade de um sistema de produção real. A simplicidade é intencional: permite atribuir com clareza as diferenças observadas exclusivamente ao padrão de resiliência, sem variáveis de confusão como banco de dados, cache, autenticação ou múltiplas dependências.

A POC é composta por dois microsserviços desenvolvidos em Spring Boot e empacotados como contêineres Docker:

\subsubsection{\texttt{servico-adquirente} — Ponto de Falha Controlado}
\begin{itemize}
    \item \textbf{Função:} simular um gateway externo de pagamento (por exemplo, Cielo ou Rede) responsável por autorizar transações.
    \item \textbf{Endpoint:} expõe \texttt{POST /autorizar} para receber solicitações de autorização.
    \item \textbf{Controle Experimental:} o comportamento é configurável via o parâmetro de query \texttt{?modo=}:
    \begin{itemize}
        \item \texttt{modo=normal}: responde em aproximadamente 50 ms com HTTP 200 (OK). Simula operação saudável.
        \item \texttt{modo=latencia}: responde em 3000 ms (utilizando \texttt{Thread.sleep()}) com HTTP 200 (OK). Simula degradação de performance.
        \item \texttt{modo=falha}: responde imediatamente com HTTP 500 (Internal Server Error). Simula indisponibilidade.
    \end{itemize}
\end{itemize}

\subsubsection{Respostas Possíveis do Sistema}

O \texttt{servico-pagamento} pode retornar diferentes códigos HTTP dependendo do estado do sistema e da versão (V1 ou V2):

\begin{table}[H]
\centering
\caption{Códigos de Resposta HTTP e seus Significados}
\label{tab:http-responses}
\begin{tabular}{clcc}
\toprule
\textbf{Status} & \textbf{Significado} & \textbf{Origem} & \textbf{Versão} \\
\midrule
200/201 & Sucesso real & API funcionou & V1, V2 \\
202 & Fallback (pagamento agendado) & CB aberto & V2 \\
500 & Erro da API externa & Falha propagada & V1, V2 \\
503 & CB rejeitando requisições & CB aberto & V2 \\
\bottomrule
\end{tabular}
\end{table}

O código HTTP 202 (Accepted) é particularmente importante pois representa a \textbf{degradação graciosa}: o sistema informa ao usuário que o pagamento foi recebido e será processado posteriormente, em vez de retornar um erro.

\subsubsection{\texttt{servico-pagamento} — Sistema Sob Teste}
\begin{itemize}
    \item \textbf{Função:} orquestrar o fluxo de pagamento exposto aos clientes finais e consumir o \texttt{servico-adquirente} síncronamente.
    \item \textbf{Endpoint:} expõe \texttt{POST /pagar}, que será exercitado pelos scripts do k6.
    \item \textbf{Lógica de Negócio:} utiliza um Feign Client para delegar a autorização ao \texttt{servico-adquirente}. Este serviço possuirá duas versões, que configuram a variável independente do experimento.
\end{itemize}

\subsection{Variáveis do Experimento}

\subsubsection{Variável Independente — Estratégia de Resiliência no \texttt{servico-pagamento}}
\begin{itemize}
    \item \textbf{V1: Baseline (Controle):} implementação ingênua que apenas configura timeouts curtos (por exemplo, 2 segundos) no Feign Client para conexão e leitura.
    \item \textbf{V2: Circuit Breaker + Fallback:} implementação robusta com Resilience4j. O Circuit Breaker é configurado para abrir após detectar, por exemplo, 50\% de falhas em uma janela de requisições. Quando o circuito está aberto, um método de fallback devolve HTTP 202 (Accepted) com a mensagem "Pagamento recebido e agendado para processamento posterior.", caracterizando a degradação graciosa.
\end{itemize}

\subsubsection{Variáveis Dependentes — Métricas coletadas via k6}
\begin{itemize}
    \item \textbf{\texttt{http\_reqs}:} número total de requisições processadas, utilizado como medida de vazão.
    \item \textbf{\texttt{http\_req\_duration\{p(95)\}}:} percentil 95 do tempo de resposta, indicador de latência sob carga.
    \item \textbf{\texttt{http\_req\_failed}:} taxa de requisições consideradas falhas pelo k6, refletindo a resiliência percebida.
\end{itemize}

\subsection{Plano de Execução — Cenários de Teste k6}
Quatro cenários de teste foram desenvolvidos em k6, cada um projetado para exercitar diferentes aspectos do comportamento do sistema sob estresse. Cada cenário foi executado duas vezes: uma para a versão Baseline (V1) e outra para a versão com Circuit Breaker (V2). Os cenários utilizam de 50 a 200 usuários virtuais (VUs) com duração variável para simular diferentes padrões de carga realistas.

\subsubsection{Cenário 1 — Falha Catastrófica}

\textbf{Contexto Real:} Este cenário reproduz situações como deploy problemático em produção, queda total de servidor, ou falha de infraestrutura de rede. São eventos raros, porém de alto impacto quando ocorrem.

\begin{itemize}
    \item \textbf{Descrição:} A API externa (\texttt{servico-adquirente}) fica \textbf{100\% indisponível} por 5 minutos consecutivos, retornando erro HTTP 500 em todas as requisições.
    
    \item \textbf{Fases do Teste (13 minutos):}
    \begin{enumerate}
        \item \textbf{Aquecimento} (0-1min): Rampa de 0 a 50 VUs, operação normal.
        \item \textbf{Operação Normal} (1-4min): 100 VUs, distribuição realista (70\% sucesso, 20\% latência, 10\% falha).
        \item \textbf{CATÁSTROFE} (4-9min): 150 VUs, \textbf{100\% das requisições em modo falha}. Este é o momento crítico.
        \item \textbf{Recuperação} (9-12min): API volta ao normal gradualmente (60\% sucesso, 25\% latência, 15\% falha).
        \item \textbf{Cooldown} (12-13min): Redução a 0 VUs.
    \end{enumerate}
    
    \item \textbf{Comportamento Esperado:}
    \begin{itemize}
        \item \textit{V1 (Baseline):} Todas as requisições aguardam timeout (~3s), threads ficam bloqueadas, potencial cascata de falhas.
        \item \textit{V2 (Circuit Breaker):} CB detecta falhas em ~10s, abre circuito, retorna fallback (HTTP 202) em <100ms.
    \end{itemize}
    
    \item \textbf{Objetivo:} Verificar se o CB abre rapidamente durante falha total, protege recursos e mantém o sistema responsivo via fallback.
    \item \textbf{Threshold:} \texttt{http\_req\_duration\{p(95)\} < 1000ms}.
\end{itemize}

\subsubsection{Cenário 2 — Degradação Gradual}

\textbf{Contexto Real:} Este cenário reproduz a situação mais comum em produção: um serviço que começa saudável mas degrada progressivamente devido a memory leaks, pool de conexões esgotando, CPU saturando ou acúmulo de requisições em fila.

\begin{itemize}
    \item \textbf{Descrição:} A taxa de falhas e latência da API externa \textbf{aumenta gradualmente} ao longo do teste, simulando degradação progressiva típica de problemas de infraestrutura.
    
    \item \textbf{Fases do Teste (13 minutos):}
    \begin{enumerate}
        \item \textbf{Sistema Saudável} (0-2min): 100 VUs, baixa taxa de erro (5\% falha, 15\% latência, 80\% normal).
        \item \textbf{Degradação Inicial} (2-5min): 150 VUs, degradação perceptível (20\% falha, 30\% latência, 50\% normal).
        \item \textbf{CRÍTICO} (5-8min): 200 VUs, sistema sob estresse severo (50\% falha, 40\% latência, 10\% normal).
        \item \textbf{Recuperação} (8-12min): 100 VUs, melhora gradual (15\% falha, 25\% latência).
        \item \textbf{Cooldown} (12-13min): Encerramento.
    \end{enumerate}
    
    \item \textbf{Comportamento Esperado:}
    \begin{itemize}
        \item \textit{V1 (Baseline):} Degrada junto com a API, usuários experimentam latência crescente.
        \item \textit{V2 (Circuit Breaker):} CB pode detectar degradação e isolar antes do colapso total.
    \end{itemize}
    
    \item \textbf{Objetivo:} Avaliar se o CB detecta degradação precoce e isola o problema antes da cascata. Este cenário também valida que o CB \textbf{não introduz overhead} em condições moderadas.
\end{itemize}

\subsubsection{Cenário 3 — Rajadas Intermitentes}

\textbf{Contexto Real:} Este cenário reproduz instabilidades de rede, problemas intermitentes de DNS, ou serviços que reiniciam frequentemente. É o \textbf{pior cenário para sistemas sem CB}, pois ficam constantemente oscilando entre funcionar e falhar.

\begin{itemize}
    \item \textbf{Descrição:} Períodos de \textbf{100\% falha} (1 minuto) alternados com períodos de operação normal (2 minutos), repetindo 3 vezes.
    
    \item \textbf{Padrão de Rajadas (13 minutos):}
    \begin{enumerate}
        \item \textbf{Aquecimento} (0-1min): 100 VUs, operação normal.
        \item \textbf{Normal} (1-3min): 150 VUs (80\% sucesso, 15\% latência, 5\% falha).
        \item \textbf{RAJADA 1} (3-4min): 200 VUs, \textbf{100\% falha}.
        \item \textbf{Normal} (4-6min): 150 VUs, operação normal.
        \item \textbf{RAJADA 2} (6-7min): 200 VUs, \textbf{100\% falha}.
        \item \textbf{Normal} (7-9min): 150 VUs, operação normal.
        \item \textbf{RAJADA 3} (9-10min): 200 VUs, \textbf{100\% falha}.
        \item \textbf{Normal} (10-12min): 150 VUs, operação normal.
        \item \textbf{Cooldown} (12-13min): Encerramento.
    \end{enumerate}
    
    \item \textbf{Comportamento Esperado:}
    \begin{itemize}
        \item \textit{V1 (Baseline):} Sofre com cada rajada (100\% erro), recupera entre elas.
        \item \textit{V2 (Circuit Breaker):} CB abre nas rajadas (~8s após início), fecha nos períodos normais. Demonstra \textbf{elasticidade}.
    \end{itemize}
    
    \item \textbf{Objetivo:} Testar a capacidade do CB de \textbf{transicionar dinamicamente} entre estados (Fechado $\rightarrow$ Aberto $\rightarrow$ Semiaberto $\rightarrow$ Fechado) conforme o estado da dependência muda.
\end{itemize}

\subsubsection{Cenário 4 — Indisponibilidade Extrema (75\% OFF)}

\textbf{Contexto Real:} Este é o cenário mais extremo, simulando janelas prolongadas de manutenção não programada, falhas de datacenter, ou dependências externas com SLA muito baixo. Demonstra o \textbf{ganho máximo} do Circuit Breaker.

\begin{itemize}
    \item \textbf{Descrição:} A API externa passa \textbf{75\% do tempo indisponível}, incluindo uma janela contínua de 4 minutos de falha total. Este cenário é propositalmente severo para evidenciar o valor do fallback.
    
    \item \textbf{Fases do Teste (9 minutos):}
    \begin{enumerate}
        \item \textbf{Aquecimento} (0-45s): 80 VUs, operação controlada.
        \item \textbf{Operação Saudável} (45s-1.5min): 140 VUs, funcionamento normal.
        \item \textbf{FALHA PROLONGADA} (1.5-5.5min): 180 VUs, \textbf{4 minutos contínuos de indisponibilidade} (100\% falha).
        \item \textbf{Instabilidade} (5.5-7.5min): 200 VUs, rajadas adicionais com alta taxa de falha.
        \item \textbf{Recuperação} (7.5-8.5min): 140 VUs, retorno gradual.
        \item \textbf{Cooldown} (8.5-9min): Encerramento.
    \end{enumerate}
    
    \item \textbf{Padrão de Indisponibilidade:}
    \begin{itemize}
        \item Ciclos de 80 segundos: 60s em falha + 20s de recuperação parcial.
        \item Janela crítica central: 4 minutos de falha \textbf{ininterrupta}.
    \end{itemize}
    
    \item \textbf{Comportamento Esperado:}
    \begin{itemize}
        \item \textit{V1 (Baseline):} Sistema praticamente \textbf{inutilizável} (~10\% sucesso). Caracteriza falha catastrófica.
        \item \textit{V2 (Circuit Breaker):} CB mantém circuito aberto, serve fallbacks continuamente, preservando \textbf{~97\% de disponibilidade percebida}.
    \end{itemize}
    
    \item \textbf{Objetivo:} Validar que o CB transforma um sistema inutilizável em um sistema funcional através da degradação graciosa.
    \item \textbf{Thresholds:} \texttt{http\_req\_duration\{p(95)\} < 1200ms} e \texttt{http\_req\_failed < 0.25}.
\end{itemize}

\subsubsection{Resumo Comparativo dos Cenários}

A Tabela \ref{tab:cenarios-resumo} apresenta uma visão consolidada dos quatro cenários, destacando suas características distintivas e o propósito de cada um no experimento.

\begin{table}[H]
\centering
\caption{Características dos Cenários de Teste}
\label{tab:cenarios-resumo}
\begin{tabular}{lcccl}
\toprule
\textbf{Cenário} & \textbf{Duração} & \textbf{VUs} & \textbf{Padrão de Falha} & \textbf{Testa} \\
\midrule
Catastrófica & 13min & 50-150 & 100\% falha por 5min & Fail-fast \\
Degradação & 13min & 100-200 & 5\% → 50\% gradual & Detecção precoce \\
Rajadas & 13min & 100-200 & 3× (100\% por 1min) & Elasticidade \\
Indisponibilidade & 9min & 80-200 & 75\% offline & Ganho máximo \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Procedimento de Análise Estatística}

Para validar estatisticamente as diferenças observadas entre as versões V1 (Baseline) e V2 (Circuit Breaker), foi definido um procedimento de análise estatística robusto, considerando as características dos dados coletados.

\subsubsection{Justificativa para Testes Não-Paramétricos}

A escolha por testes não-paramétricos foi motivada pelas seguintes características dos dados:

\begin{itemize}
    \item \textbf{Distribuição não-normal:} Tempos de resposta em sistemas distribuídos tipicamente apresentam distribuição assimétrica com cauda longa, violando a premissa de normalidade exigida por testes paramétricos como o teste t de Student.
    \item \textbf{Grande volume amostral:} Com mais de 380.000 requisições por versão, testes de normalidade (Shapiro-Wilk, Kolmogorov-Smirnov) tendem a rejeitar a hipótese nula mesmo para desvios mínimos da normalidade.
    \item \textbf{Presença de outliers:} Timeouts e respostas de fallback introduzem valores extremos que podem distorcer estimativas baseadas em média e desvio padrão.
\end{itemize}

\subsubsection{Testes Estatísticos Selecionados}

\textbf{Teste de Mann-Whitney U:} Teste não-paramétrico para comparação de duas amostras independentes, utilizado para verificar se as distribuições de tempos de resposta de V1 e V2 são estatisticamente diferentes. O nível de significância adotado foi $\alpha = 0,05$.

\textbf{Teste de Kolmogorov-Smirnov (KS):} Complementarmente, o teste KS foi aplicado para avaliar se as duas distribuições diferem em forma, não apenas em tendência central.

\subsubsection{Medida de Tamanho do Efeito}

\textbf{Cliff's Delta ($\delta$):} Para quantificar a magnitude prática da diferença entre V1 e V2, foi calculado o Cliff's Delta, uma medida de tamanho de efeito não-paramétrica. A interpretação segue a convenção de \cite{romano2006}:

\begin{itemize}
    \item $|\delta| < 0,147$: efeito \textbf{negligível}
    \item $0,147 \leq |\delta| < 0,33$: efeito \textbf{pequeno}
    \item $0,33 \leq |\delta| < 0,474$: efeito \textbf{médio}
    \item $|\delta| \geq 0,474$: efeito \textbf{grande}
\end{itemize}

Esta medida é particularmente importante porque, com amostras muito grandes, diferenças estatisticamente significativas (p $<$ 0,05) podem não ter relevância prática. O Cliff's Delta permite distinguir entre significância estatística e significância prática.

\subsubsection{Intervalo de Confiança}

Para estimar a diferença média entre as versões, foi calculado um intervalo de confiança de 95\% utilizando bootstrap (1.000 reamostragens), técnica adequada para distribuições não-normais.

\section{Resultados e Discussão}

\subsection{Introdução ao Capítulo}
Os testes de carga foram executados usando \texttt{k6} e \texttt{Docker Compose}. Cada versão do \texttt{servico-pagamento} (V1-Baseline, V2-CircuitBreaker) foi submetida aos quatro cenários de estresse (Falha Catastrófica, Degradação Gradual, Rajadas Intermitentes e Indisponibilidade Extrema). Os resultados foram avaliados contra os \texttt{thresholds} (limites de desempenho) definidos nos scripts e analisados em termos de taxa de sucesso, tempo de resposta e contribuição do mecanismo de fallback.

\subsection{Visão Geral Consolidada dos Resultados}

\begin{table}[H]
\centering
\caption{Resumo Consolidado: Comparação V1 vs V2 em Todos os Cenários}
\label{tab:resumo-consolidado}
\begin{tabular}{lccccc}
\toprule
Cenário & V1 Sucesso & V2 Sucesso & V2 Fallback & Ganho & Red. Falhas \\
\midrule
Catastrófica & 90.0\% & 94.5\% & 59.0\% & +4.5pp & -44.8\% \\
Degradação & 94.7\% & 94.9\% & 0.0\% & +0.2pp & -4.2\% \\
Indisponibilidade & 10.1\% & 97.1\% & 92.8\% & +86.9pp & -96.8\% \\
Rajadas & 94.9\% & 95.2\% & 10.2\% & +0.3pp & -5.8\% \\
\bottomrule
\end{tabular}
\end{table}

A Tabela 1 apresenta o resumo consolidado dos quatro cenários. O dado mais impressionante é o cenário de \textbf{Indisponibilidade Extrema}, onde a V1 apresentou apenas 10.14\% de sucesso, enquanto a V2 alcançou 97.08\% \textemdash\ um ganho de \textbf{86.94 pontos percentuais} e redução de 96.77\% nas falhas. Este resultado demonstra inequivocamente o valor do Circuit Breaker em cenários de alta indisponibilidade.

\begin{figure}[H]
\centering
\includegraphics[width=0.85\textwidth]{images/01_success_rates_comparison.png}
\caption{Comparação de Taxas de Sucesso: V1 (Baseline) vs V2 (Circuit Breaker)}
\label{fig:success_rates}
\end{figure}

\subsection{Análise do Cenário 1: Falha Catastrófica}

Neste cenário, a API externa ficou 100\% indisponível durante 5 minutos consecutivos, simulando uma queda total do servidor.

\textbf{Comportamento Observado:}
\begin{itemize}
    \item \textbf{V1 (Baseline):} Durante o período de catástrofe, todas as requisições aguardaram o timeout (2s) antes de falhar, consumindo threads e degradando o sistema. A taxa de sucesso geral foi de 90,0\%. O downtime total foi de 78 segundos.
    \item \textbf{V2 (Circuit Breaker):} O CB detectou as falhas em menos de 10 segundos, abriu o circuito e passou a retornar respostas via fallback (HTTP 202) em menos de 100ms. A taxa de sucesso subiu para 94,5\%, com 59\% das respostas sendo fallbacks. O downtime foi reduzido para 43 segundos.
\end{itemize}

\textbf{Métricas de Performance:}
\begin{itemize}
    \item \textbf{Melhoria no Tempo de Resposta:} 60\% de redução no tempo médio
    \item \textbf{Redução de Falhas:} 44,8\%
    \item \textbf{Redução de Downtime:} 45\% (de 78s para 43s)
\end{itemize}

\begin{figure}[H]
\centering
\includegraphics[width=0.85\textwidth]{images/07_catastrofe_timeline.png}
\caption{Timeline do Cenário de Falha Catastrófica: Transição de Estados}
\label{fig:catastrofe_timeline}
\end{figure}

\textbf{Impacto Positivo do Circuit Breaker:}
\begin{enumerate}
    \item \textbf{Proteção contra Exaustão de Recursos:} Enquanto a V1 mantinha threads bloqueadas aguardando timeout, a V2 liberava threads imediatamente após a abertura do circuito.
    \item \textbf{Tempo de Resposta Previsível:} Média de resposta da V2 durante catástrofe: ~85ms (fallback). V1: ~2000ms (timeout).
    \item \textbf{Degradação Graciosa:} Usuários receberam HTTP 202 informando que o pagamento foi agendado, em vez de erro HTTP 500.
\end{enumerate}

\subsection{Análise do Cenário 2: Degradação Gradual}

Este cenário simula uma situação comum em produção: um serviço que começa saudável mas degrada progressivamente.

\textbf{Comportamento Observado:}
\begin{itemize}
    \item \textbf{V1 (Baseline):} A degradação afetou uniformemente todas as requisições. Taxa de sucesso: 94.72\%.
    \item \textbf{V2 (Circuit Breaker):} O CB detectou o aumento na taxa de falhas e latência, mantendo o sistema estável. Taxa de sucesso: 94.94\%, com fallback praticamente não acionado (0.0\%).
\end{itemize}

\textbf{Insight:} Neste cenário, o ganho em taxa de sucesso foi marginal (+0,2pp), pois a degradação não foi severa o suficiente para acionar o CB consistentemente. Entretanto, a V2 ainda demonstrou ligeira melhoria no tempo de resposta (0,44\% mais rápido) e redução de 4,2\% nas falhas, confirmando que o CB \textbf{não introduz overhead} em cenários de degradação moderada e ainda oferece proteção incremental.

\subsection{Análise do Cenário 3: Rajadas Intermitentes}

O cenário de rajadas é particularmente desafiador, pois exige que o sistema reaja rapidamente a mudanças de estado.

\textbf{Comportamento Observado:}
\begin{itemize}
    \item \textbf{V1 (Baseline):} Durante cada rajada de 1 minuto, 100\% das requisições falharam. Nos períodos normais, o sistema se recuperou. Taxa geral: 94,9\%.
    \item \textbf{V2 (Circuit Breaker):} O CB abriu durante as rajadas e fechou nos períodos normais, demonstrando \textbf{elasticidade}. Taxa geral: 95,2\%, com 10,2\% de fallbacks. Melhoria de 10,8\% no tempo de resposta médio.
\end{itemize}

\textbf{Elasticidade do Circuit Breaker:} A capacidade do CB de transicionar entre estados (Fechado $\rightarrow$ Aberto $\rightarrow$ Semiaberto $\rightarrow$ Fechado) foi validada neste cenário. O tempo médio para abertura do circuito foi de ~8 segundos após o início de cada rajada. A redução de 5,8\% nas falhas demonstra a proteção oferecida mesmo em cenários de instabilidade.

\subsection{Análise do Cenário 4: Indisponibilidade Extrema (75\% OFF)}

Este é o cenário mais extremo e onde o Circuit Breaker demonstrou seu valor máximo.

\begin{table}[H]
\centering
\caption{Resultados Detalhados: Indisponibilidade Extrema}
\label{tab:indisponibilidade-detalhes}
\begin{tabular}{lcc}
\toprule
Métrica & V1 (Baseline) & V2 (Circuit Breaker) \\
\midrule
Taxa de Sucesso Total & 10,14\% & 97,08\% \\
Requisições via Fallback & N/A & 92,80\% \\
Taxa de Falha Real & 89,86\% & 2,91\% \\
Redução de Falhas & \textemdash & \textbf{96,77\%} \\
\midrule
Downtime (segundos) & 487,4s & 15,8s \\
Disponibilidade Efetiva & 10,1\% & 97,1\% \\
Melhoria P95 & \textemdash & \textbf{95,6\%} \\
Melhoria Tempo Médio & \textemdash & \textbf{74,6\%} \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Comportamento Observado:}
\begin{itemize}
    \item \textbf{V1 (Baseline):} Com 75\% de indisponibilidade, o sistema se tornou praticamente inutilizável. Apenas 10,14\% das requisições foram bem-sucedidas, caracterizando \textbf{falha catastrófica do serviço}. O downtime efetivo foi de \textbf{487 segundos} (mais de 8 minutos).
    \item \textbf{V2 (Circuit Breaker):} O CB manteve o circuito aberto durante os períodos de indisponibilidade, servindo fallbacks e preservando a disponibilidade percebida pelo usuário em 97,08\%. O downtime foi reduzido para apenas \textbf{16 segundos}.
\end{itemize}

\textbf{Impacto Transformador:} Este cenário demonstra que o Circuit Breaker pode transformar um sistema \textbf{completamente inutilizável} (10\% de sucesso) em um sistema \textbf{altamente disponível} (97\% de sucesso), representando uma melhoria de quase \textbf{10x na disponibilidade percebida}.

\begin{figure}[H]
\centering
\includegraphics[width=0.85\textwidth]{images/11_downtime_availability.png}
\caption{Comparação de Disponibilidade e Downtime por Cenário}
\label{fig:downtime_availability}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.85\textwidth]{images/02_failure_reduction.png}
\caption{Redução de Falhas: Impacto do Circuit Breaker por Cenário}
\label{fig:failure_reduction}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.85\textwidth]{images/09_avg_response_times.png}
\caption{Comparação de Tempos de Resposta Médios: V1 vs V2 por Cenário}
\label{fig:avg_response_times}
\end{figure}

\subsection{Análise de Tempos de Resposta}

\begin{figure}[H]
\centering
\includegraphics[width=0.85\textwidth]{images/03_response_time_percentiles.png}
\caption{Distribuição de Tempos de Resposta (Percentis) por Cenário}
\label{fig:response_percentiles}
\end{figure}

A análise dos percentis de tempo de resposta revela outro benefício crucial do Circuit Breaker: \textbf{previsibilidade}. Enquanto a V1 apresentou alta variância nos tempos de resposta (de 50ms a 2000ms dependendo do estado da dependência), a V2 manteve tempos consistentemente baixos devido ao mecanismo de fail-fast.

\begin{figure}[H]
\centering
\includegraphics[width=0.85\textwidth]{images/distributions.png}
\caption{Distribuição Estatística dos Tempos de Resposta: V1 vs V2}
\label{fig:distributions}
\end{figure}

A Figura \ref{fig:distributions} apresenta a distribuição estatística dos tempos de resposta para ambas as versões. Note a maior concentração de requisições em tempos baixos na V2, com mediana de apenas 35,69ms comparada aos 160,56ms da V1.

\begin{figure}[H]
\centering
\includegraphics[width=0.85\textwidth]{images/05_status_distribution.png}
\caption{Distribuição de Códigos de Status HTTP por Cenário}
\label{fig:status_distribution}
\end{figure}

A Figura \ref{fig:status_distribution} mostra a distribuição de códigos de status HTTP para cada cenário. Observa-se claramente que a V2 substitui erros HTTP 500 por respostas HTTP 202 (fallback), mantendo o sistema funcional para o usuário final.

\begin{figure}[H]
\centering
\includegraphics[width=0.85\textwidth]{images/10_error_rates.png}
\caption{Comparação de Taxas de Erro: V1 vs V2 por Cenário}
\label{fig:error_rates}
\end{figure}

A Figura \ref{fig:error_rates} evidencia a redução dramática nas taxas de erro proporcionada pelo Circuit Breaker, especialmente no cenário de indisponibilidade extrema onde a taxa de erro caiu de 89,9\% para apenas 2,9\%.

\subsection{Contribuição do Mecanismo de Fallback}

\begin{figure}[H]
\centering
\includegraphics[width=0.85\textwidth]{images/08_fallback_contribution.png}
\caption{Contribuição do Fallback para a Taxa de Sucesso da V2}
\label{fig:fallback_contribution}
\end{figure}

O gráfico da Figura \ref{fig:fallback_contribution} ilustra como o fallback contribuiu para a taxa de sucesso em cada cenário. No cenário de Indisponibilidade Extrema, \textbf{92.80\%} das respostas bem-sucedidas vieram do fallback, demonstrando que o sistema manteve sua utilidade mesmo com a dependência quase completamente indisponível.

\begin{figure}[H]
\centering
\includegraphics[width=0.85\textwidth]{images/timeline_comparison.png}
\caption{Comparação Temporal de Tempos de Resposta: V1 vs V2}
\label{fig:timeline_comparison}
\end{figure}

A Figura \ref{fig:timeline_comparison} apresenta a evolução temporal dos tempos de resposta ao longo de todos os cenários de teste. Observa-se que ambas as versões apresentam picos de latência nos mesmos momentos (correspondentes às fases de estresse), porém a V2 demonstra recuperação mais rápida devido ao mecanismo de fallback.

\subsection{Análise de Throughput}

\begin{figure}[H]
\centering
\includegraphics[width=0.85\textwidth]{images/04_throughput_comparison.png}
\caption{Comparação de Throughput (Requisições/segundo) entre V1 e V2}
\label{fig:throughput}
\end{figure}

Além da taxa de sucesso, o throughput (vazão) é uma métrica crítica. A V2 manteve throughput superior em cenários de falha porque não desperdiçou threads aguardando timeouts. Isso se traduz em maior capacidade de processamento sob estresse.

\subsection{Análise Estatística Formal}

Para validar estatisticamente a diferença entre as versões V1 e V2, aplicamos testes não-paramétricos dado o grande volume de dados (N > 380.000 requisições por versão) e a distribuição não-normal dos tempos de resposta.

\begin{table}[H]
\centering
\caption{Análise Estatística Comparativa: Tempos de Resposta V1 vs V2}
\label{tab:analise-estatistica}
\begin{tabular}{lr}
\toprule
Métrica & Valor \\
\midrule
N (V1) & 353.639 \\
N (V2) & 415.927 \\
Média (V1) & 735,05 ms \\
Média (V2) & 477,60 ms \\
Mediana (V1) & 160,56 ms \\
Mediana (V2) & 35,69 ms \\
Desvio Padrão (V1) & 1.085,40 ms \\
Desvio Padrão (V2) & 952,68 ms \\
P95 (V1) & 2.975,17 ms \\
P95 (V2) & 2.745,21 ms \\
P99 (V1) & 3.613,63 ms \\
P99 (V2) & 2.977,47 ms \\
\midrule
Mann-Whitney U & 101.610.477.156,50 \\
p-valor (Mann-Whitney) & $<$ 0,001 \\
Kolmogorov-Smirnov D & 0,3490 \\
p-valor (KS) & $<$ 0,001 \\
Cliff's Delta ($\delta$) & 0,3816 \\
Interpretação Effect Size & \textbf{Médio} \\
IC 95\% Diferença & [252,84; 262,03] ms \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Interpretação dos Resultados Estatísticos:}

O teste de Mann-Whitney U revela uma diferença estatisticamente significativa entre V1 e V2 (p $<$ 0,001), indicando que as distribuições de tempos de resposta são distintas. O \textbf{Cliff's Delta} ($\delta = 0,3816$) classifica o \textit{effect size} como \textbf{médio}, confirmando que a diferença observada possui relevância prática substancial.

As melhorias observadas são expressivas:
\begin{itemize}
    \item \textbf{Tempo médio de resposta:} Redução de 735,05ms para 477,60ms (\textbf{-35,0\%})
    \item \textbf{Mediana:} Redução de 160,56ms para 35,69ms (\textbf{-77,8\%})
    \item \textbf{P95:} Redução de 2.975,17ms para 2.745,21ms (\textbf{-7,7\%})
    \item \textbf{P99:} Redução de 3.613,63ms para 2.977,47ms (\textbf{-17,6\%})
\end{itemize}

A diferença média estimada entre V1 e V2 é de aproximadamente 257 ms (IC 95\%: 252,84 a 262,03 ms), o que representa uma melhoria de \textbf{35\%} no tempo médio de resposta. Este resultado demonstra que o Circuit Breaker não apenas protege o sistema contra falhas, mas também \textbf{melhora significativamente o desempenho} ao evitar esperas por timeouts durante períodos de indisponibilidade.

\subsection{Discussão Geral e Impacto do Circuit Breaker}

Os resultados experimentais validam inequivocamente a eficácia do padrão Circuit Breaker. Os principais benefícios observados foram:

\begin{enumerate}
    \item \textbf{Prevenção de Falhas em Cascata:} O CB isolou o \texttt{servico-pagamento} das falhas do \texttt{servico-adquirente}, impedindo que a indisponibilidade se propagasse.
    \item \textbf{Degradação Graciosa:} Em vez de retornar erros HTTP 500, o sistema retornou HTTP 202 com uma mensagem útil ao usuário.
    \item \textbf{Proteção de Recursos:} O mecanismo fail-fast liberou threads rapidamente, evitando thread pool starvation.
    \item \textbf{Melhoria Significativa de Performance:} A V2 apresentou redução de 35\% no tempo médio de resposta e 78\% na mediana, demonstrando que o Circuit Breaker não apenas protege, mas também otimiza o sistema.
    \item \textbf{Elasticidade:} O CB demonstrou capacidade de abrir e fechar dinamicamente conforme o estado da dependência.
    \item \textbf{Aumento de Throughput:} A V2 processou 17,6\% mais requisições (415.927 vs 353.639), evidenciando maior capacidade sob carga.
\end{enumerate}

\textbf{Impacto Quantificado:} A Tabela \ref{tab:impacto-quantificado} resume os principais ganhos proporcionados pelo Circuit Breaker.

\begin{table}[H]
\centering
\caption{Impacto Quantificado do Circuit Breaker}
\label{tab:impacto-quantificado}
\begin{tabular}{lrrr}
\toprule
Métrica & V1 & V2 & Melhoria \\
\midrule
Tempo Médio de Resposta & 735,05 ms & 477,60 ms & \textbf{-35,0\%} \\
Mediana de Resposta & 160,56 ms & 35,69 ms & \textbf{-77,8\%} \\
P95 & 2.975 ms & 2.745 ms & \textbf{-7,7\%} \\
P99 & 3.613 ms & 2.977 ms & \textbf{-17,6\%} \\
Total de Requisições & 353.639 & 415.927 & \textbf{+17,6\%} \\
Taxa de Falha (Indispon.) & 89,9\% & 2,9\% & \textbf{-96,8\%} \\
\bottomrule
\end{tabular}
\end{table}

\section{Conclusão}

\subsection{Revisão dos Objetivos e do Problema}
Este trabalho se propôs a investigar a fragilidade da comunicação síncrona em microsserviços, especificamente o risco de falhas em cascata em um sistema de pagamentos. O objetivo foi avaliar quantitativamente o impacto do padrão Circuit Breaker no desempenho e resiliência, usando um experimento prático e reprodutível com \texttt{Docker} e \texttt{k6}.

\subsection{Síntese dos Resultados}
Os resultados experimentais foram conclusivos e demonstraram de forma inequívoca o valor do padrão Circuit Breaker:

\begin{itemize}
    \item \textbf{Cenário de Indisponibilidade Extrema:} A V2 (Circuit Breaker) alcançou 97,08\% de sucesso contra apenas 10,14\% da V1 — um ganho de \textbf{86,94 pontos percentuais} e redução de \textbf{96,77\%} nas falhas.
    \item \textbf{Cenário de Falha Catastrófica:} A V2 manteve 94,5\% de sucesso com 59\% das respostas via fallback, enquanto a V1 apresentou falhas massivas durante o período de indisponibilidade (redução de 44,8\% nas falhas).
    \item \textbf{Melhoria de Performance:} O tempo médio de resposta reduziu de 735,05ms para 477,60ms (\textbf{-35\%}), e a mediana caiu de 160,56ms para 35,69ms (\textbf{-78\%}).
    \item \textbf{Aumento de Capacidade:} A V2 processou 17,6\% mais requisições (415.927 vs 353.639), demonstrando que o mecanismo fail-fast libera recursos e aumenta o throughput.
    \item \textbf{Análise Estatística:} O teste de Mann-Whitney confirmou diferença significativa (p $<$ 0,001), e o Cliff's Delta ($\delta = 0,38$) indica \textbf{effect size médio}, confirmando relevância prática substancial.
    \item \textbf{Elasticidade:} O CB demonstrou capacidade de transicionar dinamicamente entre estados conforme o comportamento da dependência.
\end{itemize}

A arquitetura Baseline (V1) provou ser \textbf{inadequada para produção} em sistemas de missão crítica, enquanto a V2 (Circuit Breaker) demonstrou robustez excepcional, protegendo o \texttt{servico-pagamento}, mantendo vazão estavel e garantindo disponibilidade percebida pelo usuário através da degradação graciosa (HTTP 202). Os resultados são particularmente relevantes para sistemas financeiros, e-commerce e qualquer domínio onde a disponibilidade é requisito crítico.

\subsection{Contribuições do Trabalho}
Este TCC contribui para a literatura ao fornecer:
\begin{enumerate}
    \item \textbf{Evidência Empírica Robusta:} Dados quantitativos que demonstram o impacto real do Circuit Breaker em cenários realistas de falha, com mais de 769.000 requisições analisadas.
    \item \textbf{Análise Estatística Rigorosa:} Aplicação de testes não-paramétricos (Mann-Whitney U, Kolmogorov-Smirnov) e medidas de effect size (Cliff's Delta = 0,38) que confirmam relevância prática substancial.
    \item \textbf{Metodologia Reprodutível:} Um framework de testes com Docker e k6 que pode ser replicado para avaliar outros padrões de resiliência.
    \item \textbf{Análise Multidimensional:} Avaliação não apenas de taxa de sucesso, mas também de latência (média, mediana, P95, P99), throughput, downtime e comportamento temporal do sistema.
    \item \textbf{Quantificação de Benefícios:} Demonstração de melhorias de até 86,94pp em taxa de sucesso, 35\% em tempo médio de resposta e 78\% na mediana.
\end{enumerate}

\subsection{Limitações do Estudo}
Apesar dos resultados expressivos, este trabalho apresenta limitações que devem ser consideradas na interpretação dos achados:

\begin{enumerate}
    \item \textbf{POC Simplificada:} O sistema experimental é uma Prova de Conceito intencionalmente rudimentar, sem banco de dados, cache, autenticação ou lógica de negócio complexa. Sistemas de produção reais possuem mais variáveis que podem interagir com o comportamento do Circuit Breaker.
    
    \item \textbf{Ambiente Local:} Os experimentos foram executados em uma única máquina, sem latência de rede real entre serviços. Em ambientes distribuídos (multi-datacenter, cloud), a latência adicional pode influenciar os resultados.
    
    \item \textbf{Carga Sintética:} O k6 gera tráfego sintético com padrões uniformes. Tráfego real apresenta características mais complexas: rajadas imprevisíveis, sazonalidade e correlação entre requisições.
    
    \item \textbf{Serviço Adquirente Mockado:} O \texttt{servico-adquirente} foi implementado com falhas controladas e determinísticas. Em produção, falhas são frequentemente parciais e imprevisíveis.
    
    \item \textbf{Execução Única:} Cada cenário foi executado uma vez por versão. Múltiplas execuções permitiriam calcular intervalos de confiança e validar reprodutibilidade.
    
    \item \textbf{Configuração Fixa do CB:} Apenas uma configuração do Circuit Breaker foi testada. Diferentes parametrizações podem resultar em comportamentos distintos.
    
    \item \textbf{Domínio Específico:} Embora o contexto de pagamentos seja generalizável, outros domínios podem ter requisitos específicos (ex: latência ultra-baixa em trading) que influenciam a aplicabilidade dos resultados.
\end{enumerate}

\subsection{Ameaças à Validade}
Identificamos as seguintes ameaças à validade dos resultados:

\textbf{Validade Interna:}
\begin{itemize}
    \item \textbf{Variabilidade do ambiente:} Processos em segundo plano no sistema operacional, garbage collection da JVM e contenção de recursos do Docker podem introduzir variância nos resultados.
    \item \textbf{Warm-up da JVM:} A compilação JIT (Just-In-Time) pode afetar os primeiros minutos de cada teste. Mitigamos isso com fases de aquecimento nos scripts k6.
    \item \textbf{Ordem de execução:} Os testes foram executados sequencialmente; efeitos de ordem (ex: fragmentação de memória) não foram controlados.
\end{itemize}

\textbf{Validade Externa:}
\begin{itemize}
    \item \textbf{Generalização:} Os resultados são específicos para o domínio de pagamentos e a stack tecnológica utilizada (Java/Spring). Outros domínios e tecnologias podem apresentar comportamentos diferentes.
    \item \textbf{Escala:} O experimento utilizou até 200 VUs (usuários virtuais). Sistemas de produção podem enfrentar milhares de requisições simultâneas, alterando a dinâmica de contenção.
    \item \textbf{Complexidade arquitetural:} O experimento envolveu apenas dois serviços. Arquiteturas reais com dezenas de microsserviços introduzem cadeias de dependência mais complexas.
\end{itemize}

\textbf{Validade de Construção:}
\begin{itemize}
    \item \textbf{Definição de sucesso:} Consideramos HTTP 200 e HTTP 202 (fallback) como sucesso. Em contextos onde o fallback não é aceitável pelo negócio, a interpretação dos resultados seria diferente.
    \item \textbf{Métricas selecionadas:} Focamos em taxa de sucesso, latência e throughput. Outras métricas (uso de CPU, memória, conexões abertas) poderiam revelar aspectos adicionais.
\end{itemize}

\subsection{Trabalhos Futuros}
Como trabalho futuro, sugere-se:
\begin{enumerate}
    \item \textbf{Comparação com Outros Padrões:} Expandir o experimento para comparar o Circuit Breaker com outros padrões de resiliência como Retry (com backoff exponencial), Bulkhead (isolamento de threads) e Rate Limiter, avaliando tanto o uso isolado quanto a composição destes padrões.
    
    \item \textbf{Análise Paramétrica:} Investigar sistematicamente o impacto de diferentes configurações do Circuit Breaker (ex: \texttt{slidingWindowSize}, \texttt{failureRateThreshold}, \texttt{waitDurationInOpenState}), identificando configurações ótimas para diferentes perfis de carga.
    
    \item \textbf{Cenários de Múltiplas Dependências:} Avaliar o comportamento do CB em arquiteturas com múltiplos serviços dependentes, investigando estratégias de Circuit Breaker por dependência versus Circuit Breaker global.
    
    \item \textbf{Comunicação Assíncrona:} Comparar os resultados com arquiteturas baseadas em mensageria (Apache Kafka, RabbitMQ), avaliando os trade-offs entre comunicação síncrona protegida por CB e comunicação assíncrona nativa.
    
    \item \textbf{Ambiente Cloud Distribuído:} Replicar os experimentos em ambiente cloud (AWS, GCP ou Azure) com serviços distribuídos geograficamente, introduzindo latência de rede real e avaliando o comportamento do CB em cenários de particionamento de rede.
    
    \item \textbf{Chaos Engineering:} Integrar ferramentas de Chaos Engineering (ex: Chaos Monkey, Litmus) para injeção de falhas aleatórias e contínuas, validando a robustez do Circuit Breaker em condições mais realistas e imprevisíveis.
    
    \item \textbf{Observabilidade Avançada:} Implementar distributed tracing (Jaeger, Zipkin) para correlacionar o estado do Circuit Breaker com traces de requisições, facilitando a análise de causa raiz em cenários complexos.
    
    \item \textbf{Machine Learning para Tuning:} Explorar o uso de algoritmos de aprendizado de máquina para ajuste dinâmico dos parâmetros do Circuit Breaker com base em padrões históricos de tráfego e falhas.
    
    \item \textbf{Estudo Longitudinal:} Conduzir um estudo de longo prazo em ambiente de produção para avaliar a eficácia do Circuit Breaker ao longo de meses, capturando eventos reais de degradação e falha.
\end{enumerate}

\section{Metodologia e Design do Experimento}
\label{sec:metodologia}

Para avaliar o impacto do padrão Circuit Breaker na resiliência e performance de um sistema de microsserviços, foi desenhado um experimento controlado. Esta seção detalha a arquitetura do sistema, as ferramentas utilizadas, os cenários de teste elaborados e as métricas coletadas.

\subsection{Arquitetura do Sistema}
O ambiente experimental consiste em três microsserviços conteinerizados, orquestrados com Docker Compose, que simulam um fluxo de pagamento simplificado:

\begin{itemize}
    \item \textbf{Serviço de Pagamento (Payment Service):} O serviço principal, onde o padrão Circuit Breaker é aplicado. Ele recebe requisições de pagamento e depende do Serviço Adquirente para processá-las. Foram criadas múltiplas versões deste serviço para comparação:
    \begin{itemize}
        \item \textbf{V1 (Baseline):} Uma implementação padrão, sem nenhum mecanismo de resiliência.
        \item \textbf{V2 (Circuit Breaker):} Implementação com o Circuit Breaker Resilience4j.
        \item \textbf{V3 (Circuit Breaker com Time Limiter):} Adiciona um limite de tempo à chamada.
        \item \textbf{V4 (Circuit Breaker com Fallback):} Adiciona um método de fallback que é executado quando o circuito está aberto.
    \end{itemize}
    \item \textbf{Serviço Adquirente (Acquirer Service):} Simula o sistema externo que autoriza os pagamentos. Sua API foi projetada para introduzir falhas e latência de forma controlada, permitindo a simulação de diferentes cenários adversos.
    \item \textbf{Proxy de Falhas (Toxiproxy):} Uma ferramenta que intercepta a comunicação de rede entre o Serviço de Pagamento e o Serviço Adquirente, permitindo a injeção de falhas de rede, como latência e perda de pacotes, de forma dinâmica.
\end{itemize}

A Figura \ref{fig:arquitetura-sistema} ilustra a interação entre os componentes.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{images/diagrama_arquitetura_tcc.png}
    \caption{Arquitetura do sistema experimental.}
    \label{fig:arquitetura-sistema}
\end{figure}

\subsection{Ferramentas de Teste e Monitoramento}
\begin{itemize}
    \item \textbf{k6:} Ferramenta de teste de carga de código aberto, utilizada para gerar tráfego HTTP intenso e simular o comportamento de múltiplos usuários simultâneos. Os scripts de teste foram escritos em JavaScript.
    \item \textbf{Prometheus:} Sistema de monitoramento e alerta, configurado para coletar métricas de performance dos serviços, como latência, taxa de erros e o estado do Circuit Breaker (fechado, aberto, semi-aberto).
    \item \textbf{Grafana:} Plataforma de visualização de dados, utilizada para criar dashboards que exibem as métricas coletadas pelo Prometheus em tempo real.
\end{itemize}

\subsection{Cenários de Teste}
Foram definidos seis cenários de teste para submeter o sistema a diferentes condições de estresse e falha. Cada cenário foi executado contra as versões V1 (Baseline) e V2 (Circuit Breaker) do serviço para permitir uma análise comparativa.

\begin{enumerate}
    \item \textbf{Cenário A - Carga Normal:} Simula um dia de operação normal, com carga de trabalho padrão e sem falhas induzidas. O objetivo é estabelecer uma linha de base (baseline) de performance.
    \item \textbf{Cenário B - Latência Elevada:} Injeta uma latência de 3 segundos nas respostas do Serviço Adquirente. Este cenário visa avaliar como o sistema se comporta quando uma dependência crítica se torna lenta.
    \item \textbf{Cenário C - Falha Catastrófica:} O Serviço Adquirente passa a retornar erros HTTP 500 para todas as requisições, simulando uma indisponibilidade total do serviço dependente.
    \item \textbf{Cenário D - Estresse Crescente:} A carga de usuários virtuais (VUs) aumenta progressivamente, testando a escalabilidade e o ponto de saturação do sistema.
    \item \textbf{Cenário E - Recuperação Pós-Falha:} Inicia com uma fase de falhas para forçar a abertura do Circuit Breaker, seguida por um período de normalização do serviço dependente. O objetivo é medir a capacidade do sistema de se recuperar e voltar à operação normal.
    \item \textbf{Cenário F - Falhas Intermitentes:} O serviço dependente alterna entre respostas de sucesso e erro, simulando um ambiente instável e imprevisível. Este cenário testa a sensibilidade e a capacidade de adaptação do Circuit Breaker.
\end{enumerate}

\subsection{Métricas Coletadas}
Para a análise quantitativa, foram coletadas as seguintes métricas principais a partir dos resultados do k6 e do Prometheus:

\begin{itemize}
    \item \textbf{Tempo de Resposta (ms):} Medido em média, mediana e percentis (P90, P95, P99) para entender a experiência do usuário.
    \item \textbf{Taxa de Requisições por Segundo (RPS):} Indica a vazão (throughput) do sistema.
    \item \textbf{Taxa de Erro (\%):} Percentual de requisições que resultaram em erro (HTTP status >= 400).
    \item \textbf{Estado do Circuit Breaker:} Número de transições entre os estados FECHADO, ABERTO e SEMI-ABERTO.
    \item \textbf{Coeficiente de Variação (CV):} Uma nova métrica estatística adicionada para medir a consistência e a previsibilidade do tempo de resposta. O CV é calculado como a razão entre o desvio padrão e a média. Valores mais baixos indicam maior estabilidade.
\end{itemize}

\section{Resultados e Discussão}
\label{sec:resultados}

Nesta seção, são apresentados e analisados os resultados dos experimentos, comparando o desempenho da versão V1 (Baseline) com a V2 (com Circuit Breaker) em cada um dos cenários de teste propostos.

\subsection{Análise Comparativa de Performance}

A implementação do Circuit Breaker (V2) demonstrou melhorias significativas em múltiplos aspectos, especialmente em cenários de falha e alta carga. Os gráficos a seguir consolidam os resultados de performance e confiabilidade.

\subsubsection{Tempo de Resposta e Taxa de Erro}

A Figura \ref{fig:response-times} compara o tempo de resposta médio e o percentil 95 (P95) entre as versões V1 e V2. A versão V2 apresenta uma redução drástica no tempo de resposta em cenários de falha, como "Alta Concorrência" e "Falha", devido à abertura rápida do circuito, que evita o custo de esperar por requisições que iriam falhar.

\begin{figure}[H]
    \centering
    \includegraphics[width=1.0\textwidth]{images/response_times.png}
    \caption{Comparativo de Tempo de Resposta (Média e P95) entre V1 e V2.}
    \label{fig:response-times}
\end{figure}

A Figura \ref{fig:error-rates} ilustra a taxa de erro. A versão V1 (Baseline) sofre com 100\% de erros em todos os cenários de falha, pois continua a enviar requisições para o serviço indisponível. Em contraste, a versão V2 consegue mitigar o impacto, resultando em uma taxa de erro próxima de zero para o cliente final, pois o Circuit Breaker intercepta as chamadas e retorna uma falha rápida (fail-fast) sem sobrecarregar a dependência.

\begin{figure}[H]
    \centering
    \includegraphics[width=1.0\textwidth]{images/error_rates.png}
    \caption{Comparativo de Taxa de Erro (\%) entre V1 e V2.}
    \label{fig:error-rates}
\end{figure}

\subsubsection{Distribuição da Latência e Consistência}

Para uma análise mais profunda da experiência do usuário, a Figura \ref{fig:distribution-boxplot} apresenta a distribuição dos tempos de resposta através de box plots. Nos cenários de falha, a dispersão dos dados para a V2 é visivelmente menor, indicando uma experiência mais consistente.

\begin{figure}[H]
    \centering
    \includegraphics[width=1.0\textwidth]{images/distribution_boxplot.png}
    \caption{Distribuição do Tempo de Resposta (Box Plot) por Cenário.}
    \label{fig:distribution-boxplot}
\end{figure}

A consistência do sistema foi quantificada usando o Coeficiente de Variação (CV), conforme exibido na Figura \ref{fig:statistical-variability}. Um CV menor significa maior previsibilidade. A versão V2 demonstrou ser mais consistente na maioria dos cenários adversos ("Alta Concorrência", "Falhas Intermitentes", "Recuperação"), o que se traduz em um comportamento de sistema mais estável e confiável sob estresse.

\begin{figure}[H]
    \centering
    \includegraphics[width=1.0\textwidth]{images/statistical_variability.png}
    \caption{Comparativo de Variabilidade do Tempo de Resposta (Coeficiente de Variação).}
    \label{fig:statistical-variability}
\end{figure}

\subsection{Análise por Cenário}

\subsubsection{Cenário de Falha Catastrófica}
Neste cenário, a V1 continuou tentando se comunicar com o serviço indisponível, resultando em tempos de espera longos (timeouts) e uma taxa de erro de 100\%. A V2, após detectar as falhas iniciais, abriu o circuito e passou a rejeitar as requisições imediatamente. Isso protegeu o sistema de uma cascata de falhas, manteve a latência baixa para o cliente (fail-fast) e reduziu o consumo de recursos, como threads e conexões.

\subsubsection{Cenário de Latência Elevada}
Ambas as versões foram impactadas pela lentidão, mas a combinação do Circuit Breaker com um `TimeLimiter` (explorado na versão V3) se mostrou a estratégia mais eficaz. O Circuit Breaker sozinho (V2) não abre o circuito se as requisições estão apenas lentas, mas não falhando. A adição de um timeout força a falha de requisições lentas, o que leva à abertura do circuito e protege o sistema de lentidão em cascata.

\subsubsection{Cenário de Recuperação Pós-Falha}
A V2 demonstrou sua capacidade de auto-recuperação. Após o serviço dependente voltar ao normal, o Circuit Breaker transita para o estado SEMI-ABERTO, permitindo que um número limitado de requisições de teste passe. Ao confirmar o sucesso, ele fecha o circuito e restaura o fluxo normal de tráfego automaticamente, sem intervenção manual. A V1, por outro lado, não possui tal mecanismo e depende de reinicializações ou de uma recuperação manual.

\subsection{Discussão dos Resultados}
Os resultados confirmam que o padrão Circuit Breaker é uma ferramenta poderosa para aumentar a resiliência e a estabilidade de sistemas distribuídos. A principal vantagem observada foi a capacidade de isolar falhas, impedindo que a indisponibilidade ou lentidão de um único serviço se propague e degrade o sistema como um todo. A estratégia de "fail-fast" não apenas melhora a experiência do usuário em momentos de crise, mas também conserva recursos computacionais valiosos.

A análise do Coeficiente de Variação (CV) trouxe uma nova perspectiva, quantificando a previsibilidade do sistema. A redução do CV na versão V2 sob estresse indica que, mesmo em condições adversas, o Circuit Breaker torna o comportamento do sistema mais consistente, o que é fundamental para a operação de sistemas críticos.

\section{Conclusão}
\label{sec:conclusao}

Este trabalho demonstrou, através de um experimento prático e controlado, o impacto positivo da implementação do padrão Circuit Breaker em um sistema de microsserviços. A análise comparativa entre uma versão baseline e uma versão com o padrão implementado revelou melhorias significativas em resiliência, performance percebida pelo usuário e estabilidade geral do sistema.

As principais conclusões são:
\begin{itemize}
    \item \textbf{Isolamento de Falhas:} O Circuit Breaker foi eficaz em isolar o sistema de falhas em suas dependências, prevenindo falhas em cascata e mantendo a aplicação principal responsiva.
    \item \textbf{Melhora na Experiência do Usuário:} Ao adotar uma estratégia de "fail-fast", o padrão reduziu drasticamente os tempos de resposta durante incidentes, evitando que os usuários finais fiquem presos em longas esperas por requisições que inevitavelmente falhariam.
    \item \textbf{Recuperação Automática:} O mecanismo de transição de estados (SEMI-ABERTO) permite que o sistema se recupere automaticamente assim que a dependência volta a operar normalmente, aumentando a disponibilidade sem a necessidade de intervenção manual.
    \item \textbf{Maior Previsibilidade:} A análise do Coeficiente de Variação (CV) mostrou que o Circuit Breaker torna o sistema mais previsível e consistente, mesmo sob condições de estresse e falhas intermitentes.
\end{itemize}

Para trabalhos futuros, sugere-se a exploração de configurações mais dinâmicas para o Circuit Breaker, que possam se adaptar automaticamente às mudanças nas condições do sistema, utilizando, por exemplo, algoritmos de machine learning para ajustar os limiares de falha em tempo real. Outra linha de pesquisa seria a análise comparativa de diferentes implementações do padrão (e.g., Resilience4j, Hystrix, Sentinel) sob os mesmos cenários de teste.

Em suma, o Circuit Breaker provou ser um componente essencial na caixa de ferramentas de qualquer arquiteto ou desenvolvedor que busca construir sistemas distribuídos robustos, confiáveis e resilientes.



% Referências
\bibliography{bibtex/bib/references}

\end{document}
