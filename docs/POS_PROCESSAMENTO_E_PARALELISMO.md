# üìö P√≥s-processamento, Parquet e Paralelismo (Execu√ß√£o + An√°lise)

> **√öltima atualiza√ß√£o:** 21 de dezembro de 2025  
> **Objetivo:** Documentar como o projeto faz p√≥s-processamento dos resultados do k6, como o **NDJSON/JSON vira Parquet (cache)**, como a an√°lise √© executada e como a paraleliza√ß√£o (threads + k6 em paralelo + ambientes isolados) acelera a execu√ß√£o.

---

## üéØ Vis√£o geral do pipeline

A execu√ß√£o ponta-a-ponta segue este fluxo:

1. **Testes de carga (k6)** geram:
   - **NDJSON** (`--out json=...`): arquivos grandes com eventos ‚ÄúPoint‚Äù de m√©tricas
   - **Summary JSON** (`--summary-export ...`): resumo agregado (contagens, rates, percentis)
2. **P√≥s-processamento em Python** l√™ NDJSON e aplica:
   - parsing otimizado (orjson quando dispon√≠vel)
   - **paraleliza√ß√£o (threads)** no parsing de chunks
   - **cache em Parquet** para acelerar reexecu√ß√µes
3. **An√°lises** geram artefatos em `analysis_results/`:
   - relat√≥rios HTML
   - tabelas CSV e tabelas Markdown
   - gr√°ficos (PNG)

O orquestrador padr√£o do pipeline √©:
- [run_everything.sh](run_everything.sh)

---

## üì¶ Formatos e conven√ß√µes de arquivos

### 1) NDJSON do k6 (entrada principal)

Arquivos (cen√°rio completo):
- `k6/results/V1_Completo.json`
- `k6/results/V2_Completo.json`
- `k6/results/V3_Completo.json`

Arquivos (cen√°rios cr√≠ticos):
- `k6/results/scenarios/<cenario>_V1.json`
- `k6/results/scenarios/<cenario>_V2.json`
- `k6/results/scenarios/<cenario>_V3.json`

Observa√ß√£o importante: esses arquivos s√£o ‚ÄúNDJSON‚Äù na pr√°tica (1 JSON por linha), e os scripts de an√°lise filtram linhas que cont√™m `"type":"Point"`.

### 2) Summary JSON do k6 (quantifica√ß√£o confi√°vel)

Arquivos (cen√°rio completo):
- `k6/results/V1_Completo_summary.json` (e V2/V3)

Arquivos (cen√°rios cr√≠ticos):
- `k6/results/scenarios/<cenario>_V1_summary.json` (e V2/V3)

Esse formato √© excelente para **quantificar** volume de requests e dura√ß√£o via:
- `metrics.http_reqs.count`
- `metrics.http_reqs.rate`

### 3) Cache Parquet (p√≥s-processamento)

O Parquet √© usado como **cache de leitura** gerado pelo loader em Python:
- `k6/results/.cache/*.parquet`
- `k6/results/scenarios/.cache/*.parquet`

Esse cache acelera execu√ß√µes subsequentes porque evita reparsear NDJSON gigante.

---

## üß± Como o JSON vira Parquet (cache)

A convers√£o acontece no loader otimizado [analysis/scripts/fast_loader.py](analysis/scripts/fast_loader.py).

### Quando o cache √© usado

- Se existir `*.parquet` correspondente e ele for **mais novo** que o JSON de origem, o loader l√™ direto do Parquet.
- Caso contr√°rio, ele faz o parsing do NDJSON e salva o cache Parquet.

### Escrita do Parquet (compress√£o)

O cache √© salvo com `pyarrow` e compress√£o `snappy`:

```python
df_cache.to_parquet(cache_path, engine='pyarrow', compression='snappy')
```

### Tratamento de colunas complexas (`tags`)

Como `tags` pode ser dict/list, o loader converte para string JSON na grava√ß√£o e tenta reidratar ao ler:

```python
# grava
lambda x: orjson.dumps(x).decode() if isinstance(x, (dict, list)) else x

# leitura
lambda x: orjson.loads(x) if isinstance(x, str) and x.startswith('{') else x
```

---

## üßÆ Como a an√°lise de dados √© feita

### 1) Cen√°rio completo (V1/V2/V3)

O script principal √© [analysis/scripts/analyzer.py](analysis/scripts/analyzer.py).

- Entrada: `k6/results/V*_Completo.json` (via FastK6Loader)
- Sa√≠das: `analysis_results/` (HTML, CSV, Markdown, plots)

Exemplos do que ele calcula:
- `Total Requests` (via m√©trica `http_reqs` dentro do NDJSON)
- lat√™ncia (m√©trica `http_req_duration`) com `Avg`, `P95`, etc
- taxas por status (`200`, `202`, `500`, `503`)

### 2) Cen√°rios cr√≠ticos (cat√°strofe, degrada√ß√£o, rajadas, indisponibilidade, normal)

O script principal √© [analysis/scripts/scenario_analyzer.py](analysis/scripts/scenario_analyzer.py).

- Entrada: `k6/results/scenarios/<cenario>_V*.json` e `*_summary.json`
- Sa√≠das: `analysis_results/scenarios/` (HTML, CSV, plots)

Um detalhe importante: o `scenario_analyzer.py` tamb√©m tenta inferir a dura√ß√£o do teste a partir do summary (`count/rate`) e usa uma dura√ß√£o estimada quando necess√°rio.

### 3) Consolida√ß√£o e gr√°ficos finais

- [analysis/scripts/generate_final_charts.py](analysis/scripts/generate_final_charts.py) consolida CSVs e gera gr√°ficos finais.
- [analysis/scripts/generate_comparison_charts.py](analysis/scripts/generate_comparison_charts.py) gera comparativos focados.
- [analysis/scripts/statistical_analysis.py](analysis/scripts/statistical_analysis.py) e [analysis/scripts/generate_academic_charts.py](analysis/scripts/generate_academic_charts.py) produzem estat√≠stica e gr√°ficos ‚Äúacad√™micos‚Äù.

---

## üìè Quantifica√ß√£o: quantos dados foram analisados (tamanho/quantidade)

Para evitar ‚Äúchutar n√∫meros‚Äù e manter o relat√≥rio sempre reprodut√≠vel, este projeto inclui um gerador de quantifica√ß√£o:

- Script: [analysis/scripts/data_volume_report.py](analysis/scripts/data_volume_report.py)
- Sa√≠da (Markdown): `analysis_results/markdown/RELATORIO_VOLUME_DADOS.md`

### Como gerar

```bash
python3 analysis/scripts/data_volume_report.py
```

### O que o relat√≥rio mede

- **Quantidade de arquivos** NDJSON / summary / Parquet
- **Tamanho total** por categoria
- **NDJSON points**: n√∫mero de linhas que cont√™m `"type":"Point"` (m√©tricas)
- **Total de requests** e **dura√ß√£o estimada** via `*_summary.json` (`http_reqs.count / http_reqs.rate`)
- **Raz√£o Parquet/NDJSON** (quanto o cache Parquet reduz de tamanho, em %)

Relat√≥rio gerado em:
- [analysis_results/markdown/RELATORIO_VOLUME_DADOS.md](analysis_results/markdown/RELATORIO_VOLUME_DADOS.md)

---

## üßµ Multiprocessing/threads no p√≥s-processamento

### Parsing paralelo (ThreadPoolExecutor)

O parsing do NDJSON, quando o arquivo n√£o √© ‚Äúgrande demais‚Äù, √© dividido em chunks e processado em **threads** (mais leve para I/O + parsing):

```python
with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
    results = list(executor.map(_process_chunk, chunks))
```

Isso est√° implementado em [analysis/scripts/fast_loader.py](analysis/scripts/fast_loader.py).

### Reservoir sampling para arquivos muito grandes

Quando o arquivo passa de um limiar (ex.: > 100 MB), o loader ativa reservoir sampling:

```python
use_sampling = file_size_mb > 100
```

Isso mant√©m o p√≥s-processamento execut√°vel mesmo com arquivos enormes, limitando o n√∫mero m√°ximo de pontos carregados.

---

## ‚ö° k6 em paralelo + ambientes isolados (sem interfer√™ncia)

### Execu√ß√£o paralela

O script [run_all_tests_parallel.sh](run_all_tests_parallel.sh) sobe todos os ambientes e executa V1/V2/V3 **simultaneamente** (processos em background), com logs por vers√£o em `.parallel_logs/`.

Trecho essencial:

```bash
run_k6_for_version "v1" &
run_k6_for_version "v2" &
run_k6_for_version "v3" &
wait
```

### Ambientes 100% isolados

O arquivo [docker-compose-parallel.yml](docker-compose-parallel.yml) define um conjunto *dedicado* de containers por vers√£o:

- `servico-pagamento-v1` ‚Üî `servico-adquirente-v1`
- `servico-pagamento-v2` ‚Üî `servico-adquirente-v2`
- `servico-pagamento-v3` ‚Üî `servico-adquirente-v3`

E cada vers√£o exp√µe portas distintas no host (evita colis√£o e evita ‚Äúmisturar tr√°fego‚Äù):
- V1: `8080` / `8091`
- V2: `8082` / `8092`
- V3: `8083` / `8093`

No script paralelo, o k6 aponta para o container espec√≠fico via rede Docker:

```bash
-e "PAYMENT_BASE_URL=http://${container}:8080"
```

### Ganho de tempo (observado)

O reposit√≥rio documenta a economia de tempo como **~60%** no modo paralelo:
- [run_all_tests_parallel.sh](run_all_tests_parallel.sh)
- [run_everything.sh](run_everything.sh)

Sugest√£o para ‚Äúfechar‚Äù isso com n√∫meros exatos na escrita do TCC: use timestamps de in√≠cio/fim do pipeline (ou logs) e compare execu√ß√£o sequencial vs paralela.

---

## ‚úÖ Como rodar tudo (incluindo an√°lise)

- Pipeline completo (sequencial):

```bash
./run_everything.sh
```

- Pipeline completo (paralelo V1/V2/V3):

```bash
./run_everything.sh --parallel
```

Depois, para (re)gerar a quantifica√ß√£o em Markdown:

```bash
python3 analysis/scripts/data_volume_report.py
```
