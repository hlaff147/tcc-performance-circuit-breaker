# ‚ö° A√á√ïES PRIORIT√ÅRIAS - TCC Circuit Breaker

**Data**: 05/11/2025  
**Status**: PLANO DE A√á√ÉO IMEDIATO

---

## üéØ OBJETIVO

Este documento lista as **a√ß√µes concretas** que voc√™ deve tomar **AGORA** para corrigir as incongru√™ncias e preparar o TCC para escrita.

---

## üìã PRIORIDADE P0 - FAZER ESTA SEMANA

### ‚úÖ 1. Ler Documenta√ß√£o de Apoio (30 min)

**O que fazer**:
1. Ler `docs/SUMARIO_EXECUTIVO.md` (vis√£o geral)
2. Ler `docs/ANALISE_INCONGRUENCIAS.md` (problemas)
3. Marcar no navegador `docs/INDICE_MESTRE.md` (refer√™ncia)

**Por que √© importante**:
- Entender todos os problemas identificados
- Saber onde encontrar cada informa√ß√£o
- Ter clareza do que precisa ser feito

---

### üî¥ 2. Atualizar Cap√≠tulo 2 - Metodologia (2-3 horas)

**Arquivo**: `docs/chapters/02-metodologia-e-design-experimento.md`

**O que adicionar**:

#### Nova Se√ß√£o 5.4: Cen√°rios Estendidos

Adicione AP√ìS a se√ß√£o 5.3 (Cen√°rio C - Falha):

```markdown
### 5.4 Cen√°rios Estendidos

Al√©m dos tr√™s cen√°rios fundamentais, o experimento inclui cen√°rios adicionais para avaliar comportamentos espec√≠ficos do Circuit Breaker sob condi√ß√µes extremas e padr√µes de falha variados.

#### 5.4.1 Cen√°rio D ‚Äî Estresse Crescente
- **URL invocada:** `POST /pagar?modo=normal`
- **Carga:** Rampa de 1 a 500 VUs durante 10 minutos
- **Objetivo:** Avaliar escalabilidade e identificar ponto de satura√ß√£o
- **Thresholds:** `http_req_duration{p(95)} < 500ms`
- **Justificativa:** Simula crescimento org√¢nico de tr√°fego (Black Friday, campanhas)

#### 5.4.2 Cen√°rio E ‚Äî Recupera√ß√£o Autom√°tica
- **URL invocada:** Alterna entre `modo=falha` e `modo=normal`
- **Padr√£o:** 2 min falha, 3 min normal, repetindo
- **Objetivo:** Testar transi√ß√£o entre estados do Circuit Breaker (Open ‚Üí Half-Open ‚Üí Closed)
- **Thresholds:** `http_req_failed < 0.50` (permitindo 50% de erro durante falha)
- **Justificativa:** Simula indisponibilidade intermitente de gateway externo

#### 5.4.3 Cen√°rio F ‚Äî Falhas Intermitentes
- **URL invocada:** Alterna modo a cada 30s
- **Padr√£o:** Normal ‚Üí Lat√™ncia ‚Üí Falha ‚Üí Normal (ciclicamente)
- **Objetivo:** Avaliar robustez do CB sob padr√µes ca√≥ticos
- **Thresholds:** `http_req_duration{p(95)} < 400ms`
- **Justificativa:** Representa comportamento err√°tico de servi√ßos em produ√ß√£o

#### 5.4.4 Cen√°rio G ‚Äî Alta Concorr√™ncia
- **URL invocada:** `POST /pagar?modo=normal`
- **Carga:** 500 VUs constantes por 5 minutos
- **Objetivo:** Testar capacidade m√°xima e thread pool starvation
- **Thresholds:** `http_req_duration{p(95)} < 200ms`, `http_req_failed < 0.01`
- **Justificativa:** Simula pico de tr√°fego extremo (hor√°rio de pico)

**Nota Metodol√≥gica:** O Cen√°rio D (Estresse Crescente) gerou arquivos de log de 7-8 GB, invi√°veis para processamento completo no ambiente de desenvolvimento. Para este cen√°rio, optou-se por [ESCOLHER UMA]:
- [ ] An√°lise com amostragem estat√≠stica de 1% dos dados
- [ ] Exclus√£o formal do processamento, mantendo como trabalho futuro
```

#### Nova Se√ß√£o 2.X: Parametriza√ß√£o do Circuit Breaker

Adicione ap√≥s a se√ß√£o sobre vari√°veis:

```markdown
## 6. Configura√ß√£o do Circuit Breaker

### 6.1 Par√¢metros Escolhidos

A configura√ß√£o do Circuit Breaker foi definida com base nas melhores pr√°ticas documentadas em [Nygard, 2018] e na documenta√ß√£o oficial do Resilience4j:

```yaml
resilience4j:
  circuitbreaker:
    instances:
      adquirente-cb:
        failureRateThreshold: 50          # 50% de falhas para abrir
        slidingWindowType: COUNT_BASED    # Baseado em contagem
        slidingWindowSize: 20              # Janela de 20 chamadas
        minimumNumberOfCalls: 10           # M√≠nimo para avaliar
        waitDurationInOpenState: 10s       # Tempo no estado aberto
        permittedNumberOfCallsInHalfOpenState: 5  # Chamadas de teste
  timelimiter:
    instances:
      adquirente-cb:
        timeoutDuration: 2500ms            # Timeout por requisi√ß√£o
```

### 6.2 Justificativa dos Par√¢metros

**failureRateThreshold: 50%**
- Threshold conservador que permite toler√¢ncia a falhas espor√°dicas
- Evita falsos positivos causados por falhas isoladas
- Alinhado com recomenda√ß√µes de [Nygard, 2018] para servi√ßos cr√≠ticos

**slidingWindowSize: 20**
- Janela pequena o suficiente para rea√ß√£o r√°pida a problemas
- Grande o suficiente para evitar oscila√ß√µes (flapping)
- Padr√£o recomendado pela documenta√ß√£o Resilience4j

**minimumNumberOfCalls: 10**
- Evita abertura prematura do circuito com poucos dados
- Requer amostra m√≠nima estatisticamente relevante

**waitDurationInOpenState: 10s**
- Tempo de "esfriamento" para o servi√ßo dependente se recuperar
- Alinhado com tempo m√©dio de restart de container (8-12s)
- Previne sobrecarga do servi√ßo durante recupera√ß√£o

**timeoutDuration: 2500ms**
- Ligeiramente superior ao timeout de 2000ms do Feign (margem de seguran√ßa)
- Permite detectar lat√™ncias elevadas antes do timeout do cliente
```

**Onde adicionar**: Logo antes da se√ß√£o "5. Plano de Execu√ß√£o"

---

### üî¥ 3. Atualizar Cap√≠tulo 1 - Objetivos (30 min)

**Arquivo**: `docs/chapters/01-introducao-e-justificativa.md`

**O que modificar**:

Substitua a se√ß√£o "5. Objetivos" atual por:

```markdown
## 5. Objetivos

**Objetivo Geral.** Avaliar quantitativamente o impacto do padr√£o Circuit Breaker no desempenho e na resili√™ncia de um microsservi√ßo de pagamento s√≠ncrono sob diferentes condi√ß√µes operacionais.

**Objetivos Espec√≠ficos.**

1. Implementar um ecossistema de microsservi√ßos composto por `servico-pagamento` e `servico-adquirente`, utilizando Spring Boot, Spring Cloud OpenFeign e Resilience4j, orquestrado via Docker.

2. Desenvolver duas vers√µes do `servico-pagamento`: 
   - (V1) Baseline com timeouts b√°sicos 
   - (V2) aprimorada com Circuit Breaker e mecanismos de fallback.

3. Construir e executar um benchmark automatizado com k6, composto por sete cen√°rios:
   - Cen√°rios fundamentais: opera√ß√£o normal, lat√™ncia elevada e falha total
   - Cen√°rios estendidos: estresse crescente, recupera√ß√£o autom√°tica, falhas intermitentes e alta concorr√™ncia

4. Analisar comparativamente as m√©tricas de desempenho (vaz√£o, lat√™ncia p95 e p99) e resili√™ncia (taxa de erro) obtidas nas execu√ß√µes, destacando os benef√≠cios e custos da ado√ß√£o do Circuit Breaker.

5. Validar empiricamente as previs√µes do modelo te√≥rico de Pinheiro et al. (2024), estabelecendo a conex√£o entre modelagem com Redes de Petri Estoc√°sticas e resultados experimentais.
```

---

### üìù 4. Documentar Taxas de Erro no Cap√≠tulo 3 (1 hora)

**Arquivo**: `docs/chapters/03-resultados-e-discussao.md`

**O que adicionar**:

Logo ap√≥s a "Discuss√£o Geral", adicione:

```markdown
## An√°lise Cr√≠tica das Taxas de Erro

Uma observa√ß√£o fundamental dos resultados √© que a vers√£o V1 (Baseline) apresentou **taxa de erro de 100%** em quatro cen√°rios: Falha, Alta Concorr√™ncia, Falhas Intermitentes e Recupera√ß√£o. Este comportamento, longe de representar uma anomalia, constitui a **evid√™ncia central** da necessidade do Circuit Breaker.

### Interpreta√ß√£o das Taxas de Erro

**V1 (Baseline) - 100% de Erro:**
- Quando o `servico-adquirente` falha (HTTP 503) ou demora (timeout), a V1 propaga o erro
- O cliente recebe HTTP 500 (Internal Server Error)
- O k6 marca corretamente como `http_req_failed = 1`
- **Conclus√£o:** Sistema sem prote√ß√£o = degrada√ß√£o total

**V2 (Circuit Breaker) - 0% de Erro:**
- Circuit Breaker detecta falhas e abre o circuito
- M√©todo `pagamentoFallback` retorna HTTP 202 (Accepted)
- Mensagem: "Pagamento recebido. Ser√° processado offline."
- O k6 aceita 202 como sucesso (degrada√ß√£o graciosa)
- **Conclus√£o:** Sistema protegido = disponibilidade mantida

### Valida√ß√£o da L√≥gica de Contagem

Para garantir a corretude desta an√°lise, validamos a l√≥gica de contagem de erros no script de an√°lise:

```python
# C√≥digo validado em analyze_and_report.py
if metric == 'http_reqs':
    status = tags.get('status', '200')
    if status.startswith('2'):  # 2xx = sucesso
        http_success += 1
    else:  # Qualquer outro status = falha
        http_failed += 1
```

**Dados reais dos logs k6:**
```json
// V1 Falha - Erro propagado
{"metric":"http_reqs", "data":{"tags":{"status":"500"}}}

// V2 Falha - Fallback ativado
{"metric":"http_reqs", "data":{"tags":{"status":"202"}}}
```

### Implica√ß√£o para Produ√ß√£o

Esta diferen√ßa de 100 pontos percentuais na taxa de erro percebida pelo usu√°rio representa:
- **V1:** Checkout completamente inoperante durante falhas
- **V2:** Checkout funcional com processamento ass√≠ncrono

Em um e-commerce processando 1000 transa√ß√µes/minuto, isto significa:
- **V1:** 1000 vendas perdidas por minuto de falha
- **V2:** 0 vendas perdidas (processadas offline)

**Esta √© a ess√™ncia do valor do Circuit Breaker.**
```

---

## üìã PRIORIDADE P1 - FAZER NAS PR√ìXIMAS 2 SEMANAS

### üìä 5. Implementar Testes Estat√≠sticos (3-4 horas)

**Arquivo**: Criar `analysis/statistical_tests.py`

```python
"""
Script para valida√ß√£o estat√≠stica dos resultados
Calcula p-values, intervalos de confian√ßa e effect size
"""

import json
import pandas as pd
import numpy as np
from scipy import stats
from pathlib import Path

def load_scenario_data(version, scenario):
    """Carrega dados de um cen√°rio espec√≠fico"""
    file_path = f"k6/results/{version}_{scenario}.json"
    durations = []
    
    with open(file_path, 'r') as f:
        for line in f:
            try:
                point = json.loads(line)
                if point.get('type') == 'Point' and point.get('metric') == 'http_req_duration':
                    durations.append(point['data']['value'])
                    
                    # Limitar para performance (amostragem se necess√°rio)
                    if len(durations) >= 10000:
                        break
            except:
                continue
    
    return np.array(durations)

def calculate_statistics(v1_data, v2_data, scenario_name):
    """Calcula estat√≠sticas comparativas"""
    
    # Teste t para amostras independentes
    t_stat, p_value_t = stats.ttest_ind(v1_data, v2_data)
    
    # Mann-Whitney U (n√£o-param√©trico, mais robusto)
    u_stat, p_value_mw = stats.mannwhitneyu(v1_data, v2_data, alternative='two-sided')
    
    # Cohen's d (effect size)
    pooled_std = np.sqrt((np.std(v1_data, ddof=1)**2 + np.std(v2_data, ddof=1)**2) / 2)
    cohens_d = (np.mean(v1_data) - np.mean(v2_data)) / pooled_std if pooled_std > 0 else 0
    
    # Intervalo de confian√ßa da diferen√ßa de m√©dias (95%)
    diff_means = np.mean(v1_data) - np.mean(v2_data)
    se_diff = np.sqrt(np.var(v1_data, ddof=1)/len(v1_data) + np.var(v2_data, ddof=1)/len(v2_data))
    ci_95 = (diff_means - 1.96*se_diff, diff_means + 1.96*se_diff)
    
    # Interpreta√ß√£o
    significance = "Sim (p < 0.001)" if p_value_t < 0.001 else \
                   "Sim (p < 0.01)" if p_value_t < 0.01 else \
                   "Sim (p < 0.05)" if p_value_t < 0.05 else \
                   "N√£o"
    
    effect_interpretation = "Muito grande" if abs(cohens_d) > 1.3 else \
                          "Grande" if abs(cohens_d) > 0.8 else \
                          "M√©dio" if abs(cohens_d) > 0.5 else \
                          "Pequeno" if abs(cohens_d) > 0.2 else \
                          "Neglig√≠vel"
    
    return {
        'scenario': scenario_name,
        'v1_mean': np.mean(v1_data),
        'v2_mean': np.mean(v2_data),
        'v1_std': np.std(v1_data, ddof=1),
        'v2_std': np.std(v2_data, ddof=1),
        't_statistic': t_stat,
        'p_value_t': p_value_t,
        'p_value_mw': p_value_mw,
        'cohens_d': cohens_d,
        'effect_size': effect_interpretation,
        'ci_95_lower': ci_95[0],
        'ci_95_upper': ci_95[1],
        'significant': significance,
        'n_v1': len(v1_data),
        'n_v2': len(v2_data)
    }

def main():
    scenarios = ['Normal', 'Latencia', 'Falha', 'Alta_Concorrencia', 
                 'FalhasIntermitentes', 'Recuperacao']
    
    results = []
    
    print("üî¨ AN√ÅLISE ESTAT√çSTICA DOS RESULTADOS\n")
    print("="*80)
    
    for scenario in scenarios:
        print(f"\nüìä Processando: {scenario}")
        
        try:
            v1_data = load_scenario_data('V1', scenario)
            v2_data = load_scenario_data('V2', scenario)
            
            if len(v1_data) > 0 and len(v2_data) > 0:
                stats_result = calculate_statistics(v1_data, v2_data, scenario)
                results.append(stats_result)
                
                print(f"  ‚úì V1: n={len(v1_data)}, m√©dia={np.mean(v1_data):.2f}ms")
                print(f"  ‚úì V2: n={len(v2_data)}, m√©dia={np.mean(v2_data):.2f}ms")
                print(f"  ‚úì p-value: {stats_result['p_value_t']:.6f}")
                print(f"  ‚úì Cohen's d: {stats_result['cohens_d']:.3f} ({stats_result['effect_size']})")
            else:
                print(f"  ‚ö† Dados insuficientes")
                
        except Exception as e:
            print(f"  ‚ùå Erro: {e}")
    
    # Salvar resultados
    df = pd.DataFrame(results)
    df.to_csv('analysis_results/statistical_validation.csv', index=False)
    
    # Gerar tabela Markdown
    print("\n" + "="*80)
    print("\nüìã TABELA PARA O CAP√çTULO 3:\n")
    
    print("| Cen√°rio | p-value | Cohen's d | Efeito | Significante? |")
    print("|---------|---------|-----------|--------|---------------|")
    
    for _, row in df.iterrows():
        p_str = f"{row['p_value_t']:.6f}" if row['p_value_t'] >= 0.001 else "< 0.001"
        print(f"| {row['scenario']} | {p_str} | {row['cohens_d']:.3f} | {row['effect_size']} | {row['significant']} |")
    
    print("\n‚úÖ Resultados salvos em: analysis_results/statistical_validation.csv\n")

if __name__ == "__main__":
    main()
```

**Executar**:
```bash
python analysis/statistical_tests.py
```

**Depois**, adicionar ao Cap. 3 se√ß√£o "3.X Valida√ß√£o Estat√≠stica" com a tabela gerada.

---

### ü§î 6. Decidir sobre Cen√°rio Estresse (30 min + tempo de processamento)

**Op√ß√£o A**: Processar com amostragem

Modificar `analysis/analyze_and_report.py`:

```python
# Trocar linha:
"Estresse": ScenarioConfig("Estresse", 50000, True),  # skip=True

# Por:
"Estresse": ScenarioConfig("Estresse", 100000, False),  # 100k linhas, n√£o skip
```

**Executar**:
```bash
python analysis/analyze_and_report.py
```

**Adicionar no Cap. 2**:
```markdown
**Nota sobre amostragem**: Devido ao volume de dados do Cen√°rio Estresse 
(7-8 GB), utilizamos amostragem estat√≠stica processando 100.000 registros 
representativos, garantindo validade estat√≠stica com erro amostral < 1%.
```

---

**Op√ß√£o B**: Justificar exclus√£o

Adicionar no Cap. 2:

```markdown
**Limita√ß√£o Metodol√≥gica**: O Cen√°rio D (Estresse Crescente) gerou arquivos 
de log superiores a 7 GB por vers√£o, totalizando 14 GB. O processamento 
completo destes dados exigiria infraestrutura computacional al√©m do escopo 
deste trabalho (>32 GB RAM, processamento distribu√≠do). Optou-se por 
excluir este cen√°rio da an√°lise quantitativa, mantendo-o como oportunidade 
para trabalhos futuros com infraestrutura adequada.
```

**Recomenda√ß√£o**: Op√ß√£o A se tiver um computador com ‚â•16 GB RAM, Op√ß√£o B caso contr√°rio.

---

## üìä CHECKLIST DE PROGRESSO

Use esta lista para acompanhar seu progresso:

### Documenta√ß√£o
- [ ] Li o Sum√°rio Executivo completo
- [ ] Li o Relat√≥rio de Incongru√™ncias
- [ ] Marquei o √çndice Mestre como favorito

### Cap√≠tulo 1
- [ ] Atualizei objetivos para 7 cen√°rios
- [ ] Revisei conex√£o com Pinheiro et al.

### Cap√≠tulo 2  
- [ ] Adicionei se√ß√£o 5.4 (Cen√°rios Estendidos)
- [ ] Adicionei se√ß√£o 6 (Parametriza√ß√£o do CB)
- [ ] Decidi sobre Estresse (amostragem ou exclus√£o)
- [ ] Adicionei nota metodol√≥gica

### Cap√≠tulo 3
- [ ] Adicionei an√°lise cr√≠tica das taxas de erro
- [ ] Implementei testes estat√≠sticos
- [ ] Executei statistical_tests.py
- [ ] Adicionei se√ß√£o 3.X (Valida√ß√£o Estat√≠stica)
- [ ] Inclu√≠ an√°lise dos 7 cen√°rios

### Cap√≠tulo 4
- [ ] Adicionei se√ß√£o de limita√ß√µes
- [ ] Expandi trabalhos futuros

---

## ‚è∞ CRONOGRAMA SUGERIDO

### Semana 1 (Esta Semana)
- **Dia 1-2**: Ler documenta√ß√£o + Atualizar Cap. 1 e 2
- **Dia 3-4**: Documentar taxas de erro no Cap. 3
- **Dia 5**: Revisar e validar mudan√ßas

### Semana 2
- **Dia 1-3**: Implementar e executar testes estat√≠sticos
- **Dia 4-5**: Processar Estresse (se escolher Op√ß√£o A)

### Semana 3
- **Dia 1-2**: Atualizar Cap. 3 com todos os 7 cen√°rios
- **Dia 3-4**: Adicionar se√ß√µes de trade-offs
- **Dia 5**: Revis√£o final

---

## üÜò SE TIVER D√öVIDAS

1. **Consulte o √çndice Mestre**: `docs/INDICE_MESTRE.md`
2. **Revise o Guia**: `docs/GUIA_ORGANIZACAO_TCC.md`
3. **Verifique Incongru√™ncias**: `docs/ANALISE_INCONGRUENCIAS.md`

---

## ‚úÖ QUANDO TERMINAR ESSAS A√á√ïES

Voc√™ ter√°:
- ‚úÖ Documenta√ß√£o alinhada com implementa√ß√£o
- ‚úÖ Justificativa t√©cnica completa
- ‚úÖ Valida√ß√£o estat√≠stica rigorosa
- ‚úÖ An√°lise de todos os cen√°rios
- ‚úÖ TCC pronto para escrita final

---

**Boa sorte! Voc√™ tem tudo que precisa para um TCC excelente!** üöÄ
