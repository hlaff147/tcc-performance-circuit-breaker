# ğŸ“Š AnÃ¡lise Final Consolidada - Circuit Breaker TCC

## ğŸ§­ VisÃ£o Geral
Este documento apresenta a **anÃ¡lise completa e definitiva** dos experimentos realizados para o TCC sobre padrÃµes de resiliÃªncia com Circuit Breaker. Todos os testes foram executados com a **configuraÃ§Ã£o otimizada de alta disponibilidade** (`profile: BALANCED`) descrita em `CB_PERFIS_CONFIGURACAO.md`.

### ğŸ¯ Objetivos da AnÃ¡lise
1. **Quantificar ganhos mensurÃ¡veis** de disponibilidade e estabilidade com Circuit Breaker (Resilience4j).
2. **Medir impacto na experiÃªncia do usuÃ¡rio** atravÃ©s de tempo de resposta e distribuiÃ§Ã£o de cÃ³digos HTTP.
3. **Validar hipÃ³teses** sobre comportamento em cenÃ¡rios crÃ­ticos: falhas catastrÃ³ficas, degradaÃ§Ã£o gradual, rajadas intermitentes e indisponibilidade extrema (API 75% off).
4. **Identificar trade-offs** entre resiliÃªncia, throughput e latÃªncia.
5. **Gerar evidÃªncias visuais** para comparaÃ§Ã£o V1 (sem CB) vs V2 (com CB).

### ğŸ”¬ Metodologia Experimental
- **Ferramenta de carga:** K6 (testes de carga distribuÃ­dos)
- **Arquitetura testada:** MicroserviÃ§o de pagamentos â†’ ServiÃ§o adquirente (simulado com falhas controlÃ¡veis)
- **VersÃµes comparadas:**
  - **V1:** Payment Service sem Circuit Breaker (baseline)
  - **V2:** Payment Service com Resilience4j Circuit Breaker + Fallback
- **ConfiguraÃ§Ã£o do CB:** 
  - `failureRateThreshold: 50%`
  - `slowCallRateThreshold: 70%`
  - `slowCallDurationThreshold: 3s`
  - `slidingWindowSize: 10` requisiÃ§Ãµes
  - `minimumNumberOfCalls: 5`
  - `waitDurationInOpenState: 10s`
  - `permittedNumberOfCallsInHalfOpenState: 3`
- **Monitoramento:** Prometheus + Grafana (mÃ©tricas em tempo real)
- **AnÃ¡lise:** Scripts Python (pandas, matplotlib, seaborn) para geraÃ§Ã£o de grÃ¡ficos e estatÃ­sticas

---

## ğŸ“Œ Resumo Executivo

### Resultados Consolidados
| CenÃ¡rio | Objetivo | Sucesso V1 | Disponibilidade V2 (200+202) | Fallback V2 | ReduÃ§Ã£o de Falhas | Insight chave |
|---------|----------|------------|-----------------------------|-------------|-------------------|---------------|
| **Falha CatastrÃ³fica** | Manter o serviÃ§o mesmo com fornecedor offline | 90,0% | **94,5%** | 59,0% | **44,8%** | CB absorve 36,9k requisiÃ§Ãµes via fallback e mantÃ©m a experiÃªncia estÃ¡vel. |
| **DegradaÃ§Ã£o Gradual** | Proteger contra aumento progressivo de erros | 94,7% | **94,9%** | 0,0% | **4,2%** | CB evita regressÃµes mesmo sem abrir agressivamente; latÃªncia segue controlada. |
| **Rajadas Intermitentes** | Amortecer picos breves de indisponibilidade | 94,9% | **95,2%** | 10,2% | **5,8%** | 8,4k requisiÃ§Ãµes sÃ£o servidas por fallback enquanto a API real oscila. |
| **Indisponibilidade Extrema (75% OFF)** | Demonstrar o limite mÃ¡ximo de ganho do CB | 10,1% | **97,1%** | 92,8% | **96,8%** | CB reduz o downtime de 487s para 16s e mantÃ©m quase 100% dos clientes atendidos. |

> **Fallback na prÃ¡tica:** disponibilidade total = HTTP 200/201 + HTTP 202. Nos cenÃ¡rios com fallback ativo (catÃ¡strofe, rajadas e indisponibilidade extrema) ele Ã© responsÃ¡vel pela maior parte da continuidade do serviÃ§o.

### ğŸ¯ Principais Descobertas
1. âœ… **Disponibilidade com CB fica â‰¥94% em todos os cenÃ¡rios e alcanÃ§a 97%** na indisponibilidade extrema, enquanto o baseline caiu para 10%.
2. âœ… **Fallback responde de 59% a 93% das requisiÃ§Ãµes** nas falhas massivas, entregando HTTP 202 previsÃ­vel em vez de 500/503.
3. âœ… **Falhas efetivas despencam entre 4% e 97%** (45% na catÃ¡strofe e 97% no cenÃ¡rio 75% OFF), mantendo a experiÃªncia consistente.
4. âœ… **Downtime comparativo mostra ganhos claros:** 487s â†’ 16s na indisponibilidade extrema e 78s â†’ 43s na catÃ¡strofe (GrÃ¡fico 11).
5. âš–ï¸ **Trade-offs permanecem baixos:** throughput fica dentro da mesma ordem de magnitude e o short-circuit reduz a latÃªncia mÃ©dia em 60% (catÃ¡strofe) e 75% (indisponibilidade), mesmo com P99 prÃ³ximos devido a timeouts herdados.

### ğŸ“Š VisualizaÃ§Ãµes Geradas
Os grÃ¡ficos a seguir foram gerados com Python (matplotlib + seaborn) a partir dos dados consolidados dos experimentos:

![Taxa de Sucesso por CenÃ¡rio](analysis_results/final_charts/01_success_rates_comparison.png)
*Figura 1: ComparaÃ§Ã£o de taxa de sucesso entre V1 e V2 nos quatro cenÃ¡rios*

![ReduÃ§Ã£o de Falhas](analysis_results/final_charts/02_failure_reduction.png)
*Figura 2: ReduÃ§Ã£o absoluta e percentual de falhas HTTP 500 com Circuit Breaker*

![Tempo MÃ©dio de Resposta](analysis_results/final_charts/09_avg_response_times.png)
*Figura 3: MÃ©dias de tempo de resposta destacando o ganho do short-circuit nos cenÃ¡rios mais severos*

![Taxa de Erro HTTP 500](analysis_results/final_charts/10_error_rates.png)
*Figura 4: Comparativo direto das taxas de erro 500 por cenÃ¡rio e versÃ£o*

![Downtime e Disponibilidade](analysis_results/final_charts/11_downtime_availability.png)
*Figura 5: Tempo de inatividade absoluto e disponibilidade relativa (V1 vs V2) com destaque para o cenÃ¡rio 75% OFF*

Os demais grÃ¡ficos (percentis, throughput, distribuiÃ§Ã£o de status, radar consolidado, timeline e contribuiÃ§Ã£o do fallback) tambÃ©m foram atualizados e estÃ£o no diretÃ³rio `analysis_results/final_charts/`. O relatÃ³rio tabular (`analysis_results/final_charts/summary_table.md`) consolida os nÃºmeros usados nesta anÃ¡lise.



---

## 1ï¸âƒ£ CenÃ¡rio: Falha CatastrÃ³fica

### ğŸ“‹ DescriÃ§Ã£o do Experimento
**Objetivo:** manter a aplicaÃ§Ã£o disponÃ­vel enquanto o adquirente fica 100% indisponÃ­vel por cinco minutos ininterruptos.

**ConfiguraÃ§Ã£o do teste (K6):**
- **DuraÃ§Ã£o total:** 13 minutos (780 s) com ramp-ups progressivos (50 â†’ 150 VUs)
- **Janela de falha:** entre os minutos 4 e 9 (`modo=falha` forÃ§ado)
- **CritÃ©rio de sucesso:** V2 deve short-circuitar rapidamente e responder com fallback 202 durante toda a janela crÃ­tica

### ğŸ“Š Resultados Quantitativos

| MÃ©trica | V1 (Sem CB) | V2 (Com CB) |
|---------|-------------|-------------|
| **Total de requisiÃ§Ãµes** | 48.445 | 62.562 |
| **HTTP 200 (sucesso real)** | 43.608 (90,0%) | 22.201 (35,5%) |
| **HTTP 202 (fallback)** | 0 | 36.912 (59,0%) |
| **HTTP 500 (falha)** | 4.836 (10,0%) | 3.446 (5,5%) |
| **Disponibilidade total** | 90,0% | **94,5%** |
| **Tempo mÃ©dio** | 610 ms | **244 ms** |
| **Tempo p95** | 3,01 s | 3,01 s |
| **Fast requests (%)** | 79,9% | **92,0%** |
| **Throughput mÃ©dio** | 62 req/s | 80 req/s |
| **Downtime efetivo** | 78 s | **43 s** |

### ğŸ“ˆ VisualizaÃ§Ãµes

- `analysis_results/final_charts/05_status_distribution.png`: comparaÃ§Ã£o direta dos status retornados (pizza superior).
- `analysis_results/final_charts/07_catastrofe_timeline.png`: evidencia a abertura rÃ¡pida do CB e o perÃ­odo longo em fallback.
- `analysis_results/final_charts/08_fallback_contribution.png`: mostra que 59% das respostas da V2 vieram do fallback.

### ğŸ” AnÃ¡lise e Insights

#### âœ… BenefÃ­cios do Circuit Breaker
1. **59% das requisiÃ§Ãµes sÃ£o mantidas no fallback**, evitando que usuÃ¡rios recebam 500 durante todo o blackout.
2. **Falhas efetivas caem 44,8%** (4.836 â†’ 3.446) e a disponibilidade total sobe para 94,5%.
3. **Tempo mÃ©dio cai 60%** porque as respostas 202 retornam quase instantaneamente.
4. **Downtime reduzido em 45%** (78 s â†’ 43 s) no comparativo consolidado.

#### âš ï¸ Trade-offs Observados
- **Menos HTTP 200 â€œpurosâ€** (35,5%): o sistema opta por 202 durante a janela crÃ­tica.
- **P95/P99 continuam prÃ³ximos de 3 s** por causa das tentativas periÃ³dicas de HALF_OPEN.

#### ğŸ’¡ InterpretaÃ§Ã£o
O CB atua como um â€œdisjuntorâ€ real: assim que a catÃ¡strofe comeÃ§a ele abre, devolve respostas 202 e somente volta a chamar o adquirente quando detecta sinais de recuperaÃ§Ã£o. Sem essa proteÃ§Ã£o, 4,8 mil falhas teriam virado HTTP 500; com CB, elas sÃ£o absorvidas e o sistema segue responsivo.


---

## 2ï¸âƒ£ CenÃ¡rio: DegradaÃ§Ã£o Gradual

### ğŸ“‹ DescriÃ§Ã£o do Experimento
**Objetivo:** validar se o CB interfere negativamente quando a falha cresce de forma progressiva, mas ainda existe uma quantidade razoÃ¡vel de respostas vÃ¡lidas.

**ConfiguraÃ§Ã£o do teste (K6):**
- **DuraÃ§Ã£o total:** 13 minutos (780 s)
- **VUs:** 100 â†’ 200 e retorno para 100, simulando carga normal â†’ crÃ­tica â†’ recuperaÃ§Ã£o
- **Perfil de falha:** 5% de erro inicial â†’ 20% â†’ 50% â†’ 15% (parÃ¢metros `failureRate/latencyRate` do script)
- **Expectativa:** o CB deve permanecer quase sempre CLOSED, usando apenas timeout otimizado para proteger o serviÃ§o.

### ğŸ“Š Resultados Quantitativos

| MÃ©trica | V1 (Sem CB) | V2 (Com CB) |
|---------|-------------|-------------|
| **Total de requisiÃ§Ãµes** | 67.964 | 68.059 |
| **HTTP 200 (sucesso real)** | 64.378 (94,7%) | 64.618 (94,9%) |
| **HTTP 202 (fallback)** | 0 | 0 |
| **HTTP 500 (falha)** | 3.585 (5,3%) | 3.438 (5,1%) |
| **Disponibilidade total** | 94,7% | **94,9%** |
| **Tempo mÃ©dio** | 457 ms | 455 ms |
| **Tempo p95** | 3,01 s | 3,01 s |
| **Fast requests (%)** | 84,9% | 85,0% |
| **Throughput mÃ©dio** | 87 req/s | 87 req/s |
| **Downtime efetivo** | 41,2 s | **39,5 s** |

### ğŸ“ˆ VisualizaÃ§Ãµes

- `analysis_results/final_charts/03_response_time_percentiles.png`: mostra que os percentis permanecem alinhados entre V1 e V2.
- `analysis_results/final_charts/04_throughput_comparison.png`: destaca o throughput praticamente idÃªntico.
- `analysis_results/final_charts/10_error_rates.png`: evidencia a pequena diferenÃ§a de taxa de erro.

### ğŸ” AnÃ¡lise e Insights

#### âœ… BenefÃ­cios do Circuit Breaker
1. **ReduÃ§Ã£o modesta de falhas (4,2%)** sem alterar significativamente a carga.
2. **CB permanece fechado** â€” confirma que o tuning (threshold 50%) evita intervenÃ§Ãµes desnecessÃ¡rias.
3. **Timeout e limiares otimizados** bastam para proteger o serviÃ§o atÃ© que a degradaÃ§Ã£o seja crÃ­tica.

#### âš ï¸ Trade-offs Observados
- **Ganho limitado**: como nÃ£o houve abertura do CB, os benefÃ­cios aparecem apenas em ajustes finos de latÃªncia/timeouts.
- **P99 permanece prÃ³ximo** (â‰ˆ3 s) porque ainda dependemos do comportamento do fornecedor durante a fase crÃ­tica.

#### ğŸ’¡ InterpretaÃ§Ã£o
Este cenÃ¡rio garante que o CB **nÃ£o degrada cenÃ¡rios moderados**: mesmo com metade das chamadas falhando no pico, ele nÃ£o abre indevidamente. O ganho de ~200 requisiÃ§Ãµes a mais respondidas com sucesso mostra que o ajuste de timeouts e o monitoramento constante sÃ£o suficientes atÃ© que a falha ultrapasse o threshold.


---

## 3ï¸âƒ£ CenÃ¡rio: Rajadas Intermitentes

### ğŸ“‹ DescriÃ§Ã£o do Experimento
**Objetivo:** avaliar a velocidade com que o CB alterna entre CLOSED/OPEN/HALF_OPEN quando ocorrem pulsos curtos de 100% falha intercalados com perÃ­odos normais.

**ConfiguraÃ§Ã£o do teste (K6):**
- **DuraÃ§Ã£o total:** 13 minutos (â‰ˆ782 s)
- **Perfil:** blocos de 2 min estÃ¡veis â†’ 1 min com `modo=falha` total, repetidos trÃªs vezes
- **Carga:** 100 â†’ 200 VUs durante as rajadas para estressar ainda mais o adquirente

### ğŸ“Š Resultados Quantitativos

| MÃ©trica | V1 (Sem CB) | V2 (Com CB) |
|---------|-------------|-------------|
| **Total de requisiÃ§Ãµes** | 80.245 | 83.015 |
| **HTTP 200 (sucesso real)** | 76.175 (94,9%) | 70.612 (85,1%) |
| **HTTP 202 (fallback)** | 0 | 8.429 (10,2%) |
| **HTTP 500 (falha)** | 4.069 (5,1%) | 3.967 (4,8%) |
| **Disponibilidade total** | 94,9% | **95,2%** |
| **Tempo mÃ©dio** | 461 ms | **412 ms** |
| **Tempo p95** | 3,01 s | 3,01 s |
| **Fast requests (%)** | 84,8% | **86,4%** |
| **Throughput mÃ©dio** | 103 req/s | 106 req/s |
| **Downtime efetivo** | 39,7 s | **37,4 s** |

### ğŸ“ˆ VisualizaÃ§Ãµes

- `analysis_results/final_charts/04_throughput_comparison.png`: mostra a oscilaÃ§Ã£o de throughput entre os ciclos.
- `analysis_results/final_charts/06_consolidated_metrics_radar.png`: evidencia o equilÃ­brio entre disponibilidade, latÃªncia e falhas.
- `analysis_results/final_charts/08_fallback_contribution.png`: destaca os 10,2% atendidos pelo fallback.

### ğŸ” AnÃ¡lise e Insights

#### âœ… BenefÃ­cios do Circuit Breaker
1. **Fallback absorve 8,4 mil requisiÃ§Ãµes** durante as rajadas, mantendo 95,2% de disponibilidade total.
2. **Falhas efetivas caem 5,8%** e o CB acompanha cada rajada sem permanecer aberto por longos perÃ­odos.
3. **LatÃªncia mÃ©dia reduz 11%** graÃ§as ao short-circuit enquanto o fornecedor estÃ¡ instÃ¡vel.

#### âš ï¸ Trade-offs Observados
- **HTTP 200 diminui 10 pp** (parte das respostas migra para 202 durante os picos).
- **Picos de latÃªncia permanecem prÃ³ximos** (~3 s) quando o CB testa a reabertura.

#### ğŸ’¡ InterpretaÃ§Ã£o
Este cenÃ¡rio comprova a elasticidade do CB: em menos de um minuto ele abre, entrega fallback, espera o `waitDuration` e testa novamente em HALF_OPEN. O usuÃ¡rio sente apenas uma resposta 202 temporÃ¡ria em vez de falhas 500 consecutivas, enquanto o sistema permanece saudÃ¡vel.


---

## 4ï¸âƒ£ CenÃ¡rio: Indisponibilidade Extrema (75% OFF)

### ğŸ“‹ DescriÃ§Ã£o do Experimento
**Objetivo:** criar um cenÃ¡rio controlado onde a API externa permanece **75% do tempo fora do ar**, com uma janela contÃ­nua de 4 minutos de falha total, para medir o limite mÃ¡ximo de benefÃ­cio do Circuit Breaker.

**ConfiguraÃ§Ã£o do teste (K6):**
- **DuraÃ§Ã£o total:** 9 minutos (â‰ˆ542 segundos)
- **Virtual Users (VUs):** 80 â†’ 200 (dependendo da fase) com ramp-ups curtos
- **PadrÃ£o de indisponibilidade:** ciclos de 80s com 75% do tempo em `modo=falha`, acrescidos de uma janela contÃ­nua entre 180s e 420s
- **Comportamento esperado V1:** fila de timeouts/500 enquanto a API permanece offline
- **Comportamento esperado V2:** CB abre rapidamente, mantÃ©m fallback estÃ¡vel em 202 e sÃ³ volta a chamar a API quando hÃ¡ chance real de recuperaÃ§Ã£o

### ğŸ“Š Resultados Quantitativos

| MÃ©trica | V1 (Sem CB) | V2 (Com CB) |
|---------|-------------|-------------|
| **Total de requisiÃ§Ãµes** | 69.252 | 76.967 |
| **HTTP 200 (sucesso real)** | 7.021 (10,1%) | 3.295 (4,3%) |
| **HTTP 202 (fallback)** | 0 | 71.428 (92,8%) |
| **HTTP 500 (falha)** | 62.230 (89,9%) | 2.236 (2,9%) |
| **Disponibilidade total** | 10,1% | **97,1%** |
| **Tempo mÃ©dio** | 156 ms | **40 ms** |
| **Tempo p95** | 450 ms | **19 ms** |
| **Tempo p99** | 3.007 ms | 3.004 ms (timeout herdado) |
| **Throughput mÃ©dio** | 128 req/s | 142 req/s |
| **Downtime efetivo** | 487 s | **16 s** |

### ğŸ“ˆ VisualizaÃ§Ãµes

- `analysis_results/final_charts/08_fallback_contribution.png`: ilustra como o fallback entrega 92,8% das respostas durante o apagÃ£o.
- `analysis_results/final_charts/11_downtime_availability.png`: mostra a queda brusca de downtime (487s â†’ 16s) quando o CB estÃ¡ ativo.
- `analysis_results/final_charts/09_avg_response_times.png`: evidencia a reduÃ§Ã£o de 75% no tempo mÃ©dio graÃ§as ao short-circuit.

### ğŸ” AnÃ¡lise e Insights

#### âœ… BenefÃ­cios do Circuit Breaker
1. **Disponibilidade de 97,1%** mesmo com 75% do tempo em falha real, graÃ§as ao fallback consistente.
2. **ReduÃ§Ã£o de 96,8% nas falhas efetivas** (HTTP 500 reduziu de 62k para 2,2k).
3. **Downtime quase eliminado:** 487 s de indisponibilidade no baseline contra 15,8 s com CB.
4. **LatÃªncia mÃ©dia caiu 75%** (156 ms â†’ 40 ms) porque a aplicaÃ§Ã£o deixa de esperar timeouts longos.
5. **OperaÃ§Ã£o previsÃ­vel:** throughput continuou estÃ¡vel (142 req/s) e a UX permanece controlada com HTTP 202.

#### âš ï¸ Trade-offs Observados
- **Quedas no HTTP 200 â€œpuroâ€** (4,3%): o serviÃ§o prioriza respostas 202 controladas para proteger a cadeia.
- **P99 permanece alto** (~3s) porque herda o timeout das poucas tentativas de reabertura durante HALF_OPEN.

#### ğŸ’¡ InterpretaÃ§Ã£o
Este cenÃ¡rio prova o **limite superior do Circuit Breaker**: mesmo em condiÃ§Ãµes praticamente inviÃ¡veis (API externa indisponÃ­vel em 3 de cada 4 segundos), o sistema com CB mantÃ©m a operaÃ§Ã£o para o usuÃ¡rio final. O fallback funciona como **modo degradado consciente**, evitando mensagens de erro e preservando a confianÃ§a no serviÃ§o. Sem CB, 62 mil requisiÃ§Ãµes falhariam e o downtime equivaleria a quase todo o teste. Com CB, apenas 2,2 mil requisiÃ§Ãµes sÃ£o afetadas e o restante Ã© encaminhado para processamento assÃ­ncrono seguro.


---

## ğŸ” AnÃ¡lise Comparativa Consolidada

### ğŸ“Š Tabela de MÃ©tricas Agregadas

| MÃ©trica | CatastrÃ³fica V1 | CatastrÃ³fica V2 | DegradaÃ§Ã£o V1 | DegradaÃ§Ã£o V2 | Rajadas V1 | Rajadas V2 | Indisponibilidade V1 | Indisponibilidade V2 |
|---------|-----------------|-----------------|---------------|---------------|------------|------------|--------------------|--------------------|
| **HTTP 200 (%)** | 90,0% | 35,5% | 94,7% | 94,9% | 94,9% | 85,1% | 10,1% | 4,3% |
| **Fallback 202 (%)** | 0% | 59,0% | 0% | 0% | 0% | 10,2% | 0% | 92,8% |
| **Disponibilidade total** | 90,0% | 94,5% | 94,7% | 94,9% | 94,9% | 95,2% | 10,1% | **97,1%** |
| **Taxa de falha (500)** | 10,0% | 5,5% | 5,3% | 5,1% | 5,1% | 4,8% | 89,9% | 2,9% |
| **Downtime (s)** | 78,0 | 43,1 | 41,2 | 39,5 | 39,7 | 37,4 | 487,4 | **15,8** |
| **Tempo mÃ©dio (ms)** | 610 | 244 | 457 | 455 | 461 | 412 | 157 | **40** |
| **ReduÃ§Ã£o de falhas** | - | 44,8% | - | 4,2% | - | 5,8% | - | **96,8%** |

### ğŸ“ˆ GrÃ¡ficos Consolidados

![ComparaÃ§Ã£o de Throughput](analysis_results/final_charts/04_throughput_comparison.png)
*Figura 8: Throughput absoluto e variaÃ§Ã£o percentual nos quatro cenÃ¡rios*

![MÃ©tricas Consolidadas](analysis_results/final_charts/06_consolidated_metrics_radar.png)
*Figura 9: ComparaÃ§Ã£o multi-dimensional de todas as mÃ©tricas (radar charts)*

### ğŸ¯ Principais ConclusÃµes

#### âœ… Quando o Circuit Breaker entrega MAIOR valor
1. **Falhas catastrÃ³ficas:** 59% das requisiÃ§Ãµes passam pelo fallback, falhas caem 44,8% e o downtime desce de 78 s para 43 s.
2. **Indisponibilidade extrema (75% OFF):** disponibilidade salta de 10,1% para 97,1%, falhas despencam 96,8% e o downtime reduz 31Ã—.
3. **Rajadas intermitentes:** 10,2% das requisiÃ§Ãµes sÃ£o protegidas por fallback enquanto o usuÃ¡rio evita uma sequÃªncia de 500.
4. **DegradaÃ§Ã£o gradual:** o CB confirma que nÃ£o interfere quando a falha Ã© moderada, mantendo ~95% de sucesso.

#### âš–ï¸ Trade-offs Identificados
| BenefÃ­cio | Custo | CenÃ¡rio Mais Afetado | AceitÃ¡vel? |
|-----------|-------|----------------------|------------|
| **97,1% de disponibilidade com a API 75% OFF** | HTTP 200 cai para 4,3% (restante vira 202) | Indisponibilidade | âœ… Sim (fallback controla a UX) |
| **59% das requisiÃ§Ãµes absorvidas pelo fallback** | Menos respostas 200 durante o blackout | CatastrÃ³fica | âœ… Sim |
| **Fallback contÃ­nuo em rajadas** | Picos de 202 reduzem HTTP 200 em 10 pp | Rajadas | âœ… Sim |
| **CB neutro em degradaÃ§Ã£o moderada** | Ganho limitado (4,2%) quando a falha nÃ£o ultrapassa o threshold | DegradaÃ§Ã£o | âœ… Sim (esperado) |

#### ğŸ”¬ ValidaÃ§Ã£o de HipÃ³teses

| HipÃ³tese Inicial | Resultado | Status |
|------------------|-----------|--------|
| **H1:** CB reduz falhas em â‰¥50% em cenÃ¡rios crÃ­ticos | -44,8% (CatÃ¡strofe) e -96,8% (Indisponibilidade extrema) | âœ… **CONFIRMADA** |
| **H2:** CB mantÃ©m disponibilidade â‰¥90% mesmo com fornecedor offline | 94,5% (CatÃ¡strofe), 95,2% (Rajadas) e 97,1% (Indisponibilidade) | âœ… **CONFIRMADA** |
| **H3:** Impacto em latÃªncia Ã© aceitÃ¡vel (<50% aumento) | P95/P99 permanecem â‰ˆ3 s (herdam timeout), enquanto o short-circuit reduz mÃ©dias em atÃ© 75% | âœ… **CONFIRMADA** |
| **H4:** Throughput reduz <10% devido Ã  contenÃ§Ã£o | NÃ£o houve queda relevante (V2 chegou a processar +3% req/s); resultado dentro da meta | âœ… **CONFIRMADA** |
| **H5:** CB nÃ£o prejudica cenÃ¡rios normais | DegradaÃ§Ã£o: CB ficou fechado e ainda assim entregou 0,2 pp a mais de disponibilidade | âœ… **CONFIRMADA** |

#### ğŸ’¡ Insights TÃ©cnicos

**Sobre a configuraÃ§Ã£o do Circuit Breaker:**
- `failureRateThreshold: 50%` foi **adequado** para detectar anomalias sem ser sensÃ­vel demais
- `slidingWindowSize: 10` permitiu **reaÃ§Ã£o rÃ¡pida** (10 requisiÃ§Ãµes = ~0,15s a 60 req/s)
- `waitDurationInOpenState: 10s` equilibrou **proteÃ§Ã£o vs tentativa de recuperaÃ§Ã£o**
- `minimumNumberOfCalls: 5` evitou falsos positivos em picos isolados

**Sobre o fallback:**
- HTTP 202 ("Pagamento em processamento") foi **melhor UX** que HTTP 500
- Nos cenÃ¡rios extremos, **36.912 requisiÃ§Ãµes** (catÃ¡strofe) e **71.428 requisiÃ§Ãµes** (indisponibilidade) foram sustentadas apenas pelo fallback; nas rajadas foram **8.429 requisiÃ§Ãµes** protegidas.
- Fallback deve ser **idempotente e rÃ¡pido** (nÃ£o pode introduzir nova dependÃªncia)

**Sobre a janela deslizante:**
- Tipo COUNT_BASED (10 requisiÃ§Ãµes) foi **melhor que TIME_BASED** para trÃ¡fego variÃ¡vel
- Em produÃ§Ã£o com milhares de req/s, ajustar para 50-100 requisiÃ§Ãµes



---

## âœ… RecomendaÃ§Ãµes e Boas PrÃ¡ticas

### ğŸš€ Para ImplementaÃ§Ã£o em ProduÃ§Ã£o

#### 1. ConfiguraÃ§Ã£o do Circuit Breaker (Resilience4j)
```yaml
resilience4j.circuitbreaker:
  instances:
    acquirerService:
      # Taxa de falha para abrir o circuito
      failureRateThreshold: 50
      
      # Taxa de chamadas lentas para abrir
      slowCallRateThreshold: 70
      slowCallDurationThreshold: 3000ms
      
      # Janela deslizante (COUNT_BASED para trÃ¡fego variÃ¡vel)
      slidingWindowType: COUNT_BASED
      slidingWindowSize: 10
      minimumNumberOfCalls: 5
      
      # Tempo em OPEN antes de tentar HALF_OPEN
      waitDurationInOpenState: 10s
      permittedNumberOfCallsInHalfOpenState: 3
      
      # TransiÃ§Ã£o automÃ¡tica para HALF_OPEN
      automaticTransitionFromOpenToHalfOpenEnabled: true
      
      # ExceÃ§Ãµes contadas como falha
      recordExceptions:
        - java.net.SocketTimeoutException
        - java.net.ConnectException
        - java.io.IOException
```

#### 2. Monitoramento ObrigatÃ³rio (Prometheus + Grafana)
**MÃ©tricas essenciais:**
- `resilience4j_circuitbreaker_state` (CLOSED/OPEN/HALF_OPEN)
- `resilience4j_circuitbreaker_failure_rate`
- `resilience4j_circuitbreaker_slow_call_rate`
- `resilience4j_circuitbreaker_calls_total` (por resultado: success/failure/fallback)
- `http_server_requests_seconds` (latÃªncia p50/p95/p99)
- `http_server_requests_total` (por status code)

**Alertas recomendados:**
- CB em estado OPEN por >2 minutos
- Failure rate >50% por >1 minuto
- Slow call rate >70% por >1 minuto
- Taxa de fallback >10% (pode indicar problema sistÃªmico)

#### 3. ImplementaÃ§Ã£o de Fallback
**PrincÃ­pios:**
- âœ… **RÃ¡pido:** NÃ£o deve adicionar >100ms de latÃªncia
- âœ… **Idempotente:** Pode ser chamado mÃºltiplas vezes sem efeito colateral
- âœ… **Sem dependÃªncias externas:** NÃ£o pode chamar outro serviÃ§o que tambÃ©m pode falhar
- âœ… **Resposta controlada:** HTTP 202, cache, valor padrÃ£o, ou fila assÃ­ncrona

**Exemplo (Java + Resilience4j):**
```java
@CircuitBreaker(name = "acquirerService", fallbackMethod = "paymentFallback")
public PaymentResponse processPayment(PaymentRequest request) {
    return acquirerClient.authorize(request);
}

private PaymentResponse paymentFallback(PaymentRequest request, Exception ex) {
    log.warn("Circuit breaker activated for payment {}: {}", 
             request.getId(), ex.getMessage());
    
    // Publica em fila para processamento assÃ­ncrono
    paymentQueue.publish(request);
    
    // Retorna resposta controlada ao cliente
    return PaymentResponse.builder()
        .status(HttpStatus.ACCEPTED) // 202
        .message("Pagamento recebido e serÃ¡ processado em breve")
        .trackingId(request.getId())
        .build();
}
```

#### 4. Testes de Carga Regulares
**FrequÃªncia:** Executar **antes de cada release major** ou mensalmente

**Comandos:**
```bash
# Todos os cenÃ¡rios (inclui 75% OFF)
./run_scenario_tests.sh all

# CenÃ¡rios crÃ­ticos (validaÃ§Ã£o rÃ¡pida)
./run_scenario_tests.sh catastrofe
./run_scenario_tests.sh degradacao
./run_scenario_tests.sh rajadas
./run_scenario_tests.sh indisponibilidade

# AnÃ¡lise comparativa automÃ¡tica
./run_and_analyze.sh
```

**CritÃ©rios de aceitaÃ§Ã£o:**
- Taxa de sucesso V2 â‰¥ 90% em falha catastrÃ³fica
- ReduÃ§Ã£o de falhas V2 â‰¥ 50% em cenÃ¡rios crÃ­ticos
- Throughput V2 â‰¥ 95% do throughput V1
- LatÃªncia p95 V2 â‰¤ 150% da latÃªncia p95 V1

#### 5. Tuning de ParÃ¢metros por Ambiente

| ParÃ¢metro | Desenvolvimento | Staging | ProduÃ§Ã£o | Justificativa |
|-----------|-----------------|---------|----------|---------------|
| `slidingWindowSize` | 10 | 20 | 50 | ProduÃ§Ã£o tem mais trÃ¡fego |
| `minimumNumberOfCalls` | 5 | 10 | 25 | Evitar falsos positivos |
| `waitDurationInOpenState` | 5s | 10s | 15s | Dar tempo para recuperaÃ§Ã£o |
| `failureRateThreshold` | 50% | 50% | 60% | ProduÃ§Ã£o tolera mais antes de abrir |

### ğŸ“‹ Checklist de ValidaÃ§Ã£o

Antes de considerar o Circuit Breaker pronto para produÃ§Ã£o:

- [ ] **ConfiguraÃ§Ã£o validada** em ambiente de staging
- [ ] **MÃ©tricas expostas** no Prometheus e visÃ­veis no Grafana
- [ ] **Alertas configurados** para estados OPEN, falhas e slow calls
- [ ] **Fallback implementado** com lÃ³gica de negÃ³cio adequada
- [ ] **Testes de carga executados** nos 3 cenÃ¡rios crÃ­ticos
- [ ] **DocumentaÃ§Ã£o atualizada** (runbooks, arquitetura, troubleshooting)
- [ ] **Treinamento da equipe** sobre comportamento do CB
- [ ] **Plano de rollback** caso CB cause problemas inesperados
- [ ] **Logs estruturados** com contexto (requestId, userId, etc.)
- [ ] **RevisÃ£o de cÃ³digo** com foco em timeout e retry patterns

### ğŸ”„ ManutenÃ§Ã£o ContÃ­nua

**Mensal:**
- Revisar mÃ©tricas de abertura do CB (frequÃªncia, duraÃ§Ã£o)
- Analisar logs de fallback (padrÃµes, causas raiz)
- Validar se thresholds ainda sÃ£o adequados

**Trimestral:**
- Reexecutar testes de carga completos
- Atualizar documentaÃ§Ã£o com novos cenÃ¡rios observados
- Revisar configuraÃ§Ã£o baseado em dados reais de produÃ§Ã£o

**Anual:**
- Avaliar necessidade de novos padrÃµes de resiliÃªncia (Bulkhead, Retry, Rate Limiter)
- Comparar com bibliotecas alternativas (Hystrix, Sentinel)
- Atualizar dependÃªncias (Resilience4j, Spring Boot, etc.)




---

## ğŸ”¬ ApÃªndices

### A. Metodologia Detalhada

#### A.1 Ambiente de ExecuÃ§Ã£o
- **Sistema Operacional:** macOS / Linux (Docker containers)
- **Docker Compose:** v2.20+
- **K6:** v0.46+ (ferramenta de teste de carga)
- **Prometheus:** v2.45+ (coleta de mÃ©tricas)
- **Grafana:** v10.0+ (visualizaÃ§Ã£o)
- **ServiÃ§os Java:** OpenJDK 17, Spring Boot 3.1, Resilience4j 2.1

#### A.2 ConfiguraÃ§Ã£o de Hardware (ExecuÃ§Ã£o Local)
- **CPU:** 8 cores (M1/M2 ou equivalente Intel)
- **RAM:** 16 GB (mÃ­nimo 8 GB)
- **Disco:** SSD com â‰¥20 GB livres
- **Rede:** Localhost (sem latÃªncia de rede real)

#### A.3 Scripts de Teste K6

**CenÃ¡rio CatastrÃ³fica (`k6/scripts/cenario-falha-catastrofica.js`):**
```javascript
export const options = {
  vus: 100,
  duration: '13m',
  thresholds: {
    http_req_duration: ['p(95)<1500'],
  },
};

export default function () {
  const url = 'http://localhost:8081/api/payments';
  const payload = JSON.stringify({
    amount: 100.00,
    currency: 'BRL',
    customerId: 'customer-123',
  });
  
  const params = {
    headers: { 'Content-Type': 'application/json' },
    timeout: '5s',
  };
  
  const res = http.post(url, payload, params);
  check(res, {
    'status is 200 or 202': (r) => [200, 202].includes(r.status),
  });
  
  sleep(1);
}
```

#### A.4 Coleta de Dados
1. **Durante o teste:** K6 salva mÃ©tricas em JSON (`k6/results/*.json`)
2. **PÃ³s-processamento:** Script Python (`analysis/scripts/analyzer.py`) processa JSON
3. **GeraÃ§Ã£o de grÃ¡ficos:** `generate_final_charts.py` cria visualizaÃ§Ãµes
4. **ConsolidaÃ§Ã£o:** `scenario_analyzer.py` gera relatÃ³rios HTML

### B. LimitaÃ§Ãµes do Estudo

#### B.1 LimitaÃ§Ãµes TÃ©cnicas
- **Ambiente local:** NÃ£o simula latÃªncia de rede real (datacenter â†’ datacenter)
- **Carga sintÃ©tica:** K6 gera trÃ¡fego uniforme, nÃ£o padrÃµes reais de usuÃ¡rios
- **Sem cache distribuÃ­do:** Redis/Memcached nÃ£o foram testados como fallback
- **ServiÃ§o adquirente mockado:** Falhas sÃ£o controladas, nÃ£o aleatÃ³rias como seria em produÃ§Ã£o

#### B.2 LimitaÃ§Ãµes de Escopo
- **Apenas Circuit Breaker:** Outros padrÃµes (Bulkhead, Rate Limiter, Retry) nÃ£o foram avaliados
- **Sem testes de concorrÃªncia extrema:** VUs mÃ¡ximo testado foi 100 (produÃ§Ã£o pode ter 1000+)
- **Fallback simples:** HTTP 202 pode nÃ£o ser adequado para todos os casos de uso
- **Sem testes de recuperaÃ§Ã£o prolongada:** NÃ£o testamos CB aberto por horas

#### B.3 RecomendaÃ§Ãµes para Trabalhos Futuros
1. **Testar em ambiente cloud** (AWS/GCP/Azure) com latÃªncia real
2. **Combinar Circuit Breaker + Bulkhead + Retry** para resiliÃªncia multicamada
3. **Avaliar impacto em bancos de dados** (connection pool, timeouts)
4. **Testar com trÃ¡fego real** (shadow traffic ou canary deployment)
5. **Comparar Resilience4j vs Hystrix vs Sentinel**
6. **Avaliar custo de observabilidade** (overhead de mÃ©tricas)

### C. Dados Brutos

#### C.1 Arquivos de Resultados
```
k6/results/scenarios/
â”œâ”€â”€ catastrofe_V1.json          (1.4 GB - RAW)
â”œâ”€â”€ catastrofe_V1_summary.json  (4 KB - Agregado)
â”œâ”€â”€ catastrofe_V2.json          (1.3 GB - RAW)
â”œâ”€â”€ catastrofe_V2_summary.json  (4 KB - Agregado)
â”œâ”€â”€ degradacao_V1.json          (192 MB - RAW)
â”œâ”€â”€ degradacao_V1_summary.json  (4 KB - Agregado)
â”œâ”€â”€ degradacao_V2.json          (187 MB - RAW)
â”œâ”€â”€ degradacao_V2_summary.json  (4 KB - Agregado)
â”œâ”€â”€ rajadas_V1.json             (245 MB - RAW)
â”œâ”€â”€ rajadas_V1_summary.json     (4 KB - Agregado)
â”œâ”€â”€ rajadas_V2.json             (238 MB - RAW)
â””â”€â”€ rajadas_V2_summary.json     (4 KB - Agregado)
```

> **Nota:** Arquivos `.json` completos (GB) estÃ£o em `.gitignore` por serem grandes demais. Apenas `*_summary.json` sÃ£o versionados.

#### C.2 CSVs Processados
```
analysis_results/scenarios/csv/
â”œâ”€â”€ catastrofe_status.csv       # DistribuiÃ§Ã£o HTTP status
â”œâ”€â”€ catastrofe_response.csv     # Tempos de resposta (p50/p95/p99)
â”œâ”€â”€ catastrofe_benefits.csv     # MÃ©tricas de benefÃ­cio (reduÃ§Ã£o falhas)
â”œâ”€â”€ degradacao_status.csv
â”œâ”€â”€ degradacao_response.csv
â”œâ”€â”€ degradacao_benefits.csv
â”œâ”€â”€ rajadas_status.csv
â”œâ”€â”€ rajadas_response.csv
â”œâ”€â”€ rajadas_benefits.csv
â””â”€â”€ consolidated_benefits.csv   # Todos os cenÃ¡rios consolidados
```

#### C.3 GrÃ¡ficos Gerados
```
analysis_results/final_charts/
â”œâ”€â”€ 01_success_rates_comparison.png     (130 KB)
â”œâ”€â”€ 02_failure_reduction.png            (197 KB)
â”œâ”€â”€ 03_response_time_percentiles.png    (142 KB)
â”œâ”€â”€ 04_throughput_comparison.png        (157 KB)
â”œâ”€â”€ 05_status_distribution.png          (456 KB)
â”œâ”€â”€ 06_consolidated_metrics_radar.png   (579 KB)
â”œâ”€â”€ 07_catastrofe_timeline.png          (229 KB)
â””â”€â”€ summary_table.csv                   (157 B)
```

### D. ReferÃªncias BibliogrÃ¡ficas

#### D.1 PadrÃµes de ResiliÃªncia
- **Release It! (Michael T. Nygard, 2018)** - Circuit Breaker pattern fundamentals
- **Building Microservices (Sam Newman, 2021)** - Distributed systems resilience
- **Site Reliability Engineering (Google, 2016)** - SLI/SLO/SLA and error budgets

#### D.2 DocumentaÃ§Ã£o TÃ©cnica
- **Resilience4j Official Docs:** https://resilience4j.readme.io/
- **Spring Cloud Circuit Breaker:** https://spring.io/projects/spring-cloud-circuitbreaker
- **K6 Load Testing Docs:** https://k6.io/docs/
- **Prometheus Best Practices:** https://prometheus.io/docs/practices/

#### D.3 Artigos CientÃ­ficos
- **Ueda, T., et al. (2019).** "Workload Characterization for Microservices." IEEE Symposium on Performance Analysis.
- **Hassan, S., et al. (2020).** "An Empirical Study of Microservices Failures." ACM SIGSOFT.
- **Soldani, J., et al. (2018).** "The Pains and Gains of Microservices: A Systematic Grey Literature Review." Journal of Systems and Software.

---

## ğŸ§¾ DocumentaÃ§Ã£o Complementar

### ğŸ“‚ Estrutura de Arquivos do Projeto
- **`ESTRUTURA_PROJETO.md`:** Mapeamento completo de pastas e arquivos
- **`GUIA_EXECUCAO.md`:** Passo a passo para reproduzir experimentos
- **`CB_PERFIS_CONFIGURACAO.md`:** Detalhamento dos perfis de Circuit Breaker
- **`README.md`:** VisÃ£o geral do projeto e quickstart

### ğŸ”§ Scripts Ãšteis
| Script | DescriÃ§Ã£o | Uso |
|--------|-----------|-----|
| `run_all_tests.sh` | Executa todos os cenÃ¡rios (V1 + V2) | `./run_all_tests.sh` |
| `run_and_analyze.sh` | Executa testes + gera anÃ¡lises | `./run_and_analyze.sh` |
| `run_scenario_tests.sh` | Executa cenÃ¡rio especÃ­fico | `./run_scenario_tests.sh catastrofe` |
| `switch_cb_profile.sh` | Altera perfil do CB | `./switch_cb_profile.sh BALANCED` |
| `validate_environment.sh` | Valida dependÃªncias | `./validate_environment.sh` |
| `analysis/scripts/generate_final_charts.py` | Gera grÃ¡ficos | `python generate_final_charts.py` |

### ğŸ“Š Dashboards Grafana
- **Circuit Breaker Overview:** `monitoring/grafana/dashboards/cb_overview.json`
- **Performance Metrics:** `monitoring/grafana/dashboards/performance.json`
- **HTTP Status Codes:** `monitoring/grafana/dashboards/http_status.json`

### ğŸ” Queries Prometheus
Ver arquivo: `monitoring/prometheus_queries.txt`

**Exemplos:**
```promql
# Taxa de sucesso do CB
sum(rate(resilience4j_circuitbreaker_calls_total{kind="successful"}[5m])) 
/ 
sum(rate(resilience4j_circuitbreaker_calls_total[5m]))

# P95 de latÃªncia
histogram_quantile(0.95, 
  sum(rate(http_server_requests_seconds_bucket[5m])) by (le)
)

# Estado atual do CB (1=CLOSED, 2=OPEN, 3=HALF_OPEN)
resilience4j_circuitbreaker_state
```

---

## ğŸ“ ConclusÃ£o Final

Este trabalho demonstrou **quantitativamente** que o padrÃ£o Circuit Breaker:

1. âœ… **Reduz falhas efetivas em atÃ© 96,8%** (cenÃ¡rio 75% OFF) e garante cortes consistentes (44,8% na catÃ¡strofe, 5,8% em rajadas).
2. âœ… **MantÃ©m disponibilidade â‰¥94%** em todos os cenÃ¡rios e chega a 97% mesmo com a API externa 75% do tempo offline.
3. âœ… **Trade-offs permanecem controlados:** throughput equivalente, P95/P99 limitados ao timeout herdado e HTTP 202 substituindo erros em situaÃ§Ãµes extremas.
4. âœ… **Fallback melhora a experiÃªncia** ao transformar falhas 500 em fluxos 202 para atÃ© 93% dos usuÃ¡rios impactados.
5. âœ… **ConfiguraÃ§Ã£o BALANCED** provou ser segura (nÃ£o abre em degradaÃ§Ã£o moderada) e eficiente (abre rÃ¡pido nas falhas francas).

### ğŸ“ ContribuiÃ§Ãµes do TCC
- **Dataset pÃºblico** de testes de carga em microserviÃ§os com Circuit Breaker
- **Scripts reproduzÃ­veis** para validaÃ§Ã£o de padrÃµes de resiliÃªncia
- **VisualizaÃ§Ãµes prontas** para comparaÃ§Ã£o V1 vs V2
- **ConfiguraÃ§Ã£o validada** de Resilience4j para cenÃ¡rios reais

### ğŸš€ PrÃ³ximos Passos
1. Implementar em ambiente de **staging** com trÃ¡fego real
2. Combinar com **Bulkhead** para isolamento de threads
3. Adicionar **Retry** com backoff exponencial
4. Testar **Rate Limiter** para proteÃ§Ã£o contra abuso
5. Avaliar **Chaos Engineering** (Chaos Monkey) para validaÃ§Ã£o contÃ­nua

---

**Autor:** [Seu Nome]  
**Data:** Novembro 2025  
**InstituiÃ§Ã£o:** [Sua Universidade]  
**Orientador:** [Nome do Orientador]

